# Probability

Probability forms a foundation for statistics. You might already be familiar with many aspects of probability, however, formalization of the concepts is new for most. This chapter aims to introduce probability on familiar terms using processes most people have seen before.

## Defining probability



2♣ 3♣ 4♣ 5♣ 6♣ 7♣ 8♣ 9♣ 10♣ J♣ Q♣ K♣ A♣
2♦ 3♦ 4♦ 5♦ 6♦ 7♦ 8♦ 9♦ 10♦ J♦ Q♦ K♦ A♦
2♥ 3♥ 4♥ 5♥ 6♥ 7♥ 8♥ 9♥ 10♥ J♥ Q♥ K♥ A♥
2♠ 3♠ 4♠ 5♠ 6♠ 7♠ 8♠ 9♠ 10♠ J♠ Q♠ K♠ A♠
\section{Exercises}

%_________________
\subsection{Defining probability}

% 1

\eoce{\qt{True or false} Determine if the statements below are true or false, and explain your reasoning.
\begin{parts}
\item If a fair coin is tossed many times and the last eight tosses are all heads, then the chance that the next toss will be heads is somewhat less than 50\%.
\item Drawing a face card (jack, queen, or king) and drawing a red card from a full deck of playing cards are mutually exclusive events.
\item Drawing a face card and drawing an ace from a full deck of playing cards are mutually exclusive events.
\end{parts}
}{}

% 2

\eoce{\qt{Roulette wheel\label{roulette_wheel}} The game of roulette involves spinning a wheel with 38 slots: 18 red, 18 black, and 2 green. A ball is spun onto the wheel and will eventually land in a slot, where each slot has an equal chance of capturing the ball. \footfullcite{rouletteWheelPic}

\noindent\begin{minipage}[c]{0.725\textwidth}
\begin{parts}
\item You watch a roulette wheel spin 3 consecutive times and the ball lands on a red slot each time. What is the probability that the ball will land on a red slot on the next spin?
\item You watch a roulette wheel spin 300 consecutive times and the ball lands on a red slot each time. What is the probability that the ball will land on a red slot on the next spin?
\item Are you equally confident of your answers to parts~(a) and~(b)? Why or why not?
\end{parts}
\end{minipage}
\begin{minipage}[c]{0.025\textwidth}
\end{minipage}
\begin{minipage}[c]{0.25\textwidth}
\hfill\includegraphics[width = 0.94\textwidth]{02/figures/eoce/images/roulette_wheel}
\end{minipage}
}{}


% 3

\eoce{\qt{Four games, one winner} Below are four versions of the same game. Your archnemisis gets to pick the version of the game, and then you get to choose how many times to flip a coin: 10 times or 100 times. Identify how many coin flips you should choose for each version of the game. Explain your reasoning.
\begin{parts}
\item If the proportion of heads is larger than 0.60, you win \$1.
\item If the proportion of heads is larger than 0.40, you win \$1.
\item If the proportion of heads is between 0.40 and 0.60, you win \$1.
\item If the proportion of heads is smaller than 0.30, you win \$1.
\end{parts}
}{}

% 4

\eoce{\qt{Backgammon} Backgammon is a board game for two players in which the playing pieces are moved according to the roll of two dice. Players win by removing all of their pieces from the board, so it is usually good to roll high numbers. You are playing backgammon with a friend and you roll two 6s in your first roll and two 6s in your second roll. Your friend rolls two 3s in his first roll and again in his second row. Your friend claims that you are cheating, because rolling double 6s twice in a row is very unlikely. Using probability, show that your rolls were just as likely as his.
}{}

% 5

\eoce{\qt{Coin flips} If you flip a fair coin 10 times, what is the probability of \vspace{-3mm}
\begin{multicols}{3}
\begin{parts}
\item getting all tails? 
\item getting all heads? 
\item getting at least one tails? 
\end{parts}
\end{multicols}
}{}

% 6

\eoce{\qt{Dice rolls} If you roll a pair of fair dice, what is the probability of \textB{\vspace{-3mm}}
\begin{multicols}{3}
\begin{parts}
\item getting a sum of 1?
\item getting a sum of 5?
\item getting a sum of 12?
\end{parts}
\end{multicols} 
}{}

% 7
\textB{\pagebreak}

\eoce{\qt{Swing voters\label{indepSwing}} A 2012 Pew Research survey asked 2,373 randomly sampled registered voters their political affiliation (Republican, Democrat, or Independent) and whether or not they identify as swing voters. 35\% of respondents identified as Independent, 23\% identified as swing voters, and 11\% identified as both.\footfullcite{indepSwing}
\begin{parts}
\item Are being Independent and being a swing voter disjoint, i.e. mutually exclusive?
\item Draw a Venn diagram summarizing the variables and their associated probabilities.
\item What percent of voters are Independent but not swing voters?
\item What percent of voters are Independent or swing voters?
\item What percent of voters are neither Independent nor swing voters?
\item Is the event that someone is a swing voter independent of the event that someone is a political Independent?
\end{parts}
}{}

% 8

\eoce{\qt{Poverty and language\label{poorLang}} The American Community Survey is an ongoing survey that provides data every year to give communities the current information they need to plan investments and services. The 2010 American Community Survey estimates that 14.6\% of Americans live below the poverty line, 20.7\% speak a language other that English at home, and 4.2\% fall into both categories. \footfullcite{poorLang}
\begin{parts}
\item Are living below the poverty line and speaking a language other than English at home disjoint?
\item Draw a Venn diagram summarizing the variables and their associated probabilities.
\item What percent of Americans live below the poverty line and only speak English at home?
\item What percent of Americans live below the poverty line or speak a language other than English at home?
\item What percent of Americans live above the poverty line and only speak English at home? 
\item Is the event that someone lives below the poverty line independent of the event that the person speaks a language other than English at home?
\end{parts}
}{}

% 9

\eoce{\qt{Disjoint vs. independent} In parts~(a) and~(b), identify whether the events are disjoint, independent, or neither (events cannot be both disjoint and independent).
\begin{parts}
\item You and a randomly selected student from your class both earn A's in this course. 
\item You and your class study partner both earn A's in this course.
\item If two events can occur at the same time, must they be dependent?
\end{parts}
}{}

% 10

\eoce{\qt{Guessing on an exam} In a multiple choice exam, there are 5 questions and 4 choices for each question (a, b, c, d). Nancy has not studied for the exam at all and decides to randomly guess the answers. What is the probability that:
\begin{parts}
\item the first question she gets right is the $5^{th}$ question?
\item she gets all of the questions right?
\item she gets at least one question right?
\end{parts}
}{}

% 11
\textB{\pagebreak}

\eoce{\qt{Educational attainment of couples} The table below shows the distribution of education level attained by US residents by gender based on data collected during the 2010 American Community Survey.\footfullcite{eduSex}
\begin{center}
\begin{tabular}{l p{7cm} c c }
&						& \multicolumn{2}{c}{\textit{Gender}} \\
\cline{3-4}
&												& Male	& Female \\
\cline{2-4}
& Less than 9th grade								&0.07	&0.13	 \\
& 9th to 12th grade, no diploma						&0.10	&0.09	 \\
\textit{Highest} & High school graduate, GED, or alternative	&0.30	&0.20	 \\
\textit{education} & Some college, no degree				&0.22	&0.24	 \\ 
\textit{attained} & Associate's degree					&0.06	&0.08	 \\
& Bachelor's degree									&0.16	&0.17	 \\
& Graduate or professional degree						&0.09	&0.09	 \\
\cline{2-4}
& Total											& 1.00	& 1.00
\end{tabular}
\end{center}
\begin{parts}
\item What is the probability that a randomly chosen man has at least a Bachelor's degree?
\item What is the probability that a randomly chosen woman has at least a Bachelor's degree?
\item What is the probability that a man and a woman getting married both have at least a Bachelor's degree? Note any assumptions you must make to answer this question.
\item If you made an assumption in part~(c), do you think it was reasonable? If you didn't make an assumption, double check your earlier answer and then return to this part.
\end{parts}
}{}

% 12

\eoce{\qt{School absences\label{elementarySchoolSick}} Data collected at elementary schools in DeKalb County, GA suggest that each year roughly 25\% of students miss exactly one day of school, 15\% miss 2 days, and 28\% miss 3 or more days due to sickness. \footfullcite{Mizan:2011}
\begin{parts}
\item What is the probability that a student chosen at random doesn't miss any days of school due to sickness this year?
\item What is the probability that a student chosen at random misses no more than one day?
\item What is the probability that a student chosen at random misses at least one day?
\item If a parent has two kids at a DeKalb County elementary school, what is the probability that neither kid will miss any school? Note any assumption you must make to answer this question.
\item If a parent has two kids at a DeKalb County elementary school, what is the probability that that both kids will miss some school, i.e. at least one day? Note any assumption you make.
\item If you made an assumption in part~(d) or~(e), do you think it was reasonable? If you didn't make any assumptions, double check your earlier answers.
\end{parts}
}{}

% 13

\eoce{\qt{Grade distributions} Each row in the table below is a proposed grade distribution for a class. Identify each as a valid or invalid probability distribution, and explain your reasoning.
\begin{center}
\begin{tabular}{l  ccccc} 
	& \multicolumn{5}{c}{\textit{Grades}} \\
\cline{2-6}
	& A		& B 		& C 		& D		& F  \\
\cline{2-6}
(a) 	& 0.3 	& 0.3 	& 0.3 	& 0.2 	& 0.1\\
(b) 	& 0	 	& 0	 	& 1		& 0		& 0 \\
(c) 	& 0.3 	& 0.3 	& 0.3		& 0		& 0 \\
(d) 	& 0.3 	& 0.5 	& 0.2		& 0.1		& -0.1 \\
(e) 	& 0.2 	& 0.4 	& 0.2		& 0.1		& 0.1 \\
(f) 	& 0	 	& -0.1 	& 1.1		& 0		& 0 \\
\end{tabular}
\end{center}
}{}

% 14
\textB{\pagebreak}

\eoce{\qt{Weight and health coverage, Part I\label{healthCovBMI}} The Behavioral Risk Factor Surveillance System (BRFSS) is an annual telephone survey designed to identify risk factors in the adult population and report emerging health trends. The following table summarizes two variables for the respondents: weight status using body mass index (BMI) and health coverage, which describes whether each respondent had health insurance. \footfullcite{data:BRFSS2010}

\begin{center}
\begin{tabular}{ll  ccc  c} 
			&	\multicolumn{1}{c}{}	& \multicolumn{3}{c}{\textit{Weight Status}} & \\ 
\cline{3-5}
			&		& Neither overweight 	& Overweight 	& Obese	&   \\
			&		& nor obese (BMI $<$ 25)&(25 $\le$ BMI $<$ 30) & (BMI $\ge$ 30) & Total \\
\cline{2-6}
\textit{Health}	&Yes 	& 134,801 	& 141,699 	& 107,301 		& 383,801\\
\textit{Coverage}&No 	& 15,098 		& 15,327 		& 14,412			& 44,837 \\
\cline{2-6}
			&Total	& 149,899		&157,026		& 121,713			& 428,638
\end{tabular}
\end{center}

\begin{parts}
\item If we draw one individual at random, what is the probability that the respondent is overweight and doesn't have health coverage?
\item If we draw one individual at random, what is the probability that the respondent is overweight or doesn't have health coverage?
\end{parts}
}{}


%_________________
\subsection{Conditional probability}

% 15

\eoce{\qt{Joint and conditional probabilities} P(A) = 0.3, P(B) = 0.7
\begin{parts}
\item Can you compute P(A and B) if you only know P(A) and P(B)?
\item Assuming that events A and B arise from independent random processes,
\begin{subparts}
\item what is P(A and B)?
\item what is P(A or B)?
\item what is P(A$|$B)?
\end{subparts}
\item If we are given that P(A and B) = 0.1, are the random variables giving rise to events A and B independent?
\item If we are given that P(A and B) = 0.1, what is P(A$|$B)?
\end{parts}
}{}

% 16

\eoce{\qt{PB \& J} Suppose 80\% of people like peanut butter, 89\% like jelly, and 78\% like both. Given that a randomly sampled person likes peanut butter, what's the probability that he also likes jelly?
}{}

% 17

\eoce{\qt{Global warming} A 2010 Pew Research poll asked 1,306 Americans ``From what you've read and heard, is there solid evidence that the average temperature on earth has been getting warmer over the past few decades, or not?". The table below shows the distribution of responses by party and ideology, where the counts have been replaced with relative frequencies.\footfullcite{globalWarming}
\begin{center}
\begin{tabular}{ll  ccc c} 
							&			& \multicolumn{3}{c}{\textit{Response}} \\
\cline{3-5}
							&			& Earth is 		& Not 		& Don't Know	&	\\
							&			& warming	& warming 	& Refuse		& Total\\
\cline{2-6}
				& Conservative Republican	& 0.11	 	& 0.20		& 0.02 		& 0.33 	\\
\textit{Party and}	& Mod/Lib Republican		& 0.06	 	& 0.06 	 	& 0.01		& 0.13 \\
\textit{Ideology}		& Mod/Cons Democrat		& 0.25	 	& 0.07 	 	& 0.02 		& 0.34 \\
				& Liberal Democrat			& 0.18	 	& 0.01 	 	& 0.01 		& 0.20\\
\cline{2-6}
							&Total		& 0.60		& 0.34		& 0.06		& 1.00
\end{tabular}
\end{center}
\begin{parts}
\item What is the probability that a randomly chosen respondent believes the earth is warming or is a liberal Democrat?
\item What is the probability that a randomly chosen respondent believes the earth is warming given that he is a liberal Democrat?
\item What is the probability that a randomly chosen respondent believes the earth is warming given that he is a conservative Republican?
\item Does it appear that whether or not a respondent believes the earth is warming is independent of their party and ideology? Explain your reasoning.
\item What is the probability that a randomly chosen respondent is a moderate/liberal Republican given that he does not believe that the earth is warming? 
\end{parts}
}{}

% 18

\eoce{\qt{Weight and health coverage, Part II} Exercise~\ref{healthCovBMI} introduced a contingency table summarizing the relationship between weight status, which is determined based on body mass index (BMI), and health coverage for a sample of 428,638 Americans. In the table below, the counts have been replaced by relative frequencies (probability estimates).

\begin{center}
\begin{tabular}{ll  ccc  c} 
			&	\multicolumn{1}{c}{}	& \multicolumn{3}{c}{\textit{Weight Status}} & \\ 
\cline{3-5}
			&		& Neither overweight 	& Overweight 	& Obese	&   \\
			&		& nor obese (BMI $<$ 25)&(25 $\le$ BMI $<$ 30) & (BMI $\ge$ 30) & Total \\
\cline{2-6}
\textit{Health}	&Yes 	& 0.3145	 	& 0.3306	 	& 0.2503	 		& 0.8954\\
\textit{Coverage}&No 	& 0.0352 		& 0.0358 		& 0.0336			& 0.1046 \\
\cline{2-6}
			&Total	& 0.3497		&0.3664		& 0.2839			& 1.0000
\end{tabular}
\end{center}

\begin{parts}
\item What is the probability that a randomly chosen individual is obese?
\item What is the probability that a randomly chosen individual is obese given that he has health coverage?
\item What is the probability that a randomly chosen individual is obese given that he doesn't have health coverage?
\item Do being overweight and having health coverage appear to be independent?
\end{parts}
}{}

% 19

\eoce{\qt{Burger preferences} A 2010 SurveyUSA poll asked 500 Los Angeles residents, ``What is the best hamburger place in Southern California? Five Guys Burgers? In-N-Out Burger? Fat Burger? Tommy's Hamburgers? Umami Burger? Or somewhere else?'' The distribution of responses by gender is shown below. \footfullcite{burgers}
\begin{center}
\begin{tabular}{l p{4cm} r r r }
&						& \multicolumn{2}{c}{\textit{Gender}} \\
\cline{3-4}
&								& Male	& Female 	& Total\\
\cline{2-5}
& Five Guys Burgers					&5		&6	 	& 11	\\
& In-N-Out Burger					&162	&181	& 343 \\
\textit{Best} & Fat Burger				&10		&12	 	& 22 \\
\textit{hamburger} & Tommy's Hamburgers	&27		&27	 	& 54	\\ 
\textit{place} & Umami Burger			&5		&1	 	& 6 \\
& Other							&26		&20	 	& 46 \\
& Not Sure						&13		&5	 	& 18 \\
\cline{2-5}
&Total							&248	&252	& 500
\end{tabular}
\end{center}
\begin{parts}
\item What is the probability that a randomly chosen male likes In-N-Out the best?
\item What is the probability that a randomly chosen female likes In-N-Out the best?
\item What is the probability that a man and a woman who are dating both like In-N-Out the best? Note any assumption you make and evaluate whether you think that assumption is reasonable.
\item What is the probability that a randomly chosen person likes Umami best or that person is female?
\end{parts}
}{}

% 20

\eoce{\qt{Assortative mating} Assortative mating is a nonrandom mating pattern where individuals with similar genotypes and/or phenotypes mate with one another more frequently than what would be expected under a random mating pattern. Researchers studying this topic collected data on eye colors of  204 Scandinavian men and their female partners. The table below summarizes the results. For simplicity, we only include heterosexual relationships in this exercise. \footfullcite{Laeng:2007}
\begin{center}
\begin{tabular}{ll  ccc c} 
							&			& \multicolumn{3}{c}{\textit{Partner (female)}} \\
\cline{3-5}
							&			& Blue 	& Brown	& Green 	& Total	\\
\cline{2-6}
							&Blue 		& 78	 	& 23		& 13		& 114 	\\
\multirow{2}{*}{\textit{Self (male)}}	&Brown		& 19	 	& 23 	 	& 12		& 54 \\
							&Green		& 11	 	& 9 	 	& 16		& 36 \\
\cline{2-6}	
							&Total		& 108	& 55		& 41		& 204
\end{tabular}
\end{center}
\begin{parts}
\item What is the probability that a randomly chosen male respondent or his partner has blue eyes?
\item What is the probability that a randomly chosen male respondent with blue eyes has a partner with blue eyes? 
\item What is the probability that a randomly chosen male respondent with brown eyes has a partner with blue eyes? What about the probability of a randomly chosen male respondent with green eyes having a partner with blue eyes?
\item Does it appear that the eye colors of male respondents and their partners are independent? Explain your reasoning.
\end{parts}
}{}

% 21

\eoce{\qt{Drawing box plots\label{constructingBoxPlots}} After an introductory statistics course, 80\% of students can successfully construct box plots. Of those who can construct box plots, 86\% passed, while only 65\% of those students who could not construct box plots passed.
\begin{parts}
\item Construct a tree diagram of this scenario.
\item Calculate the probability that a student is able to construct a box plot if it is known that he passed.
\end{parts}
}{}

% 22

\eoce{\qt{Predisposition for thrombosis} A genetic test is used to determine if people have a predisposition for \textit{thrombosis}, which is the formation of a blood clot inside a blood vessel that obstructs the flow of blood through the circulatory system. It is believed that 3\% of people actually have this predisposition. The genetic test is 99\% accurate if a person actually has the predisposition, meaning that the probability of a positive test result when a person actually has the predisposition is 0.99. The test is 98\% accurate if a person does not have the predisposition. What is the probability that a randomly selected person who tests positive for the predisposition by the test actually has the predisposition?
}{}

% 23

\eoce{\qt{HIV in Swaziland} Swaziland has the highest HIV prevalence in the world: 25.9\% of this country's population is infected with HIV.\footfullcite{ciaFactBookHIV:2012} The ELISA test is one of the first and most accurate tests for HIV. For those who carry HIV, the ELISA test is 99.7\% accurate. For those who do not carry HIV, the test is 92.6\% accurate. If an individual from Swaziland has tested positive, what is the probability that he carries HIV?
}{}

% 24

\eoce{\qt{Exit poll} Edison Research gathered exit poll results from several sources for the Wisconsin recall election of Scott Walker. They found that 53\% of the respondents voted in favor of Scott Walker. Additionally, they estimated that of those who did vote in favor for Scott Walker, 37\% had a college degree, while 44\% of those who voted against Scott Walker had a college degree. Suppose we randomly sampled a person who participated in the exit poll and found that he had a college degree. What is the probability that he voted in favor of Scott Walker?\footfullcite{data:scott}
}{}

% 25

\eoce{\qt{It's never lupus} Lupus is a medical phenomenon where antibodies that are supposed to attack foreign cells to prevent infections instead see plasma proteins as foreign bodies, leading to a high risk of blood clotting. It is believed that 2\% of the population suffer from this disease. The test is 98\% accurate if a person actually has the disease. The test is 74\% accurate if a person does not have the disease. 

There is a line from the Fox television show \emph{House} that is often used after a patient tests positive for lupus: ``It's never lupus." Do you think there is truth to this statement? Use appropriate probabilities to support your answer.
}{}

% 26

\eoce{\qt{Twins} About 30\% of human twins are identical, and the rest are fraternal. Identical twins are necessarily the same sex -- half are males and the other half are females. One-quarter of fraternal twins are both male, one-quarter both female, and one-half are mixes: one male, one female. You have just become a parent of twins and are told they are both girls. Given this information, what is the probability that they are identical?
}{}


%_________________
\subsection{Sampling from a small population}

% 27

\eoce{\qt{Urns and marbles, Part I\label{urnWithMarbles}} Imagine you have an urn containing 5 red, 3 blue, and 2 orange marbles in it. 
\begin{parts}
\item What is the probability that the first marble you draw is blue?
\item Suppose you drew a blue marble in the first draw. If drawing with replacement, what is the probability of drawing a blue marble in the second draw?
\item Suppose you instead drew an orange marble in the first draw. If drawing with replacement, what is the probability of drawing a blue marble in the second draw?
\item If drawing with replacement, what is the probability of drawing two blue marbles in a row?
\item When drawing with replacement, are the draws independent? Explain.
\end{parts}
}{}

% 28

\eoce{\qt{Socks in a drawer} In your sock drawer you have 4 blue, 5 gray, and 3 black socks. Half asleep one morning you grab 2 socks at random and put them on. Find the probability you end up wearing
\begin{parts}
\item 2 blue socks
\item no gray socks
\item at least 1 black sock
\item a green sock
\item matching socks
\end{parts}
}{}


% 29

\eoce{\qt{Urns and marbles, Part II} Imagine you have an urn containing 5 red, 3 blue, and 2 orange marbles.
\begin{parts}
\item Suppose you draw a marble and it is blue. If drawing without replacement, what is the probability the next is also blue?
\item Suppose you draw a marble and it is orange, and then you draw a second marble without replacement. What is the probability this second marble is blue?
\item If drawing without replacement, what is the probability of drawing two blue marbles in a row?
\item When drawing without replacement, are the draws independent? Explain.
\end{parts}
}{}

% 30
\textB{\pagebreak}

\eoce{\qt{Books on a bookshelf} The table below shows the distribution of books on a bookcase based on whether they are nonfiction or fiction and hardcover or paperback. \vspace{-2.5mm}
\begin{center}
\begin{tabular}{ll  cc c} 
							&			& \multicolumn{2}{c}{\textit{Format}} \\
\cline{3-4}
							&			& Hardcover 	& Paperback 	& Total	\\
\cline{2-5}
\multirow{2}{*}{\textit{Type}}		&Fiction 		& 13	 		& 59			& 72 	\\
							&Nonfiction	& 15	 		& 8 	 		& 23 \\
\cline{2-5}	
							&Total		& 28			& 67			& 95 \\
\cline{2-5}
\end{tabular}
\end{center} \vspace{-2.5mm}
\begin{parts}
\item Find the probability of drawing a hardcover book first then a paperback fiction book second when drawing without replacement.
\item Determine the probability of drawing a fiction book first and then a hardcover book second, when drawing without replacement.
\item Calculate the probability of the scenario in part~(b), except this time complete the calculations under the scenario where the first book is placed back on the bookcase before randomly drawing the second book.
\item The final answers to parts~(b) and~(c) are very similar. Explain why this is the case.
\end{parts}
}{}

% 31

\eoce{\qt{Student outfits} In a classroom with 24 students, 7 students are wearing jeans, 4 are wearing shorts, 8 are wearing skirts, and the rest are wearing leggings. If we randomly select 3 students without replacement, what is the probability that one of the selected students is wearing leggings and the other two are wearing jeans? Note that these are mutually exclusive clothing options.
}{}

% 32

\eoce{\qt{The birthday problem} Suppose we pick three people at random. For each of the following questions, ignore the special case where someone might be born on February 29th, and assume that births are evenly distributed throughout the year.
\begin{parts}
\item What is the probability that the first two people share a birthday? 
\item What is the probability that at least two people share a birthday?
\end{parts}
}{}


%_________________
\subsection{Random variables}

% 33

\eoce{\qt{College smokers} At a university, 13\% of students smoke.
\begin{parts}
\item Calculate the expected number of smokers in a random sample of 100 students from this university.
\item The university gym opens at 9am on Saturday mornings. One Saturday morning at 8:55am there are 27 students outside the gym waiting for it to open. Should you use the same approach from part (a) to calculate the expected number of smokers among these 27 students?
\end{parts}
}{}

% 34

\eoce{\qt{Card game} Consider the following card game with a well-shuffled deck of cards. If you draw a red card, you win nothing. If you get a spade, you win \$5. For any club, you win \$10 plus an extra \$20 for the ace of clubs.
\begin{parts}
\item Create a probability model for the amount you win at this game. Also, find the expected winnings for a single game and the standard deviation of the winnings.
\item What is the maximum amount you would be willing to pay to play this game? Explain.
\end{parts}
}{}

% 35

\eoce{\qt{Another card game} In a new card game, you start with a well-shuffled full deck and draw 3 cards without replacement. If you draw 3 hearts, you win \$50. If you draw 3 black cards, you win \$25. For any other draws, you win nothing.
\begin{parts}
\item Create a probability model for the amount you win at this game, and find the expected winnings. Also compute the standard deviation of this distribution.
\item If the game costs \$5 to play, what would be the expected value and standard deviation of the net profit (or loss)? \textit{(Hint: profit = winnings $-$ cost; $X-5$)}
\item If the game costs \$5 to play, should you play this game? Explain.
\end{parts}
}{}

% 36

\eoce{\qtq{Is it worth it} Andy is always looking for ways to make money fast. Lately, he has been trying to make money by gambling. Here is the game he is considering playing: The game costs \$2 to play. He draws a card from a deck. If he gets a number card (2-10), he wins nothing. For any face card (jack, queen or king), he wins \$3. For any ace, he wins \$5, and he wins an \textit{extra} \$20 if he draws the ace of clubs.
\begin{parts}
\item Create a probability model and find Andy's expected profit per game.
\item Would you recommend this game to Andy as a good way to make money? Explain.
\end{parts}
}{}

% 37

\eoce{\qt{Portfolio return} A portfolio's value increases by 18\% during a financial boom and by 9\% during normal times. It decreases by 12\% during a recession. What is the expected return on this portfolio if each scenario is equally likely?
}{}

% 38

\eoce{\qt{A game of roulette, Part I\label{roulette}} The game of roulette involves spinning a wheel with 38 slots: 18 red, 18 black, and 2 green. A ball is spun onto the wheel and will eventually land in a slot, where each slot has an equal chance of capturing the ball. Gamblers can place bets on red or black. If the ball lands on their color, they double their money. If it lands on another color, they lose their money. Suppose you bet \$1 on red. What's the expected value and standard deviation of your winnings?
}{}

% 39

\eoce{\qt{A game of roulette, Part II} Exercise~\ref{roulette} describes winnings on a game of roulette.
\begin{parts}
\item Suppose you play roulette and bet \$3 on a single round. What is the expected value and standard deviation of your total winnings?
\item Suppose you bet \$1 in three different rounds. What is the expected value and standard deviation of your total winnings?
\item How do your answers to parts (a) and (b) compare? What does this say about the riskiness of the two games?
\end{parts}
}{}

% 40

\eoce{\qt{Baggage fees\label{americanAir}} An airline charges the following baggage fees: \$25 for the first bag and \$35 for the second. Suppose 54\% of passengers have no checked luggage, 34\% have one piece of checked luggage and 12\% have two pieces. We suppose a negligible portion of people check more than two bags.
\begin{parts}
\item Build a probability model, compute the average revenue per passenger, and compute the corresponding standard deviation.
\item About how much revenue should the airline expect for a flight of 120 passengers? With what standard deviation? Note any assumptions you make and if you think they are justified.
\end{parts}
}{}

% 41

\eoce{\qt{Dodgers vs. Padres} You and your friend decide to bet on the Major League Baseball game happening one evening between the Los Angeles Dodgers and the San Diego Padres. Suppose current statistics indicate that the Dodgers have a 0.46 probability of winning this game against the Padres. If your friend bets you \$5 that the Dodgers will win, how much would you need to bet on the Padres to make this a fair game?
}{}

% 42

\eoce{\qt{Selling on Ebay} Marcie has been tracking the following two items on Ebay:
\begin{itemize}
\item A textbook that sells for an average of \$110 with a standard deviation of \$4.
\item Mario Kart for the Nintendo Wii, which sells for an average of \$38 with a standard deviation of \$5.
\end{itemize}
\begin{parts}
\item Marcie wants to sell the video game and buy the textbook. How much net money (profits - losses) would she expect to make or spend? Also compute the standard deviation of how much she would make or spend.
\item Lucy is selling the textbook on Ebay for a friend, and her friend is giving her a 10\% commission (Lucy keeps 10\% of the revenue). How much money should she expect to make? With what standard deviation?
\end{parts}
}{}

% 43

\eoce{\qt{Cost of breakfast} Sally gets a cup of coffee and a muffin every day for breakfast from one of the many coffee shops in her neighborhood. She picks a coffee shop each morning at random and independently of previous days. The average price of a cup of coffee is \$1.40 with a standard deviation of 30\textcent (\$0.30), the average price of a muffin is \$2.50 with a standard deviation of 15\textcent, and the two prices are independent of each other.
\begin{parts}
\item What is the mean and standard deviation of the amount she spends on breakfast daily?
\item What is the mean and standard deviation of the amount she spends on breakfast weekly (7~days)?
\end{parts}
}{}

% 44

\eoce{\qt{Ice cream} Ice cream usually comes in 1.5 quart boxes (48 fluid ounces), and ice cream scoops hold about 2 ounces. However, there is some variability in the amount of ice cream in a box as well as the amount of ice cream scooped out. We represent the amount of ice cream in the box as $X$ and the amount scooped out as $Y$. Suppose these random variables have the following means, standard deviations, and variances:
\begin{center}
\begin{tabular}{l ccc}
\hline
	& mean & SD & variance \\
\hline
$X$	& 48	   & 1		& 1		\\
$Y$ & 2	   & 0.25	& 0.0625	\\
\hline
\end{tabular}
\end{center}
\begin{parts}
\item An entire box of ice cream, plus 3 scoops from a second box is served at a party. How much ice cream do you expect to have been served at this party? What is the standard deviation of the amount of ice cream served?
\item How much ice cream would you expect to be left in the box after scooping out one scoop of ice cream? That is, find the expected value of $X-Y$. What is the standard deviation of the amount left in the box?
\item Using the context of this exercise, explain why we add variances when we subtract one random variable from another.
\end{parts}
}{}


%_________________
\subsection{Continuous distributions}

% 45

\eoce{\qt{Cat weights\label{catsBodyWeights}} The histogram shown \textB{below} represents the weights (in kg) of 47 female and 97 male cats. \footfullcite{cats} \\
\begin{minipage}[c]{0.4\textwidth}
\begin{parts}
\item What fraction of these cats weigh less than 2.5 kg?
\item What fraction of these cats weigh between 2.5 and 2.75 kg?
\item What fraction of these cats weigh between 2.75 and 3.5 kg?
\end{parts} \vspace{27mm}
\end{minipage}
\begin{minipage}[c]{0.05\textwidth}
$\:$ 
\end{minipage}
\begin{minipage}[c]{0.55\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{02/figures/eoce/cats/cats_bodyWeight}
\end{center}
\end{minipage}
}{}

% 46
\textB{\pagebreak}

\eoce{\qt{Income and gender} The relative frequency table below displays the distribution of annual total personal income (in 2009 inflation-adjusted dollars) for a representative sample of 96,420,486 Americans. These data come from the American Community Survey for 2005-2009. This sample is comprised of 59\% males and 41\% females. \footfullcite{acsIncome2005-2009} \\

\noindent\begin{minipage}[c]{0.60\textwidth}
\begin{parts}
\item Describe the distribution of total personal income.
\item What is the probability that a randomly chosen US resident makes less than \$50,000 per year?
\item What is the probability that a randomly chosen US resident makes less than \$50,000 per year and is female? Note any assumptions you make.
\item The same data source indicates that 71.8\% of females make less than \$50,000 per year. Use this value to determine whether or not the assumption you made in part (c) is valid.
\end{parts} 
\end{minipage}
\begin{minipage}[c]{0.4\textwidth}
{\small
\begin{center}
\begin{tabular}{lr}
  \hline
\multicolumn{1}{c}{\textit{Income}}		& \multicolumn{1}{c}{\textit{Total}} \\
  \hline
\$1 to \$9,999 or loss	&2.2\%	\\
\$10,000 to \$14,999		&4.7\%	\\
\$15,000 to \$24,999		&15.8\%	\\
\$25,000 to \$34,999		&18.3\%	\\
\$35,000 to \$49,999		&21.2\%	\\
\$50,000 to \$64,999		&13.9\%	\\
\$65,000 to \$74,999		&5.8\%	\\
\$75,000 to \$99,999		&8.4\%	\\
\$100,000 or more		&9.7\%	\\
   \hline
\end{tabular}
\end{center}
}
\end{minipage} \\
}{}



\chapter{Multiple and logistic regression}
\label{multipleRegressionAndANOVA}
\label{multipleAndLogisticRegression}

The principles of simple linear regression lay the foundation for more sophisticated regression methods used in a wide range of challenging settings. In Chapter~\ref{multipleAndLogisticRegression}, we explore multiple regression, which introduces the possibility of more than one predictor, and logistic regression, a technique for predicting categorical outcomes with two possible categories.

\section{Introduction to multiple regression}
\label{introductionToMultipleRegression}

\index{multiple regression|(}

Multiple regression extends simple two-variable regression to the case that still has one response but many predictors (denoted $x_1$, $x_2$, $x_3$, ...). The method is motivated by scenarios where many variables may be simultaneously connected to an output.

\index{data!mario\_kart|(}

We will consider Ebay auctions of a video game called \emph{Mario Kart} for the Nintendo Wii. The outcome variable of interest is the total price of an auction, which is the highest bid plus the shipping cost. We will try to determine how total price is related to each characteristic in an auction while simultaneously controlling for other variables. For instance, all other characteristics held constant, are longer auctions associated with higher or lower prices? And, on average, how much more do buyers tend to pay for additional Wii wheels (plastic steering wheels that attach to the Wii controller) in auctions? Multiple regression will help us answer these and other questions.

The data set \data{mario\_\hspace{0.3mm}kart} includes results from 141 auctions.\footnote{Diez DM, Barr CD, and \c{C}etinkaya-Rundel M. 2012. \emph{openintro}: OpenIntro data sets and supplemental functions. \href{http://cran.r-project.org/web/packages/openintro}{cran.r-project.org/web/packages/openintro}.} Four observations from this data set are shown in Table~\ref{marioKartDataMatrix}, and descriptions for each variable are shown in Table~\ref{marioKartVariables}. Notice that the condition and stock photo variables are indicator variables\index{indicator variable}. For instance, the \var{cond\_\hspace{0.3mm}new} variable takes value 1 if the game up for auction is new and 0 if it is used. Using indicator variables in place of category names allows for these variables to be directly used in regression. See Section~\ref{categoricalPredictorsWithTwoLevels} for additional details. Multiple regression also allows for categorical variables with many levels, though we do not have any such variables in this analysis, and we save these details for a second or third course.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrlr}
  \hline
 & price & cond\_\hspace{0.3mm}new & stock\_\hspace{0.3mm}photo & duration & wheels \\ 
  \hline
1 & 51.55 &   1 & 1 & 3 &   1 \\ 
  2 & 37.04 &  0 &  1 & 7 &   1 \\ 
$\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ &$\vdots$ \\
  140 & 38.76 &  0 &  0 & 7 &   0 \\ 
  141 & 54.51 &  1 &  1 & 1 &   2 \\ 
   \hline
\end{tabular}
\caption{Four observations from the \data{mario\_\hspace{0.3mm}kart} data set.}
\label{marioKartDataMatrix}
\end{table}
%library(openintro); data(marioKart); d <- marioKart[marioKart$totalPr < 100,]; row.names(d) <- NULL; d

\begin{table}
\centering\small
\begin{tabular}{lp{9.5cm}}
\hline
{\bf variable} & {\bf description} \\
\hline
\var{price} & final auction price plus shipping costs, in US dollars \\
\var{cond\_\hspace{0.3mm}new} & a coded two-level categorical variable, which takes value \resp{1} when the game is new and \resp{0} if the game is used \\
\var{stock\_\hspace{0.3mm}photo} & a coded two-level categorical variable, which takes value \resp{1} if the primary photo used in the auction was a stock photo and \resp{0} if the photo was unique to that auction \\
\var{duration} & the length of the auction, in days, taking values from 1 to 10 \\
\var{wheels} & the number of Wii wheels included with the auction (a \emph{Wii wheel} is a plastic racing wheel that holds the Wii controller and is an optional but helpful accessory for playing Mario Kart) \\
\hline
\end{tabular}
\caption{Variables and their descriptions for the \data{mario\_\hspace{0.3mm}kart} data set.}
\label{marioKartVariables}
\end{table}

\subsection{A single-variable model for the Mario Kart data}
\label{twoSingleVariableModelsForMarioKartData}

Let's fit a linear regression model with the game's condition as a predictor of auction price. The model may be written as
\begin{align*}
\widehat{price} &= 42.87 + 10.90\times cond\_\hspace{0.3mm}new
\end{align*}
Results of this model are shown in Table~\ref{singleVarModelsForPriceUsingCond} and a scatterplot for price versus game condition is shown in Figure~\ref{marioKartSingle}.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & 42.8711 & 0.8140 & 52.67 & 0.0000 \\ 
  cond\_\hspace{0.3mm}new & 10.8996 & 1.2583 & 8.66 & 0.0000 \\ 
   \hline
   &&&\multicolumn{2}{r}{$df=139$}
\end{tabular}
\caption{Summary of a linear model for predicting auction price based on game condition.}
\label{singleVarModelsForPriceUsingCond}
\end{table}
% library(openintro); library(xtable); data(marioKart); d <- marioKart[marioKart$totalPr < 100,]; d$cond <- relevel(d$cond, "used"); xtable(lm(d$totalPr ~ d$cond)); xtable(lm(d$totalPr ~ d$duration))

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{06/figures/marioKartSingle/marioKartSingle}
\caption{Scatterplot of the total auction price against the game's condition. The least squares line is also shown.}
\label{marioKartSingle}
\end{figure}

\begin{exercise}
Examine Figure~\ref{marioKartSingle}. Does the linear model seem \mbox{reasonable}?\footnote{Yes. Constant variability, nearly normal residuals, and linearity all appear reasonable.}
\end{exercise}

\textA{\pagebreak}

\begin{example}{Interpret the coefficient for the game's condition in the model. Is this coefficient significantly different from 0?}
Note that \var{cond\_\hspace{0.3mm}new} is a two-level categorical variable that takes value 1 when the game is new and value 0 when the game is used. So 10.90 means that the model predicts an extra \$10.90 for those games that are new versus those that are used. (See Section~\ref{categoricalPredictorsWithTwoLevels} for a review of the interpretation for two-level categorical predictor variables.) Examining the regression output in Table~\ref{singleVarModelsForPriceUsingCond}, we can see that the p-value for \var{cond\_\hspace{0.3mm}new} is very close to zero, indicating there is strong evidence that the coefficient is different from zero when using this simple one-variable model.
\end{example}

\subsection{Including and assessing many variables in a model}
\label{includingAndAssessingManyVariablesInAModel}

Sometimes there are underlying structures or relationships between predictor variables. For instance, new games sold on Ebay tend to come with more Wii wheels, which may have led to higher prices for those auctions. We would like to fit a model that includes all potentially important variables simultaneously. This would help us evaluate the relationship between a predictor variable and the outcome while controlling for the potential influence of other variables. This is the strategy used in \term{multiple regression}. While we remain cautious about making any causal interpretations using multiple regression, such models are a common first step in providing evidence of a causal connection.

We want to construct a model that accounts for not only the game condition, as in Section~\ref{twoSingleVariableModelsForMarioKartData}, but simultaneously accounts for three other variables: \var{stock\_\hspace{0.3mm}photo}, \var{duration}, and \var{wheels}.
\begin{align}
\widehat{\var{price}}
	&= \beta_0 + \beta_1\times \var{cond\_\hspace{0.3mm}new} +
		\beta_2\times \var{stock\_\hspace{0.3mm}photo} \notag \\
	&\qquad\  + \beta_3 \times  \var{duration} +
		\beta_4 \times  \var{wheels} \notag \\
\hat{y}
	&= \beta_0 + \beta_1 x_1 + \beta_2 x_2 +
		\beta_3 x_3 + \beta_4 x_4
\label{eqForMultipleRegrOfTotalPrForAllPredictors}
\end{align}
In this equation, $y$ represents the total price, $x_1$ indicates whether the game is new, $x_2$ indicates whether a stock photo was used, $x_3$ is the duration of the auction, and $x_4$ is the number of Wii wheels included with the game. Just as with the single predictor case, a multiple regression model may be missing important components or it might not precisely represent the relationship between the outcome and the available explanatory variables. While no model is perfect, we wish to explore the possibility that this one may fit the data reasonably well.

We estimate the parameters $\beta_0$, $\beta_1$, ..., $\beta_4$ in the same way as we did in the case of a single predictor. We select $b_0$, $b_1$, ..., $b_4$ that minimize the sum of the squared residuals:
\begin{align}\label{sumOfSqResInMultRegr}
SSE = e_1^2 + e_2^2 + \dots + e_{141}^2
	= \sum_{i=1}^{141} e_i^2
	 = \sum_{i=1}^{141} \left(y_i - \hat{y}_i\right)^2
\end{align}
Here there are 141 residuals, one for each observation. We typically use a computer to minimize the sum in Equation~\eqref{sumOfSqResInMultRegr} and compute point estimates, as shown in the sample output in Table~\ref{outputForMultipleRegrOutputForAllPredictors}. Using this output, we identify the point estimates $b_i$ of each $\beta_i$, just as we did in the one-predictor case.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & 36.2110 & 1.5140 & 23.92 & 0.0000 \\ 
  cond\_\hspace{0.3mm}new & 5.1306 & 1.0511 & 4.88 & 0.0000 \\ 
  stock\_\hspace{0.3mm}photo & 1.0803 & 1.0568 & 1.02 & 0.3085 \\ 
  duration & -0.0268 & 0.1904 & -0.14 & 0.8882 \\ 
  wheels & 7.2852 & 0.5547 & 13.13 & 0.0000 \\ 
   \hline
   &&&\multicolumn{2}{r}{$df=136$}
\end{tabular}
\caption{Output for the regression model where \var{price} is the outcome and \var{cond\_\hspace{0.3mm}new}, \var{stock\_\hspace{0.3mm}photo}, \var{duration}, and \var{wheels} are the predictors.}
\label{outputForMultipleRegrOutputForAllPredictors}
\end{table}
%library(openintro); library(xtable); data(marioKart); d <- marioKart[marioKart$totalPr < 100,]; d$cond <- relevel(d$cond, "used"); g <-lm(totalPr ~ cond + stockPhoto + duration + wheels, d)

\begin{termBox}{\tBoxTitle{Multiple regression model}
A multiple regression model is a linear model with many predictors. In general, we write the model as
\begin{align*}
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k %+ \epsilon
\end{align*}
when there are $k$ predictors. We often estimate the $\beta_i$ parameters using a computer.\vspace{1mm}}
\end{termBox}

\begin{exercise} \label{eqForMultipleRegrOfTotalPrForAllPredictorsWithCoefficients}
Write out the model in Equation~\eqref{eqForMultipleRegrOfTotalPrForAllPredictors} using the point estimates from Table~\ref{outputForMultipleRegrOutputForAllPredictors}. How many predictors are there in this model?\footnote{$\hat{y} = 36.21 + 5.13x_1 + 1.08x_2 - 0.03x_3 + 7.29x_4$, and there are $k=4$ predictor variables.}
\end{exercise}

\begin{exercise}
What does $\beta_4$, the coefficient of variable $x_4$ (Wii wheels), represent? What is the point estimate of $\beta_4$?\footnote{It is the average difference in auction price for each additional Wii wheel included when holding the other variables constant. The point estimate is $b_4 = 7.29$.}
\end{exercise}

\begin{exercise} \label{computeMultipleRegressionResidualForMarioKart}
Compute the residual of the first observation in Table~\vref{marioKartDataMatrix} using the equation identified in Guided Practice~\ref{eqForMultipleRegrOfTotalPrForAllPredictorsWithCoefficients}. \footnote{$e_i = y_i - \hat{y_i} = 51.55 - 49.62 = 1.93$, where 49.62 was computed using the variables values from the observation and the equation identified in Guided Practice~\ref{eqForMultipleRegrOfTotalPrForAllPredictorsWithCoefficients}.}
\end{exercise}

\begin{example}{We estimated a coefficient for \var{cond\_\hspace{0.3mm}new} in Section~\ref{twoSingleVariableModelsForMarioKartData} of $b_1 = 10.90$ with a standard error of $SE_{b_1} = 1.26$ when using simple linear regression. Why might there be a difference between that estimate and the one in the multiple regression setting?} \label{colinearityOfCondNewAndStockPhoto}
If we examined the data carefully, we would see that some predictors are correlated. For instance, when we estimated the connection of the outcome \var{price} and predictor \var{cond\_\hspace{0.3mm}new} using simple linear regression, we were unable to control for other variables like the number of Wii wheels included in the auction. That model was biased by the confounding variable \var{wheels}. When we use both variables, this particular underlying and unintentional bias is reduced or eliminated (though bias from other confounding variables may still remain).
\end{example}

Example~\ref{colinearityOfCondNewAndStockPhoto} describes a common issue in multiple regression: correlation among predictor variables. We say the two predictor variables are \term{collinear} (pronounced as \emph{co-linear}) when they are correlated, and this collinearity complicates model estimation. While it is impossible to prevent collinearity from arising in observational data, experiments are usually designed to prevent predictors from being collinear.

\begin{exercise}
The estimated value of the intercept is 36.21, and one might be tempted to make some interpretation of this coefficient, such as, it is the model's predicted price when each of the variables take value zero: the game is used, the primary image is not a stock photo, the auction duration is zero days, and there are no wheels included. Is there any value gained by making this interpretation?\footnote{Three of the variables (\var{cond\_\hspace{0.3mm}new}, \var{stock\_\hspace{0.3mm}photo}, and \var{wheels}) do take value 0, but the auction duration is always one or more days. If the auction is not up for any days, then no one can bid on it! That means the total auction price would always be zero for such an auction; the interpretation of the intercept in this setting is not insightful.}
\end{exercise}


\subsection{Adjusted $R^2$ as a better estimate of explained variance}

\index{adjusted r squared@adjusted $R^2$ ($R_{adj}^2$)|(}

We first used $R^2$ in Section~\ref{fittingALineByLSR} to determine the amount of variability in the response that was explained by the model:
\begin{align*}
R^2 = 1 - \frac{\text{variability in residuals}}{\text{variability in the outcome}}
	= 1 - \frac{Var(e_i)}{Var(y_i)}
\end{align*}
where $e_i$ represents the residuals of the model and $y_i$ the outcomes. This equation remains valid in the multiple regression framework, but a small enhancement can often be even more informative.

\begin{exercise} \label{computeUnadjustedR2ForAllPredictorsInMarioKart}
The variance of the residuals for the model given in Guided Practice~\ref{computeMultipleRegressionResidualForMarioKart} is 23.34, and the variance of the total price in all the auctions is 83.06. Calculate $R^2$ for this model.\footnote{$R^2 = 1 - \frac{23.34}{83.06} = 0.719$.}
\end{exercise}

This strategy for estimating $R^2$ is acceptable when there is just a single variable. However, it becomes less helpful when there are many variables. The regular $R^2$ is actually a biased estimate of the amount of variability explained by the model. To get a better estimate, we use the adjusted $R^2$.

\begin{termBox}{\tBoxTitle{Adjusted $\mathbf{R^2}$ as a tool for model assessment}
The \termsub{adjusted $\mathbf{R^2}$}{adjusted r squared@adjusted $R^2$ ($R_{adj}^2$)} is computed as
\begin{align*}
R_{adj}^{2} = 1-\frac{Var(e_i) / (n-k-1)}{Var(y_i) / (n-1)}
	= 1-\frac{Var(e_i)}{Var(y_i)} \times \frac{n-1}{n-k-1}
\end{align*}
where $n$ is the number of cases used to fit the model and $k$ is the number of predictor variables in the model.}
\end{termBox}

Because $k$ is never negative, the adjusted $R^2$ will be smaller -- often times just a little smaller -- than the unadjusted $R^2$. The reasoning behind the adjusted $R^2$ lies in the \termsub{degrees of freedom}{degrees of freedom (df)!regression} associated with each variance.\footnote{In multiple regression, the degrees of freedom associated with the variance of the estimate of the residuals is $n-k-1$, not $n-1$. For instance, if we were to make predictions for new data using our current model, we would find that the unadjusted $R^2$ is an overly optimistic estimate of the reduction in variance in the response, and using the degrees of freedom in the adjusted $R^2$ formula helps correct this bias.}

\begin{exercise}
There were $n=141$ auctions in the \data{mario\_\hspace{0.3mm}kart} data set and $k=4$ predictor variables in the model. Use $n$, $k$, and the variances from Guided Practice~\ref{computeUnadjustedR2ForAllPredictorsInMarioKart} to calculate $R_{adj}^2$ for the Mario Kart model.\footnote{$R_{adj}^2 = 1 - \frac{23.34}{83.06}\times \frac{141-1}{141-4-1} = 0.711$.}
\end{exercise}

\begin{exercise}
Suppose you added another predictor to the model, but the variance of the errors $Var(e_i)$ didn't go down. What would happen to the $R^2$? What would happen to the adjusted $R^2$?\hspace{0.7mm}\footnote{The unadjusted $R^2$ would stay the same and the adjusted $R^2$ would go down.}
\end{exercise}

\index{adjusted r squared@adjusted $R^2$ ($R_{adj}^2$)|)}


%__________________
\section{Model selection}
\label{modelSelection}

\index{model selection|(}

The best model is not always the most complicated. Sometimes including variables that are not evidently important can actually reduce the accuracy of predictions. In this section we discuss model selection strategies, which will help us eliminate from the model variables that are less important.

In this section, and in practice, the model that includes all available explanatory variables is often referred to as the \term{full model}. Our goal is to assess whether the full model is the best model. If it isn't, we want to identify a smaller model that is preferable.

\textA{\pagebreak}

\subsection{Identifying variables in the model that may not be helpful}

Table~\ref{outputForMultipleRegrOutputForAllPredictors2} provides a summary of the regression output for the full model for the auction data. The last column of the table lists p-values that can be used to assess hypotheses of the following form:
\begin{itemize}
\setlength{\itemsep}{0mm}
\item[$H_0$:] $\beta_i = 0$ when the other explanatory variables are included in the model.
\item[$H_A$:] $\beta_i \neq 0$ when the other explanatory variables are included in the model.
\end{itemize}

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & 36.2110 & 1.5140 & 23.92 & 0.0000 \\ 
  cond\_\hspace{0.3mm}new & 5.1306 & 1.0511 & 4.88 & 0.0000 \\ 
  stock\_\hspace{0.3mm}photo & 1.0803 & 1.0568 & 1.02 & 0.3085 \\ 
  duration & -0.0268 & 0.1904 & -0.14 & 0.8882 \\ 
  wheels & 7.2852 & 0.5547 & 13.13 & 0.0000 \\ 
   \hline
  \vspace{-3.6mm} & & & & \\
\multicolumn{3}{l}{$R_{adj}^2 = 0.7108$}&\multicolumn{2}{r}{$df=136$}
\end{tabular}
\caption{The fit for the full regression model, including the adjusted $R^2$.}
\label{outputForMultipleRegrOutputForAllPredictors2}
\end{table}

\begin{example}{The coefficient of \var{cond\_\hspace{0.3mm}new} has a $t$ test statistic of $T=4.88$ and a p-value for its corresponding hypotheses ($H_0: \beta_1 = 0$, $H_A: \beta_1 \neq 0$) of about zero. How can this be interpreted?}
If we keep all the other variables in the model and add no others, then there is strong evidence that a game's condition (new or used) has a real relationship with the total auction price.
\end{example}

\begin{example}{Is there strong evidence that using a stock photo is related to the total auction price?}
The $t$ test statistic for \var{stock\_\hspace{0.3mm}photo} is $T=1.02$ and the p-value is about 0.31. After accounting for the other predictors, there is not strong evidence that using a stock photo in an auction is related to the total price of the auction. We might consider removing the \var{stock\_\hspace{0.3mm}photo} variable from the model.
\end{example}

\begin{exercise}
Identify the p-values for both the \var{duration} and \var{wheels} variables in the model. Is there strong evidence supporting the connection of these variables with the total price in the model?\footnote{The p-value for the auction duration is 0.8882, which indicates that there is not statistically significant evidence that the duration is related to the total auction price when accounting for the other variables. The p-value for the Wii wheels variable is about zero, indicating that this variable is associated with the total auction price.}
\end{exercise}

There is not statistically significant evidence that either the stock photo or duration variables contribute meaningfully to the model. Next we consider common strategies for pruning such variables from a model.

\begin{tipBox}{\tipBoxTitle{Using adjusted $R^2$ instead of p-values for model selection}
The adjusted $R^2$ may be used as an alternative to p-values for model selection, where a higher adjusted $R^2$ represents a better model fit. For instance, we could compare two models using their adjusted $R^2$, and the model with the higher adjusted $R^2$ would be preferred. This approach tends to include more variables in the final model when compared to the p-value approach.}
\end{tipBox}


\subsection{Two model selection strategies}

Two common strategies for adding or removing variables in a multiple regression model are called \emph{backward-selection} and \emph{forward-selection}. These techniques are often referred to as \term{stepwise} model selection strategies, because they add or delete one variable at a time as they ``step'' through the candidate predictors. We will discuss these strategies in the context of the p-value approach. Alternatively, we could have employed an $R_{adj}^2$ approach.

The \term{backward-elimination} strategy starts with the model that includes all potential predictor variables. Variables are eliminated one-at-a-time from the model until only variables with statistically significant p-values remain. The strategy within each elimination step is to drop the variable with the largest p-value, refit the model, and reassess the inclusion of all variables.

\begin{example}{Results corresponding to the \emph{full model} for the \data{mario\_\hspace{0.3mm}kart} data are shown in Table~\ref{outputForMultipleRegrOutputForAllPredictors2}. How should we proceed under the backward-elimination strategy?} \label{backwardEliminationExampleWMarioKartData}
There are two variables with coefficients that are not statistically different from zero: \var{stock\_\hspace{0.3mm}photo} and \var{duration}. We first drop the \var{duration} variable since it has a larger corresponding p-value, \emph{then we refit the model}. A regression summary for the new model is shown in Table~\ref{outputForMultipleRegrOutputForAllPredictorsButDuration}.

In the new model, there is not strong evidence that the coefficient for \var{stock\_\hspace{0.3mm}photo} is different from zero, even though the p-value decreased slightly, and the other p-values remain very small. Next, we again eliminate the variable with the largest non-significant p-value, \var{stock\_\hspace{0.3mm}photo}, and refit the model. The updated regression summary is shown in Table~\ref{outputForMultipleRegrOutputForAllPredictorsButDurationAndStockPhoto}.

In the latest model, we see that the two remaining predictors have statistically significant coefficients with p-values of about zero. Since there are no variables remaining that could be eliminated from the model, we stop. The final model includes only the \var{cond\_\hspace{0.3mm}new} and \var{wheels} variables in predicting the total auction price:
\begin{align*}
\hat{y} \ &= \ b_0 + b_1x_1 + b_4x_4 \\
	&= \ 36.78 + 5.58x_1 + 7.23x_4
\end{align*}
where $x_1$ represents \var{cond\_\hspace{0.3mm}new} and $x_4$ represents \var{wheels}.

An alternative to using p-values in model selection is to use the adjusted $R^2$. At each elimination step, we refit the model without each of the variables up for potential elimination. For example, in the first step, we would fit four models, where each would be missing a different predictor. If one of these smaller models has a higher adjusted $R^2$ than our current model, we pick the smaller model with the largest adjusted $R^2$. We continue in this way until removing variables does not increase~$R_{adj}^2$. Had we used the adjusted $R^2$ criteria, we would have kept the \var{stock\_\hspace{0.3mm}photo} variable along with the \var{cond\_\hspace{0.3mm}new} and \var{wheels} variables.
\end{example}

\begin{table}[t]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & 36.0483 & 0.9745 & 36.99 & 0.0000 \\ 
  cond\_\hspace{0.3mm}new & 5.1763 & 0.9961 & 5.20 & 0.0000 \\ 
  stock\_\hspace{0.3mm}photo & 1.1177 & 1.0192 & 1.10 & 0.2747 \\ 
  wheels & 7.2984 & 0.5448 & 13.40 & 0.0000 \\ 
   \hline
  \vspace{-3.6mm} & & & & \\
\multicolumn{3}{l}{$R_{adj}^2 = 0.7128$}&&\small$df=137$
\end{tabular}
\caption{The output for the regression model where \var{price} is the outcome and the duration variable has been eliminated from the model.}
\label{outputForMultipleRegrOutputForAllPredictorsButDuration}
\end{table}

\begin{table}[t]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & 36.7849 & 0.7066 & 52.06 & 0.0000 \\ 
  cond\_\hspace{0.3mm}new & 5.5848 & 0.9245 & 6.04 & 0.0000 \\ 
  wheels & 7.2328 & 0.5419 & 13.35 & 0.0000 \\ 
   \hline
  \vspace{-3.6mm} & & & & \\
\multicolumn{3}{l}{$R_{adj}^2 = 0.7124$}&&\small$df=138$
\end{tabular}
\caption{The output for the regression model where \var{price} is the outcome and the duration and stock photo variables have been eliminated from the model.}
\label{outputForMultipleRegrOutputForAllPredictorsButDurationAndStockPhoto}
\end{table}

Notice that the p-value for \var{stock\_\hspace{0.3mm}photo} changed a little from the full model (0.309) to the model that did not include the \var{duration} variable (0.275). It is common for p-values of one variable to change, due to collinearity, after eliminating a different variable. This fluctuation emphasizes the importance of refitting a model after each variable elimination step. The p-values tend to change dramatically when the eliminated variable is highly correlated with another variable in the model.

The \term{forward-selection} strategy is the reverse of the backward-elimination technique. Instead of eliminating variables one-at-a-time, we add variables one-at-a-time until we cannot find any variables that present strong evidence of their importance in the model.

\begin{example}{Construct a model for the \data{mario\_\hspace{0.3mm}kart} data set using the forward-selection strategy.}\label{forwardEliminationExampleWMarioKartData}
We start with the model that includes no variables. Then we fit each of the possible models with just one variable. That is, we fit the model including just the \var{cond\_\hspace{0.3mm}new} predictor, then the model including just the \var{stock\_\hspace{0.3mm}photo} variable, then a model with just \var{duration}, and a model with just \var{wheels}. Each of the four models (yes, we fit four models!) provides a p-value for the coefficient of the predictor variable. Out of these four variables, the \var{wheels} variable had the smallest p-value. Since its p-value is less than 0.05 (the p-value was smaller than 2e-16), we add the Wii wheels variable to the model. Once a variable is added in forward-selection, it will be included in all models considered as well as the final model.

Since we successfully found a first variable to add, we consider adding another. We fit three new models: (1) the model including just the \var{cond\_\hspace{0.3mm}new} and \var{wheels} variables (output in Table~\ref{outputForMultipleRegrOutputForAllPredictorsButDurationAndStockPhoto}), (2) the model including just the \var{stock\_\hspace{0.3mm}photo} and \var{wheels} variables, and (3) the model including only the \var{duration} and \var{wheels} variables. Of these models, the first had the lowest p-value for its new variable (the p-value corresponding to \var{cond\_\hspace{0.3mm}new} was 1.4e-08). Because this p-value is below 0.05, we add the \var{cond\_\hspace{0.3mm}new} variable to the model. Now the final model is guaranteed to include both the condition and wheels variables.

We must then repeat the process a third time, fitting two new models: (1) the model including the \var{stock\_\hspace{0.3mm}photo}, \var{cond\_\hspace{0.3mm}new}, and \var{wheels} variables (output in Table~\ref{outputForMultipleRegrOutputForAllPredictorsButDuration}) and (2) the model including the \var{duration}, \var{cond\_\hspace{0.3mm}new}, and \var{wheels} variables. The p-value corresponding to \var{stock\_\hspace{0.3mm}photo} in the first model (0.275) was smaller than the p-value corresponding to \var{duration} in the second model (0.682). However, since this smaller p-value was not below 0.05, there was not strong evidence that it should be included in the model. Therefore, neither variable is added and we are finished.

The final model is the same as that arrived at using the backward-selection strategy.
\end{example}

\begin{example}{As before, we could have used the $R_{adj}^2$ criteria instead of examining p-values in selecting variables for the model. Rather than look for variables with the smallest p-value, we look for the model with the largest $R_{adj}^2$. What would the result of forward-selection be using the adjusted $R^2$ approach?}
Using the forward-selection strategy, we start with the model with no predictors. Next we look at each model with a single predictor. If one of these models has a larger $R_{adj}^2$ than the model with no variables, we use this new model. We repeat this procedure, adding one variable at a time, until we cannot find a model with a larger $R_{adj}^2$. If we had done the forward-selection strategy using $R_{adj}^2$, we would have arrived at the model including \var{cond\_\hspace{0.3mm}new}, \var{stock\_\hspace{0.3mm}photo}, and \var{wheels}, which is a slightly larger model than we arrived at using the p-value approach and the same model we arrived at using the adjusted $R^2$ and backwards-elimination.
\end{example}

\begin{termBox}{\tBoxTitle{Model selection strategies}
The backward-elimination strategy begins with the largest model and eliminates variables one-by-one until we are satisfied that all remaining variables are important to the model. The forward-selection strategy starts with no variables included in the model, then it adds in variables according to their importance until no other important variables are found.}
\end{termBox}

There is no guarantee that the backward-elimination and forward-selection strategies will arrive at the same final model using the p-value or adjusted $R^2$ methods. If the backwards-elimination and forward-selection strategies are both tried and they arrive at different models, choose the model with the larger $R_{adj}^2$ as a tie-breaker; other tie-break options exist but are beyond the scope of this book.

It is generally acceptable to use just one strategy, usually backward-elimination with either the p-value or adjusted $R^2$ criteria. However, before reporting the model results, we must verify the model conditions are reasonable.

\index{model selection|)}


%%%%%
\textA{\newpage}
\section{Checking model assumptions using graphs}
\label{multipleRegressionModelAssumptions}

\index{multiple regression!model assumptions|(}

Multiple regression methods using the model
\begin{align*}
\hat{y} &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots + \beta_kx_k
\end{align*}
generally depend on the following four assumptions:
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item the residuals of the model are nearly normal,
\item the variability of the residuals is nearly constant,
\item the residuals are independent, and
\item each variable is linearly related to the outcome.
\end{enumerate}
Simple and effective plots can be used to check each of these assumptions. We will consider the model for the auction data that uses the game condition and number of wheels as predictors. The plotting methods presented here may also be used to check the conditions for the models introduced in Chapter~\ref{linRegrForTwoVar}.

\begin{description}
\item[Normal probability plot.] A normal probability plot of the residuals is shown in Figure~\ref{mkDiagnosticNormalQuantilePlot}. While the plot exhibits some minor irregularities, there are no outliers that might be cause for concern. In a normal probability plot for residuals, we tend to be most worried about residuals that appear to be outliers, since these indicate long tails in the distribution of residuals.

\begin{figure}
\centering
\includegraphics[width=0.71\textwidth]{06/figures/marioKartDiagnostics/mkDiagnosticNormalQuantilePlot}
\caption{A normal probability plot of the residuals is helpful in identifying observations that might be outliers.}
\label{mkDiagnosticNormalQuantilePlot}
\end{figure}

\item[Absolute values of residuals against fitted values.] A plot of the absolute value of the residuals against their corresponding fitted values ($\hat{y}_i$) is shown in Figure~\ref{mkDiagnosticEvsAbsF}. This plot is helpful to check the condition that the variance of the residuals is approximately constant. We don't see any obvious deviations from constant variance in this example.

\begin{figure}
\centering
\includegraphics[width=0.72\textwidth]{06/figures/marioKartDiagnostics/mkDiagnosticEvsAbsF}
\caption{Comparing the absolute value of the residuals against the fitted values ($\hat{y}_i$) is helpful in identifying deviations from the constant variance assumption.}
\label{mkDiagnosticEvsAbsF}
\end{figure}

\item[Residuals in order of their data collection.] A plot of the residuals in the order their corresponding auctions were observed is shown in Figure~\ref{mkDiagnosticInOrder}. Such a plot is helpful in identifying any connection between cases that are close to one another, e.g. we could look for declining prices over time or if there was a time of the day when auctions tended to fetch a higher price. Here we see no structure that indicates a problem.\footnote{An especially rigorous check would use \term{time series} methods. For instance, we could check whether consecutive residuals are correlated. Doing so with these residuals yields no statistically significant correlations.}

\begin{figure}
\centering
\includegraphics[width=0.72\textwidth]{06/figures/marioKartDiagnostics/mkDiagnosticInOrder}
\caption{Plotting residuals in the order that their corresponding observations were collected helps identify connections between successive observations. If it seems that consecutive observations tend to be close to each other, this indicates the independence assumption of the observations would fail.}
\label{mkDiagnosticInOrder}
\end{figure}

\item[Residuals against each predictor variable.] We consider a plot of the residuals against the \var{cond\_\hspace{0.3mm}new} variable and the residuals against the \var{wheels} variable. These plots are shown in Figure~\ref{mkDiagnosticEvsVariables}. For the two-level condition variable, we are guaranteed not to see any remaining trend, and instead we are checking that the variability doesn't fluctuate across groups. In this example, when we consider the residuals against the \var{wheels} variable, we see some possible structure. There appears to be curvature in the residuals, indicating the relationship is probably not linear.

\begin{figure}
\centering
\includegraphics[width=0.85\textwidth]{06/figures/marioKartDiagnostics/mkDiagnosticEvsVariables}
\caption{In the two-level variable for the game's condition, we check for differences in distribution shape or variability. For numerical predictors, we also check for trends or other structure. We see some slight bowing in the residuals against the \var{wheels} variable.}
\label{mkDiagnosticEvsVariables}
\end{figure}

\end{description}

It is necessary to summarize diagnostics for any model fit. If the diagnostics support the model assumptions, this would improve credibility in the findings. If the diagnostic assessment shows remaining underlying structure in the residuals, we should try to adjust the model to account for that structure. If we are unable to do so, we may still report the model but must also note its shortcomings. In the case of the auction data, we report that there may be a nonlinear relationship between the total price and the number of wheels included for an auction. This information would be important to buyers and sellers; omitting this information could be a setback to the very people who the model might assist.

\begin{tipBox}{\tipBoxTitle[]{``All models are wrong, but some are useful'' -George E.P. Box}
The truth is that no model is perfect. However, even imperfect models can be useful. Reporting a flawed model can be reasonable so long as we are clear and report the model's shortcomings.}
\end{tipBox}

\begin{caution}
{Don't report results when assumptions are grossly violated}
{While there is a little leeway in model assumptions, don't go too far. If model assumptions are very clearly violated, consider a new model, even if it means learning more statistical methods or hiring someone who can help.}
\end{caution}

\begin{tipBox}{\tipBoxTitle{Confidence intervals in multiple regression}
\index{confidence interval}
Confidence intervals for coefficients in multiple regression can be computed using the same formula as in the single predictor model:
\begin{align*}
b_i \ \pm\ t_{df}^{\star}SE_{b_{i}}
\end{align*}
where $t_{df}^{\star}$ is the appropriate $t$ value corresponding to the confidence level and model degrees of freedom, $df=n-k-1$.}
\index{multiple regression!model assumptions|)}
\index{data!mario\_kart|)}
\index{multiple regression|)}
\end{tipBox}


%__________________
\section{Logistic regression}
\label{logisticRegression}

\index{logistic regression|(}

In this section we introduce \term{logistic regression} as a tool for building models when there is a categorical response variable with two levels. Logistic regression is a type of \term{generalized linear model} (GLM) for response variables where regular multiple regression does not work very well. In particular, the response variable in these settings often takes a form where residuals look completely different from the normal distribution.

GLMs can be thought of as a two-stage modeling approach. We first model the response variable using a probability distribution, such as the binomial or Poisson distribution. Second, we model the parameter of the distribution using a collection of predictors and a special form of multiple regression.

\index{data!email|(}

In Section~\ref{logisticRegression} we will revisit the \data{email} data set from Chapter~\ref{introductionToData}. These emails were collected from a single email account, and we will work on developing a basic spam filter using these data. The response variable, \var{spam}, has been encoded to take value~0 when a message is not spam and~1 when it is spam. Our task will be to build an appropriate model that classifies messages as spam or not spam using email characteristics coded as predictor variables. While this model will not be the same as those used in large-scale spam filters, it shares many of the same features. 


\textA{\newpage}

\subsection{Email data}

The \data{email} data set was first presented in Chapter~\ref{introductionToData} with a relatively small number of variables. In fact, there are many more variables available that might be useful for classifying spam. Descriptions of these variables are presented in Table~\ref{emailVariables}. The \var{spam} variable will be the outcome, and the other 10 variables will be the model predictors. While we have limited the predictors used in this section to be categorical variables (where many are represented as indicator variables), numerical predictors may also be used in logistic regression. See the footnote for an additional discussion on this topic.\footnote{Recall from Chapter~\ref{linRegrForTwoVar} that if outliers are present in predictor variables, the corresponding observations may be especially influential on the resulting model. This is the motivation for omitting the numerical variables, such as the number of characters and line breaks in emails, that we saw in Chapter~\ref{introductionToData}. These variables exhibited extreme skew. We could resolve this issue by transforming these variables (e.g. using a log-transformation), but we will omit this further investigation for brevity.}

\begin{table}
\centering\small
\begin{tabular}{lp{10.5cm}}
\hline
{\bf variable} & {\bf description} \\
\hline
\var{spam} & Specifies whether the message was spam. \\
\var{to\_\hspace{0.3mm}multiple} & An indicator variable for if more than one person was listed in the \emph{To} field of the email.  \\
\var{cc} & An indicator for if someone was CCed on the email. \\
\var{attach} & An indicator for if there was an attachment, such as a document or image.   \\
\var{dollar} & An indicator for if the word ``dollar'' or dollar symbol (\$) appeared in the email.  \\
\var{winner} & An indicator for if the word ``winner'' appeared in the email message.  \\
\var{inherit} & An indicator for if the word ``inherit'' (or a variation, like ``inheritance'') appeared in the email.  \\
\var{password} & An indicator for if the word ``password'' was present in the email.  \\
\var{format} & Indicates if the email contained special formatting, such as bolding, tables, or links    \\
\var{re\_\hspace{0.3mm}subj} & Indicates whether ``Re:'' was included at the start of the email subject.   \\
\var{exclaim\_\hspace{0.3mm}subj} & Indicates whether any exclamation point was included in the email subject.    \\
\hline
\end{tabular}
\caption{Descriptions for 11 variables in the \data{email} data set. Notice that all of the variables are indicator\index{indicator variable} variables, which take the value 1 if the specified characteristic is present and 0 otherwise.}
\label{emailVariables}
\end{table}


\subsection{Modeling the probability of an event}
\label{modelingTheProbabilityOfAnEvent}

\begin{tipBox}{\tipBoxTitle{Notation for a logistic regression model}
The outcome variable for a GLM is denoted by $Y_i$, where the index $i$ is used to represent observation $i$. In the email application, $Y_i$ will be used to represent whether email $i$ is spam ($Y_i=1$) or not ($Y_i=0$). \vspace{3mm}

The predictor variables are represented as follows: $x_{1,i}$ is the value of variable 1 for observation $i$, $x_{2,i}$ is the value of variable 2 for observation $i$, and so on.}
\end{tipBox}

Logistic regression is a generalized linear model where the outcome is a two-level categorical variable. The outcome, $Y_i$, takes the value 1 (in our application, this represents a spam message) with probability $p_i$ and the value 0 with probability $1-p_i$. It~is the probability $p_i$ that we model in relation to the predictor variables.

The logistic regression model relates the probability an email is spam ($p_i$) to the predictors $x_{1,i}$, $x_{2,i}$, ..., $x_{k,i}$ through a framework much like that of multiple regression:
\begin{align}
transformation(p_{i}) = \beta_0 + \beta_1x_{1,i} + \beta_2 x_{2,i} + \cdots \beta_k x_{k,i}
\label{linkTransformationEquation}
\end{align}
We want to choose a transformation in Equation~\eqref{linkTransformationEquation} that makes practical and mathematical sense. For example, we want a transformation that makes the range of possibilities on the left hand side of Equation~\eqref{linkTransformationEquation} equal to the range of possibilities for the right hand side; if there was no transformation for this equation, the left hand side could only take values between 0 and 1, but the right hand side could take values outside of this range. A common transformation for $p_i$ is the \term{logit transformation}, which may be written as
\begin{align*}
logit(p_i) = \log_{e}\left( \frac{p_i}{1-p_i} \right)
\end{align*}
The logit transformation is shown in Figure~\ref{logitTransformationFigureHoriz}. Below, we rewrite Equation~\eqref{linkTransformationEquation} using the logit transformation of $p_i$:
\begin{align*}
\log_{e}\left( \frac{p_i}{1-p_i} \right)
	= \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_k x_{k,i}
\end{align*}
In our spam example, there are 10 predictor variables, so $k = 10$. This model isn't very intuitive, but it still has some resemblance to multiple regression, and we can fit this model using software. In fact, once we look at results from software, it will start to feel like we're back in multiple regression, even if the interpretation of the coefficients is more complex.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{06/figures/logitTransformationFigureHoriz/logitTransformationFigureHoriz}
\caption{Values of $p_i$ against values of $logit(p_i)$.}
\label{logitTransformationFigureHoriz}
\end{figure}

\textA{\pagebreak}

\begin{example}{Here we create a spam filter with a single predictor: \var{to\_\hspace{0.3mm}multiple}. This variable indicates whether more than one email address was listed in the \emph{To} field of the email. The following logistic regression model was fit using statistical software:
\begin{align*}
\log\left( \frac{p_i}{1-p_i} \right) = -2.12 - 1.81\times\text{\var{to\_\hspace{0.3mm}multiple}}
\end{align*}
%library(openintro); data(email); tm <- email$to_multiple > 0; g <- glm(email$spam ~ tm, family=binomial); summary(g); a <- exp(-2.12); a/(1+a); a <- exp(-2.12-1.81); a/(1+a)
If an email is randomly selected and it has just one address in the \emph{To} field, what is the probability it is spam? What if more than one address is listed in the \emph{To} field?}\label{logisticExampleWithToMultiple}
If there is only one email in the \emph{To} field, then \var{to\_\hspace{0.3mm}multiple} takes value 0 and the right side of the model equation equals -2.12. Solving for $p_i$: $\frac{e^{-2.12}}{1 + e^{-2.12}} = 0.11$. Just as we labeled a fitted value of $y_i$ with a ``hat'' in single-variable and multiple regression, we will do the same for this probability: $\hat{p}_i = 0.11$.

If there is more than one address listed in the \emph{To} field, then the right side of the model equation is $-2.12 - 1.81\times1 = -3.93$, which corresponds to a probability $\hat{p}_i = 0.02$.

Notice that we could examine -2.12 and -3.93 in Figure~\ref{logitTransformationFigureHoriz} to estimate the probability before formally calculating the value.
\end{example}

To convert from values on the regression-scale (e.g. -2.12 and -3.93 in Example~\ref{logisticExampleWithToMultiple}), use the following formula, which is the result of solving for $p_i$ in the regression model:
\begin{align*}
p_i
	= \frac{e^{\beta_0 + \beta_1 x_{1,i}+\cdots+\beta_k x_{k,i}}}
		{\ 1\ \ +\ \ e^{\beta_0 + \beta_1 x_{1,i}+\cdots+\beta_k x_{k,i}}\ }
\end{align*}
As with most applied data problems, we substitute the point estimates for the parameters (the $\beta_i$) so that we may make use of this formula. In Example~\ref{logisticExampleWithToMultiple}, the probabilities were calculated as
\begin{align*}
&\frac{\ e^{-2.12}\ }{\ 1\ +\ e^{-2.12}\ } = 0.11 && \frac{\ e^{-2.12 - 1.81}\ }{\ 1\ +\ e^{-2.12 - 1.81}\ } = 0.02
\end{align*}
While the information about whether the email is addressed to multiple people is a helpful start in classifying email as spam or not, the probabilities of 11\% and 2\% are not dramatically different, and neither provides very strong evidence about which particular email messages are spam. To get more precise estimates, we'll need to include many more variables in the model.

We used statistical software to fit the logistic regression model with all ten predictors described in Table~\ref{emailVariables}. Like multiple regression, the result may be presented in a summary table, which is shown in Table~\ref{emailLogisticModelResults}. The structure of this table is almost identical to that of multiple regression; the only notable difference is that the p-values are calculated using the normal distribution rather than the $t$ distribution.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & -0.8362 & 0.0962 & -8.69 & 0.0000 \\ 
  to\_\hspace{0.3mm}multiple & -2.8836 & 0.3121 & -9.24 & 0.0000 \\ 
  winner & 1.7038 & 0.3254 & 5.24 & 0.0000 \\ 
  format & -1.5902 & 0.1239 & -12.84 & 0.0000 \\ 
  re\_\hspace{0.3mm}subj & -2.9082 & 0.3708 & -7.84 & 0.0000 \\ 
  exclaim\_\hspace{0.3mm}subj & 0.1355 & 0.2268 & 0.60 & 0.5503 \\ 
  cc & -0.4863 & 0.3054 & -1.59 & 0.1113 \\ 
  attach & 0.9790 & 0.2170 & 4.51 & 0.0000 \\ 
  dollar & -0.0582 & 0.1589 & -0.37 & 0.7144 \\ 
  inherit & 0.2093 & 0.3197 & 0.65 & 0.5127 \\ 
  password & -1.4929 & 0.5295 & -2.82 & 0.0048 \\ 
\hline
\end{tabular}
\caption{Summary table for the full logistic regression model for the spam filter example.}
\label{emailLogisticModelResults}
\end{table}
% library(openintro); ?email # run example
% library(xtable); xtable(g)

Just like multiple regression, we could trim some variables from the model using the p-value. Using backwards elimination with a p-value cutoff of 0.05 (start with the full model and trim the predictors with p-values greater than 0.05), we ultimately eliminate the \var{exclaim\_\hspace{0.3mm}subj}, \var{dollar}, \var{inherit}, and \var{cc} predictors. The remainder of this section will rely on this smaller model, which is summarized in Table~\ref{emailLogisticReducedModel}.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
  \vspace{-3.7mm} & & & & \\
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\ 
  \hline
  \vspace{-3.8mm} & & & & \\
(Intercept) & -0.8595 & 0.0910 & -9.44 & 0.0000 \\ 
  to\_\hspace{0.3mm}multiple & -2.8372 & 0.3092 & -9.18 & 0.0000 \\ 
  winner & 1.7370 & 0.3218 & 5.40 & 0.0000 \\ 
  format & -1.5569 & 0.1207 & -12.90 & 0.0000 \\ 
  re\_\hspace{0.3mm}subj & -3.0482 & 0.3630 & -8.40 & 0.0000 \\ 
  attach & 0.8643 & 0.2042 & 4.23 & 0.0000 \\ 
  password & -1.4871 & 0.5290 & -2.81 & 0.0049 \\ 
\hline
\end{tabular}
\caption{Summary table for the logistic regression model for the spam filter, where variable selection has been performed.}
\label{emailLogisticReducedModel}
\end{table}
% library(openintro); ?email # run example
% g <- glm(spam ~ to_multiple + winner + format + re_subj + attach + password, data=e, family=binomial); xtable(g)

\begin{exercise}
Examine the summary of the reduced model in Table~\ref{emailLogisticReducedModel}, and in particular, examine the \var{to\_\hspace{0.3mm}multiple} row. Is the point estimate the same as we found before, -1.81, or is it different? Explain why this might be.\footnote{The new estimate is different: -2.87. This new value represents the estimated coefficient when we are also accounting for other variables in the logistic regression model.}
\end{exercise}

Point estimates will generally change a little -- and sometimes a lot -- depending on which other variables are included in the model. This is usually due to colinearity in the predictor variables. We previously saw this in the Ebay auction example when we compared the coefficient of \var{cond\_\hspace{0.3mm}new} in a single-variable model and the corresponding coefficient in the multiple regression model that used three additional variables (see Sections~\ref{twoSingleVariableModelsForMarioKartData} and~\ref{includingAndAssessingManyVariablesInAModel}).

\begin{example}{Spam filters are built to be automated, meaning a piece of software is written to collect information about emails as they arrive, and this information is put in the form of variables. These variables are then put into an algorithm that uses a statistical model, like the one we've fit, to classify the email. Suppose we write software for a spam filter using the reduced model shown in Table~\ref{emailLogisticReducedModel}. If an incoming email has the word ``winner'' in it, will this raise or lower the model's calculated probability that the incoming email is spam?} \label{exampleForSpamAndWinner}
The estimated coefficient of \var{winner} is positive (1.7370). A positive coefficient estimate in logistic regression, just like in multiple regression, corresponds to a positive association between the predictor and response variables when accounting for the other variables in the model. Since the response variable takes value 1 if an email is spam and 0 otherwise, the positive coefficient indicates that the presence of ``winner'' in an email raises the model probability that the message is spam.
\end{example}

\begin{example}{Suppose the same email from Example~\ref{exampleForSpamAndWinner} was in HTML format, meaning the \var{format} variable took value 1. Does this characteristic increase or decrease the probability that the email is spam according to the model?}\label{exampleForSpamAndFormat}
Since HTML corresponds to a value of 1 in the \var{format} variable and the coefficient of this variable is negative (-1.5569), this would lower the probability estimate returned from the model.
\end{example}

\subsection{Practical decisions in the email application}

Examples~\ref{exampleForSpamAndWinner} and~\ref{exampleForSpamAndFormat} highlight a key feature of logistic and multiple regression. In the spam filter example, some email characteristics will push an email's classification in the direction of spam while other characteristics will push it in the opposite direction.

If we were to implement a spam filter using the model we have fit, then each future email we analyze would fall into one of three categories based on the email's characteristics:
\begin{enumerate}
\item The email characteristics generally indicate the email is not spam, and so the resulting probability that the email is spam is quite low, say, under 0.05.
\item The characteristics generally indicate the email is spam, and so the resulting probability that the email is spam is quite large, say, over 0.95.
\item The characteristics roughly balance each other out in terms of evidence for and against the message being classified as spam. Its probability falls in the remaining range, meaning the email cannot be adequately classified as spam or not spam.
\end{enumerate}
If we were managing an email service, we would have to think about what should be done in each of these three instances. In an email application, there are usually just two possibilities: filter the email out from the regular inbox and put it in a ``spambox'', or let the email go to the regular inbox.

\begin{exercise}
The first and second scenarios are intuitive. If the evidence strongly suggests a message is not spam, send it to the inbox. If the evidence strongly suggests the message is spam, send it to the spambox. How should we handle emails in the third category?\footnote{In this particular application, we should err on the side of sending more mail to the inbox rather than mistakenly putting good messages in the spambox. So, in summary: emails in the first and last categories go to the regular inbox, and those in the second scenario go to the spambox.}
\end{exercise}

\begin{exercise}
Suppose we apply the logistic model we have built as a spam filter and that 100 messages are placed in the spambox over 3 months. If we used the guidelines above for putting messages into the spambox, about how many legitimate (non-spam) messages would you expect to find among the 100 messages?\footnote{First, note that we proposed a cutoff for the predicted probability of 0.95 for spam. In a worst case scenario, all the messages in the spambox had the minimum probability equal to about 0.95. Thus, we should expect to find about 5 or fewer legitimate messages among the 100 messages placed in the spambox.}
\end{exercise}

Almost any classifier will have some error. In the spam filter guidelines above, we have decided that it is okay to allow up to 5\% of the messages in the spambox to be real messages. If we wanted to make it a little harder to classify messages as spam, we could use a cutoff of 0.99. This would have two effects. Because it raises the standard for what can be classified as spam, it reduces the number of good emails that are classified as spam. However, it will also fail to correctly classify an increased fraction of spam messages. No matter the complexity and the confidence we might have in our model, these practical considerations are absolutely crucial to making a helpful spam filter. Without them, we could actually do more harm than good by using our statistical model.


\subsection{Diagnostics for the email classifier}

\begin{termBox}{\tBoxTitle{Logistic regression conditions}
There are two key conditions for fitting a logistic regression model: \vspace{-1.5mm}
\begin{enumerate}
\setlength{\itemsep}{0mm}
\item Each predictor $x_i$ is linearly related to logit$(p_i)$ if all other predictors are held constant.
%\item The model relating the parameter $p_i$ to the predictors $x_{1,i}$, $x_{2,i}$, ..., $x_{k,i}$ closely resembles the true relationship between the parameter and the predictors.
\item Each outcome $Y_i$ is independent of the other outcomes.
\end{enumerate}}
\end{termBox}

The first condition of the logistic regression model is not easily checked without a fairly sizable amount of data. Luckily, we have 3,921 emails in our data set! Let's first visualize these data by plotting the true classification of the emails against the model's fitted probabilities, as shown in Figure~\ref{logisticModelPredict}. The vast majority of emails (spam or not) still have fitted probabilities below 0.5.

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{06/figures/logisticModel/logisticModelPredict}
\caption{The predicted probability that each of the 3,912 emails is spam is classified by their grouping, spam or not. Noise (small, random vertical shifts) have been added to each point so that points with nearly identical values aren't plotted exactly on top of one another. This makes it possible to see more observations.}
\label{logisticModelPredict}
\end{figure}

This may at first seem very discouraging: we have fit a logistic model to create a spam filter, but no emails have a fitted probability of being spam above 0.75. Don't despair; we will discuss ways to improve the model through the use of better variables in Section~\ref{improvingTheSetOfVariablesForASpamFilter}.

We'd like to assess the quality of our model. For example, we might ask: if we look at emails that we modeled as having a 10\% chance of being spam, do we find about 10\% of them actually are spam? To help us out, we'll borrow an advanced statistical method called \term{natural splines} that estimates the local probability over the region 0.00 to 0.75 (the largest predicted probability was 0.73, so we avoid extrapolating). All you need to know about natural splines to understand what we are doing is that they are used to fit flexible lines rather than straight lines.

The curve fit using natural splines is shown in Figure~\ref{logisticModelSpline} as a solid black line. If the logistic model fits well, the curve should closely follow the dashed $y=x$ line. We have added shading to represent the confidence bound for the curved line to clarify what fluctuations might plausibly be due to chance. Even with this confidence bound, there are weaknesses in the first model assumption. The solid curve and its confidence bound dips below the dashed line from about 0.1 to 0.3, and then it drifts above the dashed line from about 0.35 to 0.55. These deviations indicate the model relating the parameter to the predictors does not closely resemble the true relationship.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{06/figures/logisticModel/logisticModelSpline}
\caption{The solid black line provides the empirical estimate of the probability for observations based on their predicted probabilities (confidence bounds are also shown for this line), which is fit using natural splines. A small amount of noise was added to the observations in the plot to allow more observations to be seen.}
\label{logisticModelSpline}
\end{figure}

We could evaluate the second logistic regression model assumption -- independence of the outcomes -- using the model residuals. The residuals for a logistic regression model are calculated the same way as with multiple regression: the observed outcome minus the expected outcome. For logistic regression, the expected value of the outcome is the fitted probability for the observation, and the residual may be written as
\begin{align*}
e_i = Y_i - \hat{p}_i
\end{align*}
We could plot these residuals against a variety of variables or in their order of collection, as we did with the residuals in multiple regression. However, since the model will need to be revised to effectively classify spam and you have already seen similar residual plots in Section~\ref{multipleRegressionModelAssumptions}, we won't investigate the residuals here.


\subsection{Improving the set of variables for a spam filter}
\label{improvingTheSetOfVariablesForASpamFilter}

If we were building a spam filter for an email service that managed many accounts (e.g. Gmail or Hotmail), we would spend much more time thinking about additional variables that could be useful in classifying emails as spam or not. We also would use transformations or other techniques that would help us include strongly skewed numerical variables as predictors.

Take a few minutes to think about additional variables that might be useful in identifying spam. Below is a list of variables we think might be useful:
\begin{enumerate}
\item[(1)] An indicator variable could be used to represent whether there was prior two-way correspondence with a message's sender. For instance, if you sent a message to john@example.com and then John sent you an email, this variable would take value 1 for the email that John sent. If you had never sent John an email, then the variable would be set to~0.
\item[(2)] A second indicator variable could utilize an account's past spam flagging information. The variable could take value 1 if the sender of the message has previously sent messages flagged as~spam.
\item[(3)] A third indicator variable could flag emails that contain links included in previous spam messages. If such a link is found, then set the variable to~1 for the email. Otherwise, set it to~0.
\end{enumerate}
The variables described above take one of two approaches. Variable (1) is specially designed to capitalize on the fact that spam is rarely sent between individuals that have two-way communication. Variables~(2) and~(3) are specially designed to flag common spammers or spam messages. While we would have to verify using the data that each of the variables is effective, these seem like promising ideas.

Table~\ref{emailTableOfSpamAnd} shows a contingency table for spam and also for the new variable described in~(1) above. If we look at the 1,090 emails where there was correspondence with the sender in the preceding 30 days, not one of these message was spam. This suggests variable~(1) would be very effective at accurately classifying some messages as not spam. With this single variable, we would be able to send about 28\% of messages through to the inbox with confidence that almost none are spam.

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
& \multicolumn{3}{c}{prior correspondence} & \\
\cline{2-4}
 & \ \hspace{5mm}\resp{no} & \ \hspace{8mm}\resp{yes} && \ \hspace{3mm}Total \\
\hline
\vspace{-3.8mm} & & & & \\
\resp{spam} &  367 &    0 &&  367 \\
\resp{not spam}\hspace{3mm}\  & 2464 & 1090 && 3554 \\
\hline
\vspace{-3.8mm} & & & & \\
Total & 2831 & 1090 && 3921 \\
\hline
\end{tabular}
\caption{A contingency table for \var{spam} and a new variable that represents whether there had been correspondence with the sender in the preceding 30~days.}
\label{emailTableOfSpamAnd}
\end{table}
%library(openintro); data(email); contTable(email[,c("spam", "sent_email")])

The variables described in (2) and (3) would provide an excellent foundation for distinguishing messages coming from known spammers or messages that take a known form of spam. To utilize these variables, we would need to build databases: one holding email addresses of known spammers, and one holding URLs found in known spam messages. Our access to such information is limited, so we cannot implement these two variables in this textbook. However, if we were hired by an email service to build a spam filter, these would be important next steps.

In addition to finding more and better predictors, we would need to create a customized logistic regression model for each email account. This may sound like an intimidating task, but its complexity is not as daunting as it may at first seem. We'll save the details for a statistics course where computer programming plays a more central role.

For what is the extremely challenging task of classifying spam messages, we have made a lot of progress. We have seen that simple email variables, such as the format, inclusion of certain words, and other circumstantial characteristics, provide helpful information for spam classification. Many challenges remain, from better understanding logistic regression to carrying out the necessary computer programming, but completing such a task is very nearly within your reach.

\index{data!email|)}
\index{logistic regression|)}



Probability
===========

Probability forms a foundation for statistics. You might already be
familiar with many aspects of probability, however, formalization of the
concepts is new for most. This chapter aims to introduce probability on
familiar terms using processes most people have seen before.

Defining probability {#basicsOfProbability}
--------------------

A "die", the singular of dice, is a cube with six faces numbered , , , ,
, and . What is the chance of getting when rolling a
die?[\[probOf1\]]{#probOf1 label="probOf1"} If the die is fair, then the
chance of a is as good as the chance of any other number. Since there
are six outcomes, the chance must be 1-in-6 or, equivalently, $1/6$.

What is the chance of getting a or in the next
roll?[\[probOf1Or2\]]{#probOf1Or2 label="probOf1Or2"} and constitute two
of the six equally likely possible outcomes, so the chance of getting
one of these two outcomes must be $2/6 = 1/3$.

What is the chance of getting either , , , , , or on the next
roll?[\[probOf123456\]]{#probOf123456 label="probOf123456"} 100%. The
outcome must be one of these numbers.

What is the chance of not rolling a ?[\[probNot2\]]{#probNot2
label="probNot2"} Since the chance of rolling a is $1/6$ or
$16.\bar{6}\%$, the chance of not rolling a must be
$100\% - 16.\bar{6}\%=83.\bar{3}\%$ or $5/6$.

Alternatively, we could have noticed that not rolling a is the same as
getting a , , , , or , which makes up five of the six equally likely
outcomes and has probability $5/6$.

Consider rolling two dice. If $1/6^{th}$ of the time the first die is a
and $1/6^{th}$ of those times the second die is a , what is the chance
of getting two s?[\[probOf2Ones\]]{#probOf2Ones label="probOf2Ones"} If
$16.\bar{6}$% of the time the first die is a and $1/6^{th}$ of *those*
times the second die is also a , then the chance that both dice are is
$(1/6)\times (1/6)$ or $1/36$.

### Probability

We use probability to build tools to describe and understand apparent
randomness. We often frame probability in terms of a giving rise to an .

  ------------- --------------- --------------
  Roll a die    $\rightarrow$   , , , , , or
  Flip a coin   $\rightarrow$   or
  ------------- --------------- --------------

Rolling a die or flipping a coin is a seemingly random process and each
gives rise to an outcome.

The of an outcome is the proportion of times the outcome would occur if
we observed the random process an infinite number of times.

Probability is defined as a proportion, and it always takes values
between 0 and 1 (inclusively). It may also be displayed as a percentage
between 0% and 100%.

Probability can be illustrated by rolling a die many times. Let
$\hat{p}_n$ be the proportion of outcomes that are after the first $n$
rolls. As the number of rolls increases, $\hat{p}_n$ will converge to
the probability of rolling a , $p = 1/6$.
Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"} shows
this convergence for 100,000 die rolls. The tendency of $\hat{p}_n$ to
stabilize around $p$ is described by the .

![The fraction of die rolls that are 1 at each stage in a simulation.
The proportion tends to get closer to the probability
$1/6 \approx 0.167$ as the number of rolls
increases.[]{label="dieProp"}](appendix-probability/figures/dieProp/dieProp){#dieProp
width="80%"}

As more observations are collected, the proportion $\hat{p}_n$ of
occurrences with a particular outcome converges to the probability $p$
of that outcome.

Occasionally the proportion will veer off from the probability and
appear to defy the Law of Large Numbers, as $\hat{p}_n$ does many times
in Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"}.
However, these deviations become smaller as the number of rolls
increases.

Above we write $p$ as the probability of rolling a . We can also write
this probability as $$\begin{aligned}
P(\text{rolling a \resp{1}})\end{aligned}$$ As we become more
comfortable with this notation, we will abbreviate it further. For
instance, if it is clear that the process is "rolling a die", we could
abbreviate $P($rolling a $)$ as $P($$)$.

[\[randomProcessExercise\]]{#randomProcessExercise
label="randomProcessExercise"} Random processes include rolling a die
and flipping a coin. (a) Think of another random process. (b) Describe
all the possible outcomes of that process. For instance, rolling a die
is a random process with potential outcomes , , \..., .[^1]

What we think of as random processes are not necessarily random, but
they may just be too difficult to understand exactly. The fourth example
in the footnote solution to Guided
Practice [\[randomProcessExercise\]](#randomProcessExercise){reference-type="ref"
reference="randomProcessExercise"} suggests a roommate's behavior is a
random process. However, even if a roommate's behavior is not truly
random, modeling her behavior as a random process can still be useful.

It can be helpful to model a process as random even if it is not truly
random.

### Disjoint or mutually exclusive outcomes

Two outcomes are called or if they cannot both happen. For instance, if
we roll a die, the outcomes and are disjoint since they cannot both
occur. On the other hand, the outcomes and "rolling an odd number" are
not disjoint since both occur if the outcome of the roll is a . The
terms *disjoint* and *mutually exclusive* are equivalent and
interchangeable.

Calculating the probability of disjoint outcomes is easy. When rolling a
die, the outcomes and are disjoint, and we compute the probability that
one of these outcomes will occur by adding their separate probabilities:
$$\begin{aligned}
P(\text{\resp{1} or \resp{2}}) = P(\text{\resp{1}})+P(\text{\resp{2}}) = 1/6 + 1/6 = 1/3\end{aligned}$$
What about the probability of rolling a , , , , , or ? Here again, all
of the outcomes are disjoint so we add the probabilities:
$$\begin{aligned}
&&P(\text{\resp{1} or \resp{2} or \resp{3} or \resp{4} or \resp{5} or \resp{6}}) \\
    &&\quad= P(\text{\resp{1}})+P(\text{\resp{2}})+P(\text{\resp{3}})+P(\text{\resp{4}})+P(\text{\resp{5}})+P(\text{\resp{6}}) \\
    &&\quad= 1/6 + 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 1.\end{aligned}$$ The
guarantees the accuracy of this approach when the outcomes are disjoint.

If $A_1$ and $A_2$ represent two disjoint outcomes, then the probability
that one of them occurs is given by $$\begin{aligned}
P(A_1\text{ or } A_2) = P(A_1) + P(A_2)\end{aligned}$$ If there are many
disjoint outcomes $A_1$, \..., $A_k$, then the probability that one of
these outcomes will occur is $$\begin{aligned}
P(A_1) + P(A_2) + \cdots + P(A_k)\end{aligned}$$

We are interested in the probability of rolling a , , or . (a) Explain
why the outcomes , , and are disjoint. (b) Apply the Addition Rule for
disjoint outcomes to determine $P($ or or $)$.[^2]

In the data set in
Chapter [\[introductionToData\]](#introductionToData){reference-type="ref"
reference="introductionToData"}, the variable described whether no
number (labeled ), only one or more small numbers (), or whether at
least one big number appeared in an email (). Of the 3,921 emails, 549
had no numbers, 2,827 had only one or more small numbers, and 545 had at
least one big number. (a) Are the outcomes , , and disjoint? (b)
Determine the proportion of emails with value and separately. (c) Use
the Addition Rule for disjoint outcomes to compute the probability a
randomly selected email from the data set has a number in it, small or
big.[^3]

Statisticians rarely work with individual outcomes and instead consider
or of outcomes. Let $A$ represent the event where a die roll results in
or and $B$ represent the event that the die roll is a or a . We write
$A$ as the set of outcomes $\{$, $\}$ and $B=\{$, $\}$. These sets are
commonly called . Because $A$ and $B$ have no elements in common, they
are disjoint events. $A$ and $B$ are represented in
Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"}.

![Three events, $A$, $B$, and $D$, consist of outcomes from rolling a
die. $A$ and $B$ are disjoint since they do not have any outcomes in
common.[]{label="disjointSets"}](appendix-probability/figures/disjointSets/disjointSets){#disjointSets
height="0.7in"}

The Addition Rule applies to both disjoint outcomes and disjoint events.
The probability that one of the disjoint events $A$ or $B$ occurs is the
sum of the separate probabilities: $$\begin{aligned}
P(A\text{ or }B) = P(A) + P(B) = 1/3 + 1/3 = 2/3\end{aligned}$$

\(a\) Verify the probability of event $A$, $P(A)$, is $1/3$ using the
Addition Rule. (b) Do the same for event $B$.[^4]

[\[exerExaminingDisjointSetsABD\]]{#exerExaminingDisjointSetsABD
label="exerExaminingDisjointSetsABD"} (a) Using
Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} as a reference, what outcomes are represented
by event $D$? (b) Are events $B$ and $D$ disjoint? (c) Are events $A$
and $D$ disjoint?[^5]

In Guided
Practice [\[exerExaminingDisjointSetsABD\]](#exerExaminingDisjointSetsABD){reference-type="ref"
reference="exerExaminingDisjointSetsABD"}, you confirmed $B$ and $D$
from Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} are disjoint. Compute the probability that
either event $B$ or event $D$ occurs.[^6]

### Probabilities when events are not disjoint

Let's consider calculations for two events that are not disjoint in the
context of a , represented in
Table [\[deckOfCards\]](#deckOfCards){reference-type="ref"
reference="deckOfCards"}. If you are unfamiliar with the cards in a
regular deck, please see the footnote.[^7]

  -- -- -- -- -- -- -- -- -- -- -- -- --
                                      
                                      
                                      
                                      
  -- -- -- -- -- -- -- -- -- -- -- -- --

  : Representations of the 52 unique cards in a
  deck.[]{label="deckOfCards"}

\(a\) What is the probability that a randomly selected card is a
diamond? (b) What is the probability that a randomly selected card is a
face card?[^8]

are useful when outcomes can be categorized as "in" or "out" for two or
three variables, attributes, or random processes. The Venn diagram in
Figure [1.3](#venn){reference-type="ref" reference="venn"} uses a circle
to represent diamonds and another to represent face cards. If a card is
both a diamond and a face card, it falls into the intersection of the
circles. If it is a diamond but not a face card, it will be in part of
the left circle that is not in the right circle (and so on). The total
number of cards that are diamonds is given by the total number of cards
in the diamonds circle: $10+3=13$. The probabilities are also shown
(e.g. $10/52 = 0.1923$).

![A Venn diagram for diamonds and face
cards.[]{label="venn"}](appendix-probability/figures/venn/venn){#venn
height="1.4in"}

Using the Venn diagram, verify $P($face card$) = 12/52=3/13$.[^9]

Let $A$ represent the event that a randomly selected card is a diamond
and $B$ represent the event that it is a face card. How do we compute
$P(A$ or $B)$? Events $A$ and $B$ are not disjoint -- the cards
$J\diamondsuit$, $Q\diamondsuit$, and $K\diamondsuit$ fall into both
categories -- so we cannot use the Addition Rule for disjoint events.
Instead we use the Venn diagram. We start by adding the probabilities of
the two events: $$\begin{aligned}
P(A) + P(B) = P({\color{redcards}\diamondsuit}) + P(\text{face card}) = 12/52 + 13/52
\label{overCountFaceDiamond}\end{aligned}$$ However, the three cards
that are in both events were counted twice, once in each probability. We
must correct this double counting: $$\begin{aligned}
P(A\text{ or } B) &=&P(\text{face card or }{\color{redcards}\diamondsuit})  \notag \\
 &=& P(\text{face card}) + P({\color{redcards}\diamondsuit}) - P(\text{face card and }{\color{redcards}\diamondsuit}) \label{diamondFace} \\
 &=& 12/52 + 13/52 - 3/52 \notag \\
 &=& 22/52 = 11/26 \notag\end{aligned}$$
Equation ([\[diamondFace\]](#diamondFace){reference-type="ref"
reference="diamondFace"}) is an example of the .

If $A$ and $B$ are any two events, disjoint or not, then the probability
that at least one of them will occur is $$\begin{aligned}
P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and }B)
\label{generalAdditionRule}\end{aligned}$$ where $P(A$ and $B)$ is the
probability that both events occur.

When we write "or" in statistics, we mean "and/or" unless we explicitly
state otherwise. Thus, $A$ or $B$ occurs means $A$, $B$, or both $A$ and
$B$ occur.

\(a\) If $A$ and $B$ are disjoint, describe why this implies $P(A$ and
$B) = 0$. (b) Using part (a), verify that the General Addition Rule
simplifies to the simpler Addition Rule for disjoint events if $A$ and
$B$ are disjoint.[^10]

[\[emailSpamNumberVennExer\]]{#emailSpamNumberVennExer
label="emailSpamNumberVennExer"} In the data set with 3,921 emails, 367
were spam, 2,827 contained some small numbers but no big numbers, and
168 had both characteristics. Create a Venn diagram for this setup.[^11]

\(a\) Use your Venn diagram from Guided
Practice [\[emailSpamNumberVennExer\]](#emailSpamNumberVennExer){reference-type="ref"
reference="emailSpamNumberVennExer"} to determine the probability a
randomly drawn email from the data set is spam and had small numbers
(but not big numbers). (b) What is the probability that the email had
either of these attributes?[^12]

### Probability distributions

A is a table of all disjoint outcomes and their associated
probabilities. Table [\[diceProb\]](#diceProb){reference-type="ref"
reference="diceProb"} shows the probability distribution for the sum of
two dice.

  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
                                                                                                                                                                                          
  Dice sum             2                3                4                5                6                7                8                9                10               11               12
  Probability    $\frac{1}{36}$   $\frac{2}{36}$   $\frac{3}{36}$   $\frac{4}{36}$   $\frac{5}{36}$   $\frac{6}{36}$   $\frac{5}{36}$   $\frac{4}{36}$   $\frac{3}{36}$   $\frac{2}{36}$   $\frac{1}{36}$
  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------

  : Probability distribution for the sum of two
  dice.[]{label="diceProb"}

A probability distribution is a list of the possible outcomes with
corresponding probabilities that satisfies three rules:

1.  The outcomes listed must be disjoint.

2.  Each probability must be between 0 and 1.

3.  The probabilities must total 1.

[\[usHouseholdIncomeDistsExercise\]]{#usHouseholdIncomeDistsExercise
label="usHouseholdIncomeDistsExercise"}
Table [\[usHouseholdIncomeDists\]](#usHouseholdIncomeDists){reference-type="ref"
reference="usHouseholdIncomeDists"} suggests three distributions for
household income in the United States. Only one is correct. Which one
must it be? What is wrong with the other two?[^13]

    Income range (\$1000s)   0-25   25-50   50-100   100+
  ------------------------ ------ ------- -------- ------
                     \(a\)   0.18    0.39     0.33   0.16
                     \(b\)   0.38   -0.27     0.52   0.37
                     \(c\)   0.28    0.27     0.29   0.16

  : Proposed distributions of US household incomes (Guided
  Practice [\[usHouseholdIncomeDistsExercise\]](#usHouseholdIncomeDistsExercise){reference-type="ref"
  reference="usHouseholdIncomeDistsExercise"}).[]{label="usHouseholdIncomeDists"}

Chapter [\[introductionToData\]](#introductionToData){reference-type="ref"
reference="introductionToData"} emphasized the importance of plotting
data to provide quick summaries. Probability distributions can also be
summarized in a bar plot. For instance, the distribution of US household
incomes is shown in
Figure [1.4](#usHouseholdIncomeDistBar){reference-type="ref"
reference="usHouseholdIncomeDistBar"} as a bar plot.[^14] The
probability distribution for the sum of two dice is shown in
Table [\[diceProb\]](#diceProb){reference-type="ref"
reference="diceProb"} and plotted in
Figure [1.5](#diceSumDist){reference-type="ref"
reference="diceSumDist"}.

![The probability distribution of US household
income.[]{label="usHouseholdIncomeDistBar"}](appendix-probability/figures/usHouseholdIncomeDistBar/usHouseholdIncomeDistBar){#usHouseholdIncomeDistBar
width="68%"}

![The probability distribution of the sum of two
dice.[]{label="diceSumDist"}](appendix-probability/figures/diceSumDist/diceSumDist){#diceSumDist
width="73%"}

In these bar plots, the bar heights represent the probabilities of
outcomes. If the outcomes are numerical and discrete, it is usually
(visually) convenient to make a bar plot that resembles a histogram, as
in the case of the sum of two dice. Another example of plotting the bars
at their respective locations is shown in
Figure [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} on page .

### Complement of an event

Rolling a die produces a value in the set $\{$, , , , , $\}$. This set
of all possible outcomes is called the ($S$) for rolling a die. We often
use the sample space to examine the scenario where an event does not
occur.

Let $D=\{$, $\}$ represent the event that the outcome of a die roll is
or . Then the of $D$ represents all outcomes in our sample space that
are not in $D$, which is denoted by $D^c = \{$, , , $\}$. That is, $D^c$
is the set of all possible outcomes not already included in $D$.
Figure [1.6](#complementOfD){reference-type="ref"
reference="complementOfD"} shows the relationship between $D$, $D^c$,
and the sample space $S$.

![Event $D=\{$, $\}$ and its complement, $D^c = \{$, , , $\}$.
$S$ represents the sample space, which is the set of all possible
events.[]{label="complementOfD"}](appendix-probability/figures/complementOfD/complementOfD){#complementOfD
width="40%"}

\(a\) Compute $P(D^c) = P($rolling a , , , or $)$. (b) What is
$P(D) + P(D^c)$?[^15]

Events $A=\{$, $\}$ and $B=\{$, $\}$ are shown in
Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} on page . (a) Write out what $A^c$ and $B^c$
represent. (b) Compute $P(A^c)$ and $P(B^c)$. (c) Compute $P(A)+P(A^c)$
and $P(B)+P(B^c)$.[^16]

A complement of an event $A$ is constructed to have two very important
properties: (i) every possible outcome not in $A$ is in $A^c$, and (ii)
$A$ and $A^c$ are disjoint. Property (i) implies $$\begin{aligned}
P(A\text{ or }A^c) = 1
\label{complementSumTo1}\end{aligned}$$ That is, if the outcome is not
in $A$, it must be represented in $A^c$. We use the Addition Rule for
disjoint events to apply Property (ii): $$\begin{aligned}
P(A\text{ or }A^c) = P(A) + P(A^c)
\label{complementDisjointEquation}\end{aligned}$$ Combining
Equations ([\[complementSumTo1\]](#complementSumTo1){reference-type="ref"
reference="complementSumTo1"})
and ([\[complementDisjointEquation\]](#complementDisjointEquation){reference-type="ref"
reference="complementDisjointEquation"}) yields a very useful
relationship between the probability of an event and its complement.

The complement of event $A$ is denoted $A^c$, and $A^c$ represents all
outcomes not in $A$. $A$ and $A^c$ are mathematically related:
$$\begin{aligned}
\label{complement}
P(A) + P(A^c) = 1, \quad\text{i.e.}\quad P(A) = 1-P(A^c)\end{aligned}$$

In simple examples, computing $A$ or $A^c$ is feasible in a few steps.
However, using the complement can save a lot of time as problems grow in
complexity.

Let $A$ represent the event where we roll two dice and their total is
less than . (a) What does the event $A^c$ represent? (b) Determine
$P(A^c)$ from Table [\[diceProb\]](#diceProb){reference-type="ref"
reference="diceProb"} on page . (c) Determine $P(A)$.[^17]

Consider again the probabilities from
Table [\[diceProb\]](#diceProb){reference-type="ref"
reference="diceProb"} and rolling two dice. Find the following
probabilities: (a) The sum of the dice is *not* . (b) The sum is at
least , i.e. $\{$, , \..., $\}$. (c) The sum is no more than . That is,
determine the probability of the event $D=\{$, , \..., $\}$.[^18]

### Independence {#probabilityIndependence}

Just as variables and observations can be independent, random processes
can be independent, too. Two processes are if knowing the outcome of one
provides no useful information about the outcome of the other. For
instance, flipping a coin and rolling a die are two independent
processes -- knowing the coin was heads does not help determine the
outcome of a die roll. On the other hand, stock prices usually move up
or down together, so they are not independent.

Example [\[probOf2Ones\]](#probOf2Ones){reference-type="ref"
reference="probOf2Ones"} provides a basic example of two independent
processes: rolling two dice. We want to determine the probability that
both will be . Suppose one of the dice is red and the other white. If
the outcome of the red die is a , it provides no information about the
outcome of the white die. We first encountered this same question in
Example [\[probOf2Ones\]](#probOf2Ones){reference-type="ref"
reference="probOf2Ones"} (page ), where we calculated the probability
using the following reasoning: $1/6^{th}$ of the time the red die is a ,
and $1/6^{th}$ of *those* times the white die will also be . This is
illustrated in Figure [1.7](#indepForRollingTwo1s){reference-type="ref"
reference="indepForRollingTwo1s"}. Because the rolls are independent,
the probabilities of the corresponding outcomes can be multiplied to get
the final answer: $(1/6)\times(1/6)=1/36$. This can be generalized to
many independent processes.

![$1/6^{th}$ of the time, the first roll is a . Then $1/6^{th}$ of
*those* times, the second roll will also be a
.[]{label="indepForRollingTwo1s"}](appendix-probability/figures/indepForRollingTwo1s/indepForRollingTwo1s){#indepForRollingTwo1s
width="65%"}

What if there was also a blue die independent of the other two? What is
the probability of rolling the three dice and getting all
s?[\[threeDice\]]{#threeDice label="threeDice"} The same logic applies
from Example [\[probOf2Ones\]](#probOf2Ones){reference-type="ref"
reference="probOf2Ones"}. If $1/36^{th}$ of the time the white and red
dice are both , then $1/6^{th}$ of *those* times the blue die will also
be , so multiply: $$\begin{aligned}
P(white=\text{\small\resp{1} and } red=\text{\small\resp{1} and } blue=\text{\small\resp{1}})
    &= P(white=\text{\small\resp{1}})\times P(red=\text{\small\resp{1}})\times P(blue=\text{\small\resp{1}}) \\
    &= (1/6)\times (1/6)\times (1/6)
    = 1/216\end{aligned}$$

Examples [\[probOf2Ones\]](#probOf2Ones){reference-type="ref"
reference="probOf2Ones"}
and [\[threeDice\]](#threeDice){reference-type="ref"
reference="threeDice"} illustrate what is called the Multiplication Rule
for independent processes.

If $A$ and $B$ represent events from two different and independent
processes, then the probability that both $A$ and $B$ occur can be
calculated as the product of their separate probabilities:
$$\begin{aligned}
\label{eqForIndependentEvents}
P(A \text{ and }B) = P(A) \times  P(B)\end{aligned}$$ Similarly, if
there are $k$ events $A_1$, \..., $A_k$ from $k$ independent processes,
then the probability they all occur is $$\begin{aligned}
P(A_1) \times  P(A_2)\times  \cdots \times  P(A_k)\end{aligned}$$

[\[ex2Handedness\]]{#ex2Handedness label="ex2Handedness"} About 9% of
people are left-handed. Suppose 2 people are selected at random from the
U.S. population. Because the sample size of 2 is very small relative to
the population, it is reasonable to assume these two people are
independent. (a) What is the probability that both are left-handed?
(b) What is the probability that both are right-handed?[^19]

[\[ex5Handedness\]]{#ex5Handedness label="ex5Handedness"} Suppose 5
people are selected at random.[^20]

1.  What is the probability that all are right-handed?

2.  What is the probability that all are left-handed?

3.  What is the probability that not all of the people are right-handed?

Suppose the variables and are independent, i.e. knowing someone's
provides no useful information about their and vice-versa. Then we can
compute whether a randomly selected person is right-handed and
female[^21] using the Multiplication Rule: $$\begin{aligned}
P(\text{right-handed and female}) &=& P(\text{right-handed}) \times  P(\text{female}) \\
&=& 0.91 \times  0.50 = 0.455\end{aligned}$$

Three people are selected at random.[^22]

1.  What is the probability that the first person is male and
    right-handed?

2.  What is the probability that the first two people are male and
    right-handed?.

3.  What is the probability that the third person is female and
    left-handed?

4.  What is the probability that the first two people are male and
    right-handed and the third person is female and left-handed?

Sometimes we wonder if one outcome provides useful information about
another outcome. The question we are asking is, are the occurrences of
the two events independent? We say that two events $A$ and $B$ are
independent if they satisfy
Equation [\[eqForIndependentEvents\]](#eqForIndependentEvents){reference-type="eqref"
reference="eqForIndependentEvents"}.

If we shuffle up a deck of cards and draw one, is the event that the
card is a heart independent of the event that the card is an ace? The
probability the card is a heart is $1/4$ and the probability that it is
an ace is $1/13$. The probability the card is the ace of hearts is
$1/52$. We check whether
Equation [\[eqForIndependentEvents\]](#eqForIndependentEvents){reference-type="ref"
reference="eqForIndependentEvents"} is satisfied: $$\begin{aligned}
P({\color{redcards}\heartsuit})\times P(\text{ace}) = \frac{1}{4}\times \frac{1}{13} = \frac{1}{52} 
                    = P({\color{redcards}\heartsuit}\text{ and ace})\end{aligned}$$
Because the equation holds, the event that the card is a heart and the
event that the card is an ace are independent events.

Conditional probability {#conditionalProbabilitySection}
-----------------------

Are students more likely to use marijuana when their parents used drugs?
The data set contains a sample of 445 cases with two variables, and ,
and is summarized in
Table [\[contTableOfParStDrugUse\]](#contTableOfParStDrugUse){reference-type="ref"
reference="contTableOfParStDrugUse"}.[^23] The variable is either or ,
where a student is labeled as if she has recently used marijuana. The
variable takes the value if at least one of the parents used drugs,
including alcohol.

  --------- ------- ----- ----- ------- -- --
                                           
                                  Total    
                      125    94     219    
  \[0pt\]              85   141     226    
            Total     210   235     445    
  --------- ------- ----- ----- ------- -- --

  : Contingency table summarizing the data
  set.[]{label="contTableOfParStDrugUse"}

![A Venn diagram using boxes for the data
set.[]{label="drugUseVenn"}](appendix-probability/figures/drugUseVenn/drugUseVenn){#drugUseVenn
width="65%"}

If at least one parent used drugs, what is the chance their child ()
uses? We will estimate this probability using the data. Of the 210 cases
in this data set where = , 125 represent cases where = :
$$\begin{aligned}
P(\text{\var{student} = \resp{uses} given \var{parents} = \resp{used}}) = \frac{125}{210} = 0.60\end{aligned}$$

A student is randomly selected from the study and she does not use
drugs. What is the probability that at least one of her parents
used?[\[drugUseProbOfParentsGivenStudents\]]{#drugUseProbOfParentsGivenStudents
label="drugUseProbOfParentsGivenStudents"} If the student does not use
drugs, then she is one of the 226 students in the second row. Of these
226 students, 85 had at least one parent who used drugs:
$$\begin{aligned}
P(\text{\var{parents} = \resp{used} given \var{student} = \resp{not}}) = \frac{85}{226} = 0.376\end{aligned}$$

### Marginal and joint probabilities {#marginalAndJointProbabilities}

Table [\[drugUseProbTable\]](#drugUseProbTable){reference-type="ref"
reference="drugUseProbTable"} includes row and column totals for each
variable separately in the data set. These totals represent for the
sample, which are the probabilities based on a single variable without
conditioning on any other variables. For instance, a probability based
solely on the variable is a marginal probability: $$\begin{aligned}
P(\text{\var{student} = \resp{uses}}) = \frac{219}{445} = 0.492\end{aligned}$$
A probability of outcomes for two or more variables or processes is
called a : $$\begin{aligned}
P(\text{\var{student} = \resp{uses} and \var{parents} = \resp{not}}) = \frac{94}{445} = 0.21\end{aligned}$$
It is common to substitute a comma for "and" in a joint probability,
although either is acceptable.

               :      :   Total
  ------- ------ ------ -------
  :         0.28   0.21    0.49
  :         0.19   0.32    0.51
  Total     0.47   0.53    1.00

  : Probability table summarizing parental and student drug
  use.[]{label="drugUseProbTable"}

If a probability is based on a single variable, it is a *marginal
probability*. The probability of outcomes for two or more variables or
processes is called a *joint probability*.

We use to summarize joint probabilities for the sample. These
proportions are computed by dividing each count in
Table [\[contTableOfParStDrugUse\]](#contTableOfParStDrugUse){reference-type="ref"
reference="contTableOfParStDrugUse"} by 445 to obtain the proportions in
Table [\[drugUseProbTable\]](#drugUseProbTable){reference-type="ref"
reference="drugUseProbTable"}. The joint probability distribution of the
and variables is shown in
Table [\[drugUseDistribution\]](#drugUseDistribution){reference-type="ref"
reference="drugUseDistribution"}.

  Joint outcome    Probability
  --------------- -------------
  = , =               0.28
  = , =               0.19
  = , =               0.21
  = , =               0.32
  Total               1.00

  : A joint probability distribution for the data
  set.[]{label="drugUseDistribution"}

Verify
Table [\[drugUseDistribution\]](#drugUseDistribution){reference-type="ref"
reference="drugUseDistribution"} represents a probability distribution:
events are disjoint, all probabilities are non-negative, and the
probabilities sum to 1.[^24]

We can compute marginal probabilities using joint probabilities in
simple cases. For example, the probability a random student from the
study uses drugs is found by summing the outcomes from
Table [\[drugUseDistribution\]](#drugUseDistribution){reference-type="ref"
reference="drugUseDistribution"} where = : $$\begin{aligned}
&&P(\text{\underline{\color{black}\var{student} = \resp{uses}}}) \\
&& \quad =  P(\text{\var{parents} = \resp{used}, \underline{\color{black}\var{student} = \resp{uses}}}) + \\
&& \quad \quad \quad \quad P(\text{\var{parents} = \resp{not}, \underline{\color{black}\var{student} = \resp{uses}}}) \\
&& \quad = 0.28 + 0.21 = 0.49\end{aligned}$$

### Defining conditional probability

There is some connection between drug use of parents and of the student:
drug use of one is associated with drug use of the other.[^25] In this
section, we discuss how to use information about associations between
two variables to improve probability estimation.

The probability that a random student from the study uses drugs is 0.49.
Could we update this probability if we knew that this student's parents
used drugs? Absolutely. To do so, we limit our view to only those 210
cases where parents used drugs and look at the fraction where the
student uses drugs: $$\begin{aligned}
P(\text{\var{student} = \resp{uses} given \var{parents} = \resp{used}}) = \frac{125}{210} = 0.60\end{aligned}$$
We call this a because we computed the probability under a condition: =
. There are two parts to a conditional probability, and the . It is
useful to think of the condition as information we know to be true, and
this information usually can be described as a known outcome or event.

We separate the text inside our probability notation into the outcome of
interest and the condition: $$\begin{aligned}
&& P(\text{\var{student} = \resp{uses} given \var{parents} = \resp{used}}) \notag \\
&& = P(\text{\var{student} = \resp{uses} } | \text{ \var{parents} = \resp{used}}) = \frac{125}{210} = 0.60
\label{probStudentUsedIfParentsUsedInFormalNotation}\end{aligned}$$ The
vertical bar "$|$" is read as *given*.

In
Equation ([\[probStudentUsedIfParentsUsedInFormalNotation\]](#probStudentUsedIfParentsUsedInFormalNotation){reference-type="ref"
reference="probStudentUsedIfParentsUsedInFormalNotation"}), we computed
the probability a student uses based on the condition that at least one
parent used as a fraction: $$\begin{aligned}
&& P(\text{\var{student} = \resp{uses} } | \text{ \var{parents} = \resp{used}}) \notag \\
&&\quad = \frac{\text{\# times \var{student} = \resp{uses} and \var{parents} = \resp{used}}}{\text{\# times \var{parents} = \resp{used}}} \label{ratioOfBothToRatioOfConditionalForParentsAndStudent} \\
&&\quad = \frac{125}{210} = 0.60 \notag\end{aligned}$$ We considered
only those cases that met the condition, = , and then we computed the
ratio of those cases that satisfied our outcome of interest, the
student uses.

Counts are not always available for data, and instead only marginal and
joint probabilities may be provided. For example, disease rates are
commonly listed in percentages rather than in a count format. We would
like to be able to compute conditional probabilities even when no counts
are available, and we use
Equation ([\[ratioOfBothToRatioOfConditionalForParentsAndStudent\]](#ratioOfBothToRatioOfConditionalForParentsAndStudent){reference-type="ref"
reference="ratioOfBothToRatioOfConditionalForParentsAndStudent"}) as an
example demonstrating this technique.

We considered only those cases that satisfied the condition, = . Of
these cases, the conditional probability was the fraction who
represented the outcome of interest, = . Suppose we were provided only
the information in
Table [\[drugUseProbTable\]](#drugUseProbTable){reference-type="ref+page"
reference="drugUseProbTable"}, i.e. only probability data. Then if we
took a sample of 1000 people, we would anticipate about 47% or
$0.47\times 1000 = 470$ would meet our information criterion. Similarly,
we would expect about 28% or $0.28\times 1000 = 280$ to meet both the
information criterion and represent our outcome of interest. Thus, the
conditional probability could be computed: $$\begin{aligned}
P(\text{\var{student} = \resp{uses} } | \text{ \var{parents} = \resp{used}})
    &= \frac{\text{\# (\var{student} = \resp{uses} and \var{parents} = \resp{used})}}{\text{\# (\var{parents} = \resp{used})}} \notag \\
    &= \frac{280}{470} = \frac{0.28}{0.47} = 0.60
\label{stUserPUsedHypSampSize}\end{aligned}$$ In
Equation ([\[stUserPUsedHypSampSize\]](#stUserPUsedHypSampSize){reference-type="ref"
reference="stUserPUsedHypSampSize"}), we examine exactly the fraction of
two probabilities, 0.28 and 0.47, which we can write as
$$\begin{aligned}
P(\var{student} = \resp{uses}\ \text{and}\ \var{parents} = \resp{used})
    \quad\text{and}\quad
    P(\var{parents} = \resp{used}).\end{aligned}$$ The fraction of these
probabilities represents our general formula for conditional
probability.

The conditional probability of the outcome of interest $A$ given
condition $B$ is computed as the following: $$\begin{aligned}
P(A | B) = \frac{P(A\text{ and }B)}{P(B)}
\label{condProbEq}\end{aligned}$$

[\[drugUseProbOfParentsEqualNotGivenStudents\]]{#drugUseProbOfParentsEqualNotGivenStudents
label="drugUseProbOfParentsEqualNotGivenStudents"} (a) Write out the
following statement in conditional probability notation: "*The
probability a random case has = if it is known that =* ". Notice that
the condition is now based on the student, not the parent. (b) Determine
the probability from part (a).
Table [\[drugUseProbTable\]](#drugUseProbTable){reference-type="ref+page"
reference="drugUseProbTable"} may be helpful.[^26]

[\[whyCondProbSumTo1\]]{#whyCondProbSumTo1 label="whyCondProbSumTo1"}
(a) Determine the probability that one of the parents had used drugs if
it is known the student does not use drugs. (b) Using the answers from
part (a) and Guided
Practice [\[drugUseProbOfParentsEqualNotGivenStudents\]](#drugUseProbOfParentsEqualNotGivenStudents){reference-type="ref"
reference="drugUseProbOfParentsEqualNotGivenStudents"}(b), compute
$$\begin{aligned}
P(\text{\var{parents} = \resp{used}}|\text{\var{student} = \resp{not}})
    + P(\text{\var{parents} = \resp{not}}|\text{\var{student} = \resp{not}})\end{aligned}$$
(c) Provide an intuitive argument to explain why the sum in (b) is
1.[^27]

The data indicate that drug use of parents and children are associated.
Does this mean the drug use of parents causes the drug use of the
students?[^28]

### Smallpox in Boston, 1721

The data set provides a sample of 6,224 individuals from the year 1721
who were exposed to smallpox in Boston.[^29] Doctors at the time
believed that inoculation, which involves exposing a person to the
disease in a controlled form, could reduce the likelihood of death.

Each case represents one person with two variables: and . The variable
takes two levels: or , indicating whether the person was inoculated or
not. The variable has outcomes or . These data are summarized in
Tables [\[smallpoxContingencyTable\]](#smallpoxContingencyTable){reference-type="ref"
reference="smallpoxContingencyTable"}
and [\[smallpoxProbabilityTable\]](#smallpoxProbabilityTable){reference-type="ref"
reference="smallpoxProbabilityTable"}.

  --------- ------- ----- ------ -------
                                 
                                   Total
                      238   5136    5374
  \[0pt\]               6    844     850
            Total     244   5980    6224
  --------- ------- ----- ------ -------

  : Contingency table for the data
  set.[]{label="smallpoxContingencyTable"}

  --------- ------- -------- -------- --------
                                      
                                         Total
                      0.0382   0.8252   0.8634
  \[0pt\]             0.0010   0.1356   0.1366
            Total     0.0392   0.9608   1.0000
  --------- ------- -------- -------- --------

  : Table proportions for the data, computed by dividing each count by
  the table total, 6224.[]{label="smallpoxProbabilityTable"}

[\[probDiedIfNotInoculated\]]{#probDiedIfNotInoculated
label="probDiedIfNotInoculated"} Write out, in formal notation, the
probability a randomly selected person who was not inoculated died from
smallpox, and find this probability.[^30]

Determine the probability that an inoculated person died from smallpox.
How does this result compare with the result of Guided
Practice [\[probDiedIfNotInoculated\]](#probDiedIfNotInoculated){reference-type="ref"
reference="probDiedIfNotInoculated"}?[^31]

[\[SmallpoxInoculationObsExpExercise\]]{#SmallpoxInoculationObsExpExercise
label="SmallpoxInoculationObsExpExercise"} The people of Boston
self-selected whether or not to be inoculated. (a) Is this study
observational or was this an experiment? (b) Can we infer any causal
connection using these data? (c) What are some potential confounding
variables that might influence whether someone or and also affect
whether that person was inoculated?[^32]

### General multiplication rule

Section [1.1.6](#probabilityIndependence){reference-type="ref"
reference="probabilityIndependence"} introduced the Multiplication Rule
for independent processes. Here we provide the for events that might not
be independent.

If $A$ and $B$ represent two outcomes or events, then $$\begin{aligned}
P(A\text{ and }B) = P(A | B)\times P(B)\end{aligned}$$

It is useful to think of $A$ as the outcome of interest and $B$ as the
condition.

This General Multiplication Rule is simply a rearrangement of the
definition for conditional probability in
Equation ([\[condProbEq\]](#condProbEq){reference-type="ref"
reference="condProbEq"}) on page .

Consider the data set. Suppose we are given only two pieces of
information: 96.08% of residents were not inoculated, and 85.88% of the
residents who were not inoculated ended up surviving. How could we
compute the probability that a resident was not inoculated and lived? We
will compute our answer using the General Multiplication Rule and then
verify it using
Table [\[smallpoxProbabilityTable\]](#smallpoxProbabilityTable){reference-type="ref"
reference="smallpoxProbabilityTable"}. We want to determine
$$\begin{aligned}
P(\text{\var{result} = \resp{lived} and \var{inoculated} = \resp{no}})\end{aligned}$$
and we are given that $$\begin{aligned}
P(\text{\var{result} = \resp{lived} }|\text{ \var{inoculated} = \resp{no}})=0.8588 \\
P(\text{\var{inoculated} = \resp{no}})=0.9608\end{aligned}$$ Among the
96.08% of people who were not inoculated, 85.88% survived:
$$\begin{aligned}
P(\text{\var{result} = \resp{lived} and \var{inoculated} = \resp{no}}) = 0.8588\times 0.9608 = 0.8251\end{aligned}$$
This is equivalent to the General Multiplication Rule. We can confirm
this probability in
Table [\[smallpoxProbabilityTable\]](#smallpoxProbabilityTable){reference-type="ref"
reference="smallpoxProbabilityTable"} at the intersection of and (with a
small rounding error).

Use $P($ = $) = 0.0392$ and $P($ = $|$ = $) = 0.9754$ to determine the
probability that a person was both inoculated and lived.[^33]

If 97.45% of the people who were inoculated lived, what proportion of
inoculated people must have died?[^34]

Let $A_1$, \..., $A_k$ represent all the disjoint outcomes for a
variable or process. Then if $B$ is an event, possibly for another
variable or process, we have: $$\begin{aligned}
P(A_1|B)+\cdots+P(A_k|B) = 1\end{aligned}$$

The rule for complements also holds when an event and its complement are
conditioned on the same information: $$\begin{aligned}
P(A | B) = 1 - P(A^c | B)\end{aligned}$$

Based on the probabilities computed above, does it appear that
inoculation is effective at reducing the risk of death from
smallpox?[^35]

### Independence considerations in conditional probability

If two processes are independent, then knowing the outcome of one should
provide no information about the other. We can show this is
mathematically true using conditional probabilities.

[\[condProbOfRollingA1AfterOne1\]]{#condProbOfRollingA1AfterOne1
label="condProbOfRollingA1AfterOne1"} Let $X$ and $Y$ represent the
outcomes of rolling two dice. (a) What is the probability that the first
die, $X$, is ? (b) What is the probability that both $X$ and $Y$ are ?
(c) Use the formula for conditional probability to compute $P(Y =$
$| X =$ $)$. (d) What is $P(Y=1)$? Is this different from the answer
from part (c)? Explain.[^36]

We can show in Guided
Practice [\[condProbOfRollingA1AfterOne1\]](#condProbOfRollingA1AfterOne1){reference-type="ref"
reference="condProbOfRollingA1AfterOne1"}(c) that the conditioning
information has no influence by using the Multiplication Rule for
independence processes: $$\begin{aligned}
P(Y=\text{\resp{1}}|X=\text{\resp{1}})
    &=& \frac{P(Y=\text{\resp{1} and }X=\text{\resp{1}})}{P(X=\text{\resp{1}})} \\
    &=& \frac{P(Y=\text{\resp{1}})\times \color{oiGB}P(X=\text{\resp{1}})}{\color{oiGB}P(X=\text{\resp{1}})} \\
    &=& P(Y=\text{\resp{1}}) \\\end{aligned}$$

Ron is watching a roulette table in a casino and notices that the last
five outcomes were . He figures that the chances of getting six times in
a row is very small (about $1/64$) and puts his paycheck on red. What is
wrong with his reasoning?[^37]

### Tree diagrams

are a tool to organize outcomes and probabilities around the structure
of the data. They are most useful when two or more processes occur in a
sequence and each process is conditioned on its predecessors.

The data fit this description. We see the population as split by : and .
Following this split, survival rates were observed for each group. This
structure is reflected in the shown in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. The first branch for is said to be the
branch while the other branches are .

![A tree diagram of the data
set.[]{label="smallpoxTreeDiagram"}](appendix-probability/figures/smallpoxTreeDiagram/smallpoxTreeDiagram){#smallpoxTreeDiagram
width="93%"}

Tree diagrams are annotated with marginal and conditional probabilities,
as shown in Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. This tree diagram splits the smallpox
data by into the and groups with respective marginal probabilities
0.0392 and 0.9608. The secondary branches are conditioned on the first,
so we assign conditional probabilities to these branches. For example,
the top branch in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"} is the probability that = conditioned
on the information that = . We may (and usually do) construct joint
probabilities at the end of each branch in our tree by multiplying the
numbers we come across as we move from left to right. These joint
probabilities are computed using the General Multiplication Rule:
$$\begin{aligned}
&& P(\text{\var{inoculated} = \resp{yes} and \var{result} = \resp{lived}}) \\
    &&\quad = P(\text{\var{inoculated} = \resp{yes}})\times P(\text{\var{result} = \resp{lived}}|\text{\var{inoculated} = \resp{yes}}) \\
    &&\quad = 0.0392\times 0.9754=0.0382\end{aligned}$$

Consider the midterm and final for a statistics class. Suppose 13% of
students earned an on the midterm. Of those students who earned an on
the midterm, 47% received an on the final, and 11% of the students who
earned lower than an on the midterm received an on the final. You
randomly pick up a final exam and notice the student received an . What
is the probability that this student earned an on the midterm?
[\[exerciseForTreeDiagramOfStudentGettingAOnMidtermGivenThatSheGotAOnFinal\]]{#exerciseForTreeDiagramOfStudentGettingAOnMidtermGivenThatSheGotAOnFinal
label="exerciseForTreeDiagramOfStudentGettingAOnMidtermGivenThatSheGotAOnFinal"}
The end-goal is to find
$P(\text{\var{midterm} = \resp{A}} | \text{\var{final} = \resp{A}})$. To
calculate this conditional probability, we need the following
probabilities: $$\begin{aligned}
P(\text{\var{midterm} = \resp{A} and \var{final} = \resp{A}}) \qquad\text{and}\qquad
P(\text{\var{final} = \resp{A}})\end{aligned}$$ However, this
information is not provided, and it is not obvious how to calculate
these probabilities. Since we aren't sure how to proceed, it is useful
to organize the information into a tree diagram, as shown in
Figure [1.10](#testTree){reference-type="ref" reference="testTree"}.
When constructing a tree diagram, variables provided with marginal
probabilities are often used to create the tree's primary branches; in
this case, the marginal probabilities are provided for midterm grades.
The final grades, which correspond to the conditional probabilities
provided, will be shown on the secondary branches.

![A tree diagram describing the and
variables.[]{label="testTree"}](appendix-probability/figures/testTree/testTree){#testTree
width="87%"}

With the tree diagram constructed, we may compute the required
probabilities: $$\begin{aligned}
&&P(\text{\var{midterm} = \resp{A} and \var{final} = \resp{A}}) = 0.0611 \\
&&P(\text{\underline{\color{black}\var{final} = \resp{A}}})  \\
&& \quad= P(\text{\var{midterm} = \resp{other} and \underline{\color{black}\var{final} = \resp{A}}}) + P(\text{\var{midterm} = \resp{A} and \underline{\color{black}\var{final} = \resp{A}}}) \\
&& \quad= 0.0611 + 0.0957 = 0.1568\end{aligned}$$ The marginal
probability, $P($ = $)$, was calculated by adding up all the joint
probabilities on the right side of the tree that correspond to = . We
may now finally take the ratio of the two probabilities:
$$\begin{aligned}
P(\text{\var{midterm} = \resp{A}} | \text{\var{final} = \resp{A}}) &=& \frac{P(\text{\var{midterm} = \resp{A} and \var{final} = \resp{A}})}{P(\text{\var{final} = \resp{A}})} \\
&=& \frac{0.0611}{0.1568} = 0.3897\end{aligned}$$ The probability the
student also earned an A on the midterm is about 0.39.

After an introductory statistics course, 78% of students can
successfully construct tree diagrams. Of those who can construct tree
diagrams, 97% passed, while only 57% of those students who could not
construct tree diagrams passed. (a) Organize this information into a
tree diagram. (b) What is the probability that a randomly selected
student passed? (c) Compute the probability a student is able to
construct a tree diagram if it is known that she passed.[^38]

Random variables {#randomVariablesSection}
----------------

Two books are assigned for a statistics class: a textbook and its
corresponding study guide. The university bookstore determined 20% of
enrolled students do not buy either book, 55% buy the textbook only, and
25% buy both books, and these percentages are relatively constant from
one term to another. If there are 100 students enrolled, how many books
should the bookstore expect to sell to this
class?[\[bookStoreSales\]]{#bookStoreSales label="bookStoreSales"}
Around 20 students will not buy either book (0 books total), about 55
will buy one book (55 books total), and approximately 25 will buy two
books (totaling 50 books for these 25 students). The bookstore should
expect to sell about 105 books for this class.

Would you be surprised if the bookstore sold slightly more or less than
105 books?[^39]

The textbook costs \$137 and the study guide \$33. How much revenue
should the bookstore expect from this class of 100
students?[\[bookStoreRev\]]{#bookStoreRev label="bookStoreRev"} About 55
students will just buy a textbook, providing revenue of
$$\begin{aligned}
\$137 \times  55 = \$7,535\end{aligned}$$ The roughly 25 students who
buy both the textbook and the study guide would pay a total of
$$\begin{aligned}
(\$137 + \$33) \times  25 = \$170 \times  25 = \$4,250\end{aligned}$$
Thus, the bookstore should expect to generate about
$\$7,535 + \$4,250 = \$11,785$ from these 100 students for this one
class. However, there might be some *sampling variability* so the actual
amount may differ by a little bit.

![Probability distribution for the bookstore's revenue from a single
student. The distribution balances on a triangle representing the
average revenue per
student.[]{label="bookCostDist"}](appendix-probability/figures/bookCostDist/bookCostDist){#bookCostDist
width="69%"}

What is the average revenue per student for this
course?[\[revFromStudent\]]{#revFromStudent label="revFromStudent"} The
expected total revenue is \$11,785, and there are 100 students.
Therefore the expected revenue per student is
$\$11,785/100 =  \$117.85$.

### Expectation

We call a variable or process with a numerical outcome a , and we
usually represent this random variable with a capital letter such as
$X$, $Y$, or $Z$. The amount of money a single student will spend on her
statistics books is a random variable, and we represent it by $X$.

A random process or variable with a numerical outcome.

The possible outcomes of $X$ are labeled with a corresponding lower case
letter $x$ and subscripts. For example, we write $x_1=\$0$, $x_2=\$137$,
and $x_3=\$170$, which occur with probabilities $0.20$, $0.55$, and
$0.25$. The distribution of $X$ is summarized in
Figure [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and
Table [\[statSpendDist\]](#statSpendDist){reference-type="ref"
reference="statSpendDist"}.

  $i$            1       2       3      Total
  ------------ ------ ------- ------- -------
  $x_i$         \$0    \$137   \$170       --
  $P(X=x_i)$    0.20   0.55    0.25      1.00

  : The probability distribution for the random variable $X$,
  representing the bookstore's revenue from a single
  student.[]{label="statSpendDist"}

We computed the average outcome of $X$ as \$117.85 in
Example [\[revFromStudent\]](#revFromStudent){reference-type="ref"
reference="revFromStudent"}. We call this average the of $X$, denoted by
$E(X)$. The expected value of a random variable is computed by adding
each outcome weighted by its probability: $$\begin{aligned}
E(X) &= 0 \times  P(X=0) + 137 \times  P(X=137) + 170 \times  P(X=170) \\
    &= 0 \times  0.20 + 137 \times  0.55 + 170 \times  0.25 = 117.85\end{aligned}$$

If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$, the expected value of $X$ is the sum of each outcome
multiplied by its corresponding probability: $$\begin{aligned}
E(X)    &= x_1\times P(X=x_1) + \cdots + x_k\times P(X=x_k) \notag \\
    &= \sum_{i=1}^{k}x_iP(X=x_i)\end{aligned}$$ The Greek letter $\mu$
may be used in place of the notation $E(X)$.

The expected value for a random variable represents the average outcome.
For example, $E(X)=117.85$ represents the average amount the bookstore
expects to make from a single student, which we could also write as
$\mu=117.85$.

It is also possible to compute the expected value of a continuous random
variable. However, it requires a little calculus and we save it for a
later class.[^40]

In physics, the expectation holds the same meaning as the center of
gravity. The distribution can be represented by a series of weights at
each outcome, and the mean represents the balancing point. This is
represented in Figures [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and [1.12](#bookWts){reference-type="ref"
reference="bookWts"}. The idea of a center of gravity also expands to
continuous probability distributions.
Figure [1.13](#contBalance){reference-type="ref"
reference="contBalance"} shows a continuous probability distribution
balanced atop a wedge placed at the mean.

![A weight system representing the probability distribution for $X$. The
string holds the distribution at the mean to keep the system
balanced.[]{label="bookWts"}](appendix-probability/figures/bookWts/bookWts){#bookWts
width="72%"}

![A continuous distribution can also be balanced at its
mean.[]{label="contBalance"}](appendix-probability/figures/contBalance/contBalance){#contBalance
width="65%"}

### Variability in random variables

Suppose you ran the university bookstore. Besides how much revenue you
expect to generate, you might also want to know the volatility
(variability) in your revenue.

The and can be used to describe the variability of a random variable.
Section [\[variability\]](#variability){reference-type="ref"
reference="variability"} introduced a method for finding the variance
and standard deviation for a data set. We first computed deviations from
the mean ($x_i - \mu$), squared those deviations, and took an average to
get the variance. In the case of a random variable, we again compute
squared deviations. However, we take their sum weighted by their
corresponding probabilities, just like we did for the expectation. This
weighted sum of squared deviations equals the variance, and we calculate
the standard deviation by taking the square root of the variance, just
as we did in
Section [\[variability\]](#variability){reference-type="ref"
reference="variability"}.

If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$ and expected value $\mu=E(X)$, then the variance of
$X$, denoted by $Var(X)$ or the symbol $\sigma^2$, is $$\begin{aligned}
\sigma^2 &= (x_1-\mu)^2\times P(X=x_1) + \cdots \notag \\
    & \qquad\quad\cdots+ (x_k-\mu)^2\times P(X=x_k) \notag \\
    &= \sum_{j=1}^{k} (x_j - \mu)^2 P(X=x_j)\end{aligned}$$ The standard
deviation of $X$, labeled $\sigma$, is the square root of the variance.

Compute the expected value, variance, and standard deviation of $X$, the
revenue of a single statistics student for the bookstore. It is useful
to construct a table that holds computations for each outcome
separately, then add up the results.

  $i$                           1       2       3    Total
  ------------------------ ------ ------- ------- --------
  $x_i$                       \$0   \$137   \$170 
  $P(X=x_i)$                 0.20    0.55    0.25 
  $x_i \times  P(X=x_i)$        0   75.35   42.50   117.85

Thus, the expected value is $\mu=117.85$, which we computed earlier. The
variance can be constructed by extending this table:

  $i$                                     1        2         3    Total
  ------------------------------ ---------- -------- --------- --------
  $x_i$                                 \$0    \$137     \$170 
  $P(X=x_i)$                           0.20     0.55      0.25 
  $x_i \times  P(X=x_i)$                  0    75.35     42.50   117.85
  $x_i - \mu$                       -117.85    19.15     52.15 
  $(x_i-\mu)^2$                    13888.62   366.72   2719.62 
  $(x_i-\mu)^2\times P(X=x_i)$       2777.7    201.7     679.9   3659.3

The variance of $X$ is $\sigma^2 = 3659.3$, which means the standard
deviation is $\sigma = \sqrt{3659.3} = \$60.49$.

The bookstore also offers a chemistry textbook for \$159 and a book
supplement for \$41. From past experience, they know about 25% of
chemistry students just buy the textbook while 60% buy both the textbook
and supplement.[^41]

1.  What proportion of students don't buy either book? Assume no
    students buy the supplement without the textbook.

2.  Let $Y$ represent the revenue from a single student. Write out the
    probability distribution of $Y$, i.e. a table for each outcome and
    its associated probability.

3.  Compute the expected revenue from a single chemistry student.

4.  Find the standard deviation to describe the variability associated
    with the revenue from a single student.

### Linear combinations of random variables

So far, we have thought of each variable as being a complete story in
and of itself. Sometimes it is more appropriate to use a combination of
variables. For instance, the amount of time a person spends commuting to
work each week can be broken down into several daily commutes.
Similarly, the total gain or loss in a stock portfolio is the sum of the
gains and losses in its components.

John travels to work five days a week. We will use $X_1$ to represent
his travel time on Monday, $X_2$ to represent his travel time on
Tuesday, and so on. Write an equation using $X_1$, \..., $X_5$ that
represents his travel time for the week, denoted by $W$. His total
weekly travel time is the sum of the five daily values:
$$W = X_1 + X_2 + X_3 + X_4 + X_5$$ Breaking the weekly travel time $W$
into pieces provides a framework for understanding each source of
randomness and is useful for modeling $W$.

It takes John an average of 18 minutes each day to commute to work. What
would you expect his average commute time to be for the week? We were
told that the average (i.e. expected value) of the commute time is 18
minutes per day: $E(X_i) = 18$. To get the expected time for the sum of
the five days, we can add up the expected time for each individual day:
$$\begin{aligned}
E(W) &= E(X_1 + X_2 + X_3 + X_4 + X_5) \\
    &= E(X_1) + E(X_2) + E(X_3) + E(X_4) + E(X_5) \\
    &= 18 + 18 + 18 + 18 + 18 = 90\text{ minutes}\end{aligned}$$ The
expectation of the total time is equal to the sum of the expected
individual times. More generally, the expectation of a sum of random
variables is always the sum of the expectation for each random variable.

[\[elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction\]]{#elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction
label="elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction"} Elena is
selling a TV at a cash auction and also intends to buy a toaster oven in
the auction. If $X$ represents the profit for selling the TV and $Y$
represents the cost of the toaster oven, write an equation that
represents the net change in Elena's cash.[^42]

Based on past auctions, Elena figures she should expect to make about
\$175 on the TV and pay about \$23 for the toaster oven. In total, how
much should she expect to make or spend?[^43]

[\[explainWhyThereIsUncertaintyInTheSum\]]{#explainWhyThereIsUncertaintyInTheSum
label="explainWhyThereIsUncertaintyInTheSum"} Would you be surprised if
John's weekly commute wasn't exactly 90 minutes or if Elena didn't make
exactly \$152? Explain.[^44]

Two important concepts concerning combinations of random variables have
so far been introduced. First, a final value can sometimes be described
as the sum of its parts in an equation. Second, intuition suggests that
putting the individual average values into this equation gives the
average value we would expect in total. This second point needs
clarification -- it is guaranteed to be true in what are called *linear
combinations of random variables*.

A of two random variables $X$ and $Y$ is a fancy phrase to describe a
combination $$aX + bY$$ where $a$ and $b$ are some fixed and known
numbers. For John's commute time, there were five random variables --
one for each work day -- and each random variable could be written as
having a fixed coefficient of 1:
$$1X_1 + 1 X_2 + 1 X_3 + 1 X_4 + 1 X_5$$ For Elena's net gain or loss,
the $X$ random variable had a coefficient of +1 and the $Y$ random
variable had a coefficient of -1.

When considering the average of a linear combination of random
variables, it is safe to plug in the mean of each random variable and
then compute the final result. For a few examples of nonlinear
combinations of random variables -- cases where we cannot simply plug in
the means -- see the footnote.[^45]

If $X$ and $Y$ are random variables, then a linear combination of the
random variables is given by $$\begin{aligned}
\label{linComboOfRandomVariablesXAndY}
aX + bY\end{aligned}$$ where $a$ and $b$ are some fixed numbers. To
compute the average value of a linear combination of random variables,
plug in the average of each individual random variable and compute the
result: $$\begin{aligned}
a\times E(X) + b\times E(Y)\end{aligned}$$ Recall that the expected
value is the same as the mean, e.g. $E(X) = \mu_X$.

Leonard has invested \$6000 in Google Inc. (stock ticker: GOOG) and
\$2000 in Exxon Mobil Corp. (XOM). If $X$ represents the change in
Google's stock next month and $Y$ represents the change in Exxon Mobil
stock next month, write an equation that describes how much money will
be made or lost in Leonard's stocks for the month. For simplicity, we
will suppose $X$ and $Y$ are not in percents but are in decimal form
(e.g. if Google's stock increases 1%, then $X=0.01$; or if it loses 1%,
then $X=-0.01$). Then we can write an equation for Leonard's gain as
$$\begin{aligned}
\$6000\times X + \$2000\times Y\end{aligned}$$ If we plug in the change
in the stock value for $X$ and $Y$, this equation gives the change in
value of Leonard's stock portfolio for the month. A positive value
represents a gain, and a negative value represents a loss.

[\[expectedChangeInLeonardsStockPortfolio\]]{#expectedChangeInLeonardsStockPortfolio
label="expectedChangeInLeonardsStockPortfolio"} Suppose Google and Exxon
Mobil stocks have recently been rising 2.1% and 0.4% per month,
respectively. Compute the expected change in Leonard's stock portfolio
for next month.[^46]

You should have found that Leonard expects a positive gain in Guided
Practice [\[expectedChangeInLeonardsStockPortfolio\]](#expectedChangeInLeonardsStockPortfolio){reference-type="ref"
reference="expectedChangeInLeonardsStockPortfolio"}. However, would you
be surprised if he actually had a loss this month?[^47]

### Variability in linear combinations of random variables

Quantifying the average outcome from a linear combination of random
variables is helpful, but it is also important to have some sense of the
uncertainty associated with the total outcome of that combination of
random variables. The expected net gain or loss of Leonard's stock
portfolio was considered in Guided
Practice [\[expectedChangeInLeonardsStockPortfolio\]](#expectedChangeInLeonardsStockPortfolio){reference-type="ref"
reference="expectedChangeInLeonardsStockPortfolio"}. However, there was
no quantitative discussion of the volatility of this portfolio. For
instance, while the average monthly gain might be about \$134 according
to the data, that gain is not guaranteed.
Figure [1.14](#changeInLeonardsStockPortfolioFor36Months){reference-type="ref"
reference="changeInLeonardsStockPortfolioFor36Months"} shows the monthly
changes in a portfolio like Leonard's during the 36 months from 2009 to
2011. The gains and losses vary widely, and quantifying these
fluctuations is important when investing in stocks.

![The change in a portfolio like Leonard's for the 36 months from 2009
to 2011, where \$6000 is in Google's stock and \$2000 is in Exxon
Mobil's.[]{label="changeInLeonardsStockPortfolioFor36Months"}](appendix-probability/figures/changeInLeonardsStockPortfolioFor36Months/changeInLeonardsStockPortfolioFor36Months){#changeInLeonardsStockPortfolioFor36Months
width="65%"}

Just as we have done in many previous cases, we use the variance and
standard deviation to describe the uncertainty associated with Leonard's
monthly returns. To do so, the variances of each stock's monthly return
will be useful, and these are shown in
Table [\[sumStatOfGOOGXOM\]](#sumStatOfGOOGXOM){reference-type="ref"
reference="sumStatOfGOOGXOM"}. The stocks' returns are nearly
independent.

           Mean ($\bar{x}$)   Standard deviation ($s$)   Variance ($s^2$)
  ------ ------------------ -------------------------- ------------------
  GOOG               0.0210                     0.0846             0.0072
  XOM                0.0038                     0.0519             0.0027

  : The mean, standard deviation, and variance of the GOOG and XOM
  stocks. These statistics were estimated from historical stock data, so
  notation used for sample statistics has been
  used.[]{label="sumStatOfGOOGXOM"}

Here we use an equation from probability theory to describe the
uncertainty of Leonard's monthly returns; we leave the proof of this
method to a dedicated probability course. The variance of a linear
combination of random variables can be computed by plugging in the
variances of the individual random variables and squaring the
coefficients of the random variables: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ It is
important to note that this equality assumes the random variables are
independent; if independence doesn't hold, then more advanced methods
are necessary. This equation can be used to compute the variance of
Leonard's monthly return: $$\begin{aligned}
Var(6000\times X + 2000\times Y)
    &= 6000^2\times Var(X) + 2000^2\times Var(Y) \\
    &= 36,000,000\times 0.0072 + 4,000,000\times 0.0027 \\
    &= 270,000\end{aligned}$$ The standard deviation is computed as the
square root of the variance: $\sqrt{270,000} = \$520$. While an average
monthly return of \$134 on an \$8000 investment is nothing to scoff at,
the monthly returns are so volatile that Leonard should not expect this
income to be very stable.

The variance of a linear combination of random variables may be computed
by squaring the constants, substituting in the variances for the random
variables, and computing the result: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ This
equation is valid as long as the random variables are independent of
each other. The standard deviation of the linear combination may be
found by taking the square root of the variance.

Suppose John's daily commute has a standard deviation of 4 minutes. What
is the uncertainty in his total commute time for the week?
[\[sdOfJohnsCommuteWeeklyTime\]]{#sdOfJohnsCommuteWeeklyTime
label="sdOfJohnsCommuteWeeklyTime"} The expression for John's commute
time was $$\begin{aligned}
X_1 + X_2 + X_3 + X_4 + X_5\end{aligned}$$ Each coefficient is 1, and
the variance of each day's time is $4^2=16$. Thus, the variance of the
total weekly commute time is $$\begin{aligned}
&\text{variance }= 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 = 5\times 16 = 80 \\
&\text{standard deviation } = \sqrt{\text{variance}} = \sqrt{80} = 8.94\end{aligned}$$
The standard deviation for John's weekly work commute time is about 9
minutes.

The computation in
Example [\[sdOfJohnsCommuteWeeklyTime\]](#sdOfJohnsCommuteWeeklyTime){reference-type="ref"
reference="sdOfJohnsCommuteWeeklyTime"} relied on an important
assumption: the commute time for each day is independent of the time on
other days of that week. Do you think this is valid? Explain.[^48]

[\[elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability\]]{#elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability
label="elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability"}
Consider Elena's two auctions from Guided
Practice [\[elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction\]](#elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction){reference-type="ref"
reference="elenaIsSellingATVAndBuyingAToasterOvenAtAnAuction"} on page .
Suppose these auctions are approximately independent and the variability
in auction prices associated with the TV and toaster oven can be
described using standard deviations of \$25 and \$8. Compute the
standard deviation of Elena's net gain.[^49]

Consider again Guided
Practice [\[elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability\]](#elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability){reference-type="ref"
reference="elenaIsSellingATVAndBuyingAToasterOvenAtAnAuctionVariability"}.
The negative coefficient for $Y$ in the linear combination was
eliminated when we squared the coefficients. This generally holds true:
negatives in a linear combination will have no impact on the variability
computed for a linear combination, but they do impact the expected value
computations.

[^1]: Here are four examples. (i) Whether someone gets sick in the next
    month or not is an apparently random process with outcomes and .
    (ii) We can *generate* a random process by randomly picking a person
    and measuring that person's height. The outcome of this process will
    be a positive number. (iii) Whether the stock market goes up or down
    next week is a seemingly random process with possible outcomes , ,
    and . Alternatively, we could have used the percent change in the
    stock market as a numerical outcome. (iv) Whether your roommate
    cleans her dishes tonight probably seems like a random process with
    possible outcomes and .

[^2]: \(a\) The random process is a die roll, and at most one of these
    outcomes can come up. This means they are disjoint outcomes.
    (b) $P($ or or
    $) = P($$)+P($$)+P($$) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2}$

[^3]: \(a\) Yes. Each email is categorized in only one level of . (b)
    Small: $\frac{2827}{3921} = 0.721$. Big: $\frac{545}{3921} = 0.139$.
    (c) $P($ or $) = P($$) + P($$) = 0.721 + 0.139 = 0.860$.

[^4]: \(a\) $P(A) = P($ or
    $) = P($$) + P($$) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}$.
    (b) Similarly, $P(B) = 1/3$.

[^5]: (a) Outcomes and . (b) Yes, events $B$ and $D$ are disjoint
    because they share no outcomes. (c) The events $A$ and $D$ share an
    outcome in common, , and so are not disjoint.

[^6]: Since $B$ and $D$ are disjoint events, use the Addition Rule:
    $P(B$ or
    $D) = P(B) + P(D) = \frac{1}{3} + \frac{1}{3} = \frac{2}{3}$.

[^7]: The 52 cards are split into four : $\clubsuit$ (club),
    $\diamondsuit$ (diamond), $\heartsuit$ (heart), $\spadesuit$
    (spade). Each suit has its 13 cards labeled: , , \..., , (jack),
    (queen), (king), and (ace). Thus, each card is a unique combination
    of a suit and a label, e.g. and . The 12 cards represented by the
    jacks, queens, and kings are called . The cards that are
    $\diamondsuit$ or $\heartsuit$ are typically colored red while the
    other two suits are typically colored black.

[^8]: \(a\) There are 52 cards and 13 diamonds. If the cards are
    thoroughly shuffled, each card has an equal chance of being drawn,
    so the probability that a randomly selected card is a diamond is
    $P({\color{redcards}\diamondsuit}) = \frac{13}{52} = 0.250$.
    (b) Likewise, there are 12 face cards, so $P($face
    card$) = \frac{12}{52} = \frac{3}{13} = 0.231$.

[^9]: The Venn diagram shows face cards split up into "face card but not
    $\diamondsuit$" and "face card and $\diamondsuit$". Since these
    correspond to disjoint events, $P($face card$)$ is found by adding
    the two corresponding probabilities:
    $\frac{3}{52} + \frac{9}{52} = \frac{12}{52} = \frac{3}{13}$.

[^10]: \(a\) If $A$ and $B$ are disjoint, $A$ and $B$ can never occur
    simultaneously. (b) If $A$ and $B$ are disjoint, then the last term
    of
    Equation ([\[generalAdditionRule\]](#generalAdditionRule){reference-type="ref"
    reference="generalAdditionRule"}) is 0 (see part (a)) and we are
    left with the Addition Rule for disjoint events.

[^11]: Both the counts and corresponding probabilities (e.g.
    $2659/3921 = 0.678$) are shown. Notice that the number of emails
    represented in the left circle corresponds to $2659 + 168 = 2827$,
    and the number represented in the right circle is $168 + 199 = 367$.

     

    ![image](appendix-probability/figures/emailSpamNumberVenn/emailSpamNumberVenn){height="13mm"}

[^12]: (a) The solution is represented by the intersection of the two
    circles: 0.043. (b) This is the sum of the three disjoint
    probabilities shown in the circles: $0.678 + 0.043 + 0.051 = 0.772$.

[^13]: The probabilities of (a) do not sum to 1. The second probability
    in (b) is negative. This leaves (c), which sure enough satisfies the
    requirements of a distribution. One of the three was said to be the
    actual distribution of US household incomes, so it must be (c).

[^14]: It is also possible to construct a distribution plot when income
    is not artificially binned into four groups.

[^15]: (a) The outcomes are disjoint and each has probability $1/6$, so
    the total probability is $4/6=2/3$. (b) We can also see that
    $P(D)=\frac{1}{6} + \frac{1}{6} = 1/3$. Since $D$ and $D^c$ are
    disjoint, $P(D) + P(D^c) = 1$.

[^16]: Brief solutions: (a) $A^c=\{$, , , $\}$ and $B^c=\{$, , , $\}$.
    (b) Noting that each outcome is disjoint, add the individual outcome
    probabilities to get $P(A^c)=2/3$ and $P(B^c)=2/3$.
    (c) $A$ and $A^c$ are disjoint, and the same is true of
    $B$ and $B^c$. Therefore, $P(A) + P(A^c) = 1$ and
    $P(B) + P(B^c) = 1$.

[^17]: (a) The complement of $A$: when the total is equal to .
    (b) $P(A^c) = 1/36$. (c) Use the probability of the complement from
    part (b), $P(A^c) = 1/36$, and
    Equation ([\[complement\]](#complement){reference-type="ref"
    reference="complement"}): $P($less than
    $) = 1 - P($$) = 1 - 1/36 = 35/36$.

[^18]: (a) First find $P($$)=5/36$, then use the complement: $P($not
    $) = 1 - P($$) = 31/36$. (b) First find the complement, which
    requires much less effort: $P($ or $)=1/36+2/36=1/12$. Then
    calculate $P(B) = 1-P(B^c) = 1-1/12 = 11/12$. (c) As before, finding
    the complement is the clever way to determine $P(D)$. First find
    $P(D^c) = P($ or $)=2/36 + 1/36=1/12$. Then calculate
    $P(D) = 1 - P(D^c) = 11/12$.

[^19]: \(a\) The probability the first person is left-handed is $0.09$,
    which is the same for the second person. We apply the Multiplication
    Rule for independent processes to determine the probability that
    both will be left-handed: $0.09\times 0.09 = 0.0081$.

    \(b\) It is reasonable to assume the proportion of people who are
    ambidextrous (both right and left handed) is nearly 0, which results
    in $P($right-handed$)=1-0.09=0.91$. Using the same reasoning as in
    part (a), the probability that both will be right-handed is
    $0.91\times 0.91 = 0.8281$.

[^20]: (a) The abbreviations and are used for right-handed and
    left-handed, respectively. Since each are independent, we apply the
    Multiplication Rule for independent processes: $$\begin{aligned}
    P(\text{all five are \resp{RH}})
    &= P(\text{first = \resp{RH}, second = \resp{RH}, ..., fifth = \resp{RH}}) \\
    &= P(\text{first = \resp{RH}})\times P(\text{second = \resp{RH}})\times  \dots \times P(\text{fifth = \resp{RH}}) \\
    &= 0.91\times 0.91\times 0.91\times 0.91\times 0.91 = 0.624\end{aligned}$$

    (b) Using the same reasoning as in (a),
    $0.09\times 0.09\times 0.09\times 0.09\times 0.09 = 0.0000059$

    (c) Use the complement, $P($all five are $)$, to answer this
    question: $$\begin{aligned}
    P(\text{not all \resp{RH}})
        = 1 - P(\text{all \resp{RH}})
        = 1 - 0.624 = 0.376\end{aligned}$$

[^21]: The actual proportion of the U.S. population that is is about
    50%, and so we use 0.5 for the probability of sampling a woman.
    However, this probability does differ in other countries.

[^22]: Brief answers are provided. (a) This can be written in
    probability notation as $P($a randomly selected person is male and
    right-handed$)=0.455$. (b) 0.207. (c) 0.045. (d) 0.0093.

[^23]: Ellis GJ and Stone LH. 1979. Marijuana Use in College: An
    Evaluation of a Modeling Explanation. Youth and Society 10:323-334.

[^24]: Each of the four outcome combination are disjoint, all
    probabilities are indeed non-negative, and the sum of the
    probabilities is $0.28 + 0.19 + 0.21 + 0.32 = 1.00$.

[^25]: This is an observational study and no causal conclusions may be
    reached.

[^26]: \(a\)
    $P(\text{\var{parent} = \resp{not}} | \text{\var{student} = \resp{not}})$.
    (b) Equation ([\[condProbEq\]](#condProbEq){reference-type="ref"
    reference="condProbEq"}) for conditional probability indicates we
    should first find
    $P(\text{\var{parents} = \resp{not} and \var{student} = \resp{not}})=0.32$
    and $P(\text{\var{student} = \resp{not}})=0.51$. Then the ratio
    represents the conditional probability: $0.32/0.51 = 0.63$.

[^27]: (a) This probability is
    $\frac{P(\text{\var{parents} = \resp{used} and \var{student} = \resp{not}})}{P(\text{\var{student} = \resp{not}})} = \frac{0.19}{0.51} = 0.37$.
    (b) The total equals 1. (c) Under the condition the student does not
    use drugs, the parents must either use drugs or not. The complement
    still appears to work *when conditioning on the same information*.

[^28]: No. This was an observational study. Two potential confounding
    variables include and . Can you think of others?

[^29]: Fenner F. 1988. *Smallpox and Its Eradication (History of
    International Public Health, No. 6)*. Geneva: World Health
    Organization. ISBN 92-4-156110-6.

[^30]: $P($ = $|$ =
    $) = \frac{P(\text{\var{result} = \resp{died} and \var{inoculated} = \resp{no}})}{P(\text{\var{inoculated} = \resp{no}})} = \frac{0.1356}{0.9608} = 0.1411$.

[^31]: $P($ = $|$ =
    $) = \frac{P(\text{\var{result} = \resp{died} and \var{inoculated} = \resp{yes}})}{P(\text{\var{inoculated} = \resp{yes}})} = \frac{0.0010}{0.0392} = 0.0255$.
    The death rate for individuals who were inoculated is only about
    1 in 40 while the death rate is about 1 in 7 for those who were not
    inoculated.

[^32]: Brief answers: (a) Observational. (b) No, we cannot infer
    causation from this observational study. (c) Accessibility to the
    latest and best medical care. There are other valid answers for
    part (c).

[^33]: The answer is 0.0382, which can be verified using
    Table [\[smallpoxProbabilityTable\]](#smallpoxProbabilityTable){reference-type="ref"
    reference="smallpoxProbabilityTable"}.

[^34]: There were only two possible outcomes: or . This means that 100%
    - 97.45% = 2.55% of the people who were inoculated died.

[^35]: The samples are large relative to the difference in death rates
    for the "inoculated" and "not inoculated" groups, so it seems there
    is an association between and . However, as noted in the solution to
    Guided
    Practice [\[SmallpoxInoculationObsExpExercise\]](#SmallpoxInoculationObsExpExercise){reference-type="ref"
    reference="SmallpoxInoculationObsExpExercise"}, this is an
    observational study and we cannot be sure if there is a causal
    connection. (Further research has shown that inoculation is
    effective at reducing death rates.)

[^36]: Brief solutions: (a) $1/6$. (b) $1/36$.
    (c) $\frac{P(Y = \text{ \resp{1} and }X=\text{ \resp{1}})}{P(X=\text{ \resp{1}})} = \frac{1/36}{1/6} = 1/6$.
    (d) The probability is the same as in part (c): $P(Y=1)=1/6$. The
    probability that $Y=1$ was unchanged by knowledge about $X$, which
    makes sense as $X$ and $Y$ are independent.

[^37]: He has forgotten that the next roulette spin is independent of
    the previous spins. Casinos do employ this practice; they post the
    last several outcomes of many betting games to trick unsuspecting
    gamblers into believing the odds are in their favor. This is called
    the .

[^38]: \(a\) The tree diagram is shown to the right. (b) Identify which
    two joint probabilities represent students who passed, and add them:
    $P($passed$) = 0.7566+0.1254= 0.8820$. (c) $P($construct tree
    diagram $|$ passed$) = \frac{0.7566}{0.8820} = 0.8578$.\
     

    ![image](appendix-probability/figures/treeDiagramAndPass/treeDiagramAndPass){width="\\textwidth"}

[^39]: If they sell a little more or a little less, this should not be a
    surprise. Hopefully
    Chapter [\[introductionToData\]](#introductionToData){reference-type="ref"
    reference="introductionToData"} helped make clear that there is
    natural variability in observed data. For example, if we would flip
    a coin 100 times, it will not usually come up heads exactly half the
    time, but it will probably be close.

[^40]: $\mu = \int xf(x)dx$ where $f(x)$ represents a function for the
    density curve.

[^41]: \(a\) 100% - 25% - 60% = 15% of students do not buy any books for
    the class. Part (b) is represented by the first two lines in the
    table below. The expectation for part (c) is given as the total on
    the line $y_i\times P(Y=y_i)$. The result of part (d) is the
    square-root of the variance listed on in the total on the last line:
    $\sigma = \sqrt{Var(Y)} = \$69.28$.

                   $i$ (scenario)       1 ()     2 ()      3 ()                   Total
      --------------------------- ---------- -------- --------- -----------------------
                            $y_i$       0.00   159.00    200.00 
                       $P(Y=y_i)$       0.15     0.25      0.60 
             $y_i\times P(Y=y_i)$       0.00    39.75    120.00         $E(Y) = 159.75$
                       $y_i-E(Y)$    -159.75    -0.75     40.25 
                   $(y_i-E(Y))^2$   25520.06     0.56   1620.06 
        $(y_i-E(Y))^2\times P(Y)$     3828.0      0.1     972.0   $Var(Y) \approx 4800$

[^42]: She will make $X$ dollars on the TV but spend $Y$ dollars on the
    toaster oven: $X-Y$.

[^43]: $E(X-Y) = E(X) - E(Y) = 175 - 23 = \$152$. She should expect to
    make about \$152.

[^44]: No, since there is probably some variability. For example, the
    traffic will vary from one day to next, and auction prices will vary
    depending on the quality of the merchandise and the interest of the
    attendees.

[^45]: If $X$ and $Y$ are random variables, consider the following
    combinations: $X^{1+Y}$, $X\times Y$, $X/Y$. In such cases, plugging
    in the average value for each random variable and computing the
    result will not generally lead to an accurate average value for the
    end result.

[^46]: $E(\$6000\times X + \$2000\times Y) = \$6000\times 0.021 + \$2000\times 0.004 = \$134$.

[^47]: No. While stocks tend to rise over time, they are often volatile
    in the short term.

[^48]: One concern is whether traffic patterns tend to have a weekly
    cycle (e.g. Fridays may be worse than other days). If that is the
    case, and John drives, then the assumption is probably not
    reasonable. However, if John walks to work, then his commute is
    probably not affected by any weekly traffic cycle.

[^49]: The equation for Elena can be written as $$\begin{aligned}
    (1)\times X + (-1)\times Y\end{aligned}$$ The variances of $X$ and
    $Y$ are 625 and 64. We square the coefficients and plug in the
    variances: $$\begin{aligned}
    (1)^2\times Var(X) + (-1)^2\times Var(Y) = 1\times 625 + 1\times 64 = 689\end{aligned}$$
    The variance of the linear combination is 689, and the standard
    deviation is the square root of 689: about \$26.25.
    
    
    
    
    
    

