
Probability
===========

Probability forms a foundation for statistics. You might already be
familiar with many aspects of probability, however, formalization of the
concepts is new for most. This chapter aims to introduce probability on
familiar terms using processes most people have seen before.

Defining probability {#basicsOfProbability}
--------------------
### Intro Questions
**Q1**: A "die", the singular of dice, is a cube with six faces numbered *1*,
*2*, *3*, *4*, *5*, and *6*. What is the chance of getting *1* when
rolling a die

> **S1**: If the die is
> fair, then the chance of a *1* is as good as the chance of any other
> number. Since there are six outcomes, the chance must be 1-in-6 or,
> equivalently, $1/6$.

**Q2**: What is the chance of getting a *1* or *2* in the next
roll
 
> **S2**: *1* and *2*
> constitute two of the six equally likely possible outcomes, so the
> chance of getting one of these two outcomes must be $2/6 = 1/3$.

**Q3**: What is the chance of getting either *1*, *2*, *3*, *4*, *5*, or *6* on
the next roll
 

> **S3**: 100%. The outcome must be one of these numbers.

**Q4**: What is the chance of not rolling a *2*
 
> **S4**: Since the chance of rolling a *2* is $1/6$ or
> $16.\bar{6}\%$, the chance of not rolling a *2* must be
> $100\% - 16.\bar{6}\%=83.\bar{3}\%$ or $5/6$.
> 
> Alternatively, we could have noticed that not rolling a *2* is the same
> as getting a *1*, *3*, *4*, *5*, or *6*, which makes up five of the six
> equally likely outcomes and has probability $5/6$.

**Q5**: Consider rolling two dice. If $1/6^{th}$ of the time the first die is a
*1* and $1/6^{th}$ of those times the second die is a *1*, what is the
chance of getting two *1*s
 
> **S**: If $16.\bar{6}$% of the time the first die is a *1*
> and $1/6^{th}$ of *those* times the second die is also a *1*, then the
> chance that both dice are *1* is $(1/6)\times (1/6)$ or $1/36$.

### Probability

We use probability to build tools to describe and understand apparent
randomness. We often frame probability in terms of a **random process** giving rise to an .

  ------------- --------------- ---------------------------------
  Roll a die    $\rightarrow$   *1*, *2*, *3*, *4*, *5*, or *6*
  Flip a coin   $\rightarrow$   *H* or *T*
  ------------- --------------- ---------------------------------

Rolling a die or flipping a coin is a seemingly random process and each
gives rise to an outcome.



**Def of Probability**

> The **probability** of an outcome is the proportion of times the outcome would occur if
> we observed the random process an infinite number of times.


Probability is defined as a proportion, and it always takes values
between 0 and 1 (inclusively). It may also be displayed as a percentage
between 0% and 100%.

Probability can be illustrated by rolling a die many times. Let
$\hat{p}_n$ be the proportion of outcomes that are *1* after the first
$n$ rolls. As the number of rolls increases, $\hat{p}_n$ will converge
to the probability of rolling a *1*, $p = 1/6$.
Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"} shows
this convergence for 100,000 die rolls. The tendency of $\hat{p}_n$ to
stabilize around $p$ is described by the **Law of Large Numbers**.

![The fraction of die rolls that are 1 at each stage in a simulation.
The proportion tends to get closer to the probability
$1/6 \approx 0.167$ as the number of rolls
increases.[]{label="dieProp"}](figures/dieProp/dieProp.png){#dieProp
width="80%"}


**Def of Law of Large Numbers**

> As more observations are collected, the proportion $\hat{p}_n$ of
> occurrences with a particular outcome converges to the probability $p$
> of that outcome.


Occasionally the proportion will veer off from the probability and
appear to defy the Law of Large Numbers, as $\hat{p}_n$ does many times
in Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"}.
However, these deviations become smaller as the number of rolls
increases.

Above we write $p$ as the probability of rolling a *1*. We can also
write this probability as $$\begin{aligned}
P(\text{rolling a 1})\end{aligned}$$ As we become more
comfortable with this notation, we will abbreviate it further. For
instance, if it is clear that the process is "rolling a die", we could
abbreviate $P($rolling a *1*$)$ as $P($*1*$)$.

**Guided Practice**

Random processes include rolling a die
and flipping a coin. 

(a) Think of another random process. 
(b) Describe
all the possible outcomes of that process. For instance, rolling a die
is a random process with potential outcomes *1*, *2*, \..., *6*.[^1]


What we think of as random processes are not necessarily random, but
they may just be too difficult to understand exactly. The fourth example
in the footnote solution to Guided
Practice suggests a roommate's behavior is a
random process. However, even if a roommate's behavior is not truly
random, modeling her behavior as a random process can still be useful.

**Tip**

It can be helpful to model a process as random even if it is not truly
random.

### Disjoint or mutually exclusive outcomes

Two outcomes are called **disjoint** or **mutually exclusive** if they cannot both happen. For instance, if
we roll a die, the outcomes *1* and *2* are disjoint since they cannot
both occur. On the other hand, the outcomes *1* and "rolling an odd
number" are not disjoint since both occur if the outcome of the roll is
a *1*. The terms *disjoint* and *mutually exclusive* are equivalent and
interchangeable.

Calculating the probability of disjoint outcomes is easy. When rolling a
die, the outcomes *1* and *2* are disjoint, and we compute the
probability that one of these outcomes will occur by adding their
separate probabilities: $$\begin{aligned}
P(\text{1 or 2}) = P(\text{1})+P(\text{2}) = 1/6 + 1/6 = 1/3\end{aligned}$$
What about the probability of rolling a *1*, *2*, *3*, *4*, *5*, or *6*
 

Here again, all of the outcomes are disjoint so we add the
probabilities: $$\begin{aligned}
&&P(\text{1 or 2 or 3 or 4 or 5 or 6}) \\
    &&\quad= P(\text{1})+P(\text{2})+P(\text{3})+P(\text{4})+P(\text{5})+P(\text{6}) \\
    &&\quad= 1/6 + 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 1.\end{aligned}$$ The **Addition Rule**
guarantees the accuracy of this approach when the outcomes are disjoint.

**Addition Rule of disjoint outcomes**

If $A_1$ and $A_2$ represent two disjoint outcomes, then the probability
that one of them occurs is given by $$\begin{aligned}
P(A_1\text{ or } A_2) = P(A_1) + P(A_2)\end{aligned}$$ If there are many
disjoint outcomes $A_1$, \..., $A_k$, then the probability that one of
these outcomes will occur is $$\begin{aligned}
P(A_1) + P(A_2) + \cdots + P(A_k)\end{aligned}$$


**Guided Practice**

We are interested in the probability of rolling a *1*, *4*, or *5*.

  (a) Explain why the outcomes *1*, *4*, and *5* are disjoint.
  
  (b) Apply the
Addition Rule for disjoint outcomes to determine $P($*1* or *4* or
*5*$)$.[^2]
 

Statisticians rarely work with individual outcomes and instead consider
or of outcomes. Let $A$ represent the event where a die roll results in
*1* or *2* and $B$ represent the event that the die roll is a *4* or a
*6*. We write $A$ as the set of outcomes $\{$*1*, *2*$\}$ and $B=\{$*4*,
*6*$\}$. These sets are commonly called . Because $A$ and $B$ have no
elements in common, they are disjoint events. $A$ and $B$ are
represented in Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"}.

![Three events, $A$, $B$, and $D$, consist of outcomes from rolling a
die. $A$ and $B$ are disjoint since they do not have any outcomes in
common.[]{label="disjointSets"}](figures/disjointSets/disjointSets.png){#disjointSets
height="0.7in"}

The Addition Rule applies to both disjoint outcomes and disjoint events.
The probability that one of the disjoint events $A$ or $B$ occurs is the
sum of the separate probabilities: $$\begin{aligned}
P(A\text{ or }B) = P(A) + P(B) = 1/3 + 1/3 = 2/3\end{aligned}$$

(a) Verify the probability of event $A$, $P(A)$, is $1/3$ using the
Addition Rule.
(b) Do the same for event $B$.[^4]

(a) Using
Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} as a reference, what outcomes are represented
by event $D$
 
 (b) Are events $B$ and $D$ disjoint
 
 (c) Are events $A$
and $D$ disjoint
 
[^5]

In the Guided
Practice above, you confirmed $B$ and $D$
from Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} are disjoint. Compute the probability that
either event $B$ or event $D$ occurs.[^6]

### Probabilities when events are not disjoint

Let's consider calculations for two events that are not disjoint in the
context of a , represented in
Table below. If you are unfamiliar with the cards in a
regular deck, please see the footnote.[^7]

  ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- -------------------- ------------------- ------------------- ------------------- -------------------
  *2$\clubsuit$*      *3$\clubsuit$*      *4$\clubsuit$*      *5$\clubsuit$*      *6$\clubsuit$*      *7$\clubsuit$*      *8$\clubsuit$*      *9$\clubsuit$*      *10$\clubsuit$*      *J$\clubsuit$*      *Q$\clubsuit$*      *K$\clubsuit$*      *A$\clubsuit$*
  *2$\diamondsuit$*   *3$\diamondsuit$*   *4$\diamondsuit$*   *5$\diamondsuit$*   *6$\diamondsuit$*   *7$\diamondsuit$*   *8$\diamondsuit$*   *9$\diamondsuit$*   *10$\diamondsuit$*   *J$\diamondsuit$*   *Q$\diamondsuit$*   *K$\diamondsuit$*   *A$\diamondsuit$*
  *2$\heartsuit$*     *3$\heartsuit$*     *4$\heartsuit$*     *5$\heartsuit$*     *6$\heartsuit$*     *7$\heartsuit$*     *8$\heartsuit$*     *9$\heartsuit$*     *10$\heartsuit$*     *J$\heartsuit$*     *Q$\heartsuit$*     *K$\heartsuit$*     *A$\heartsuit$*
  *2$\spadesuit$*     *3$\spadesuit$*     *4$\spadesuit$*     *5$\spadesuit$*     *6$\spadesuit$*     *7$\spadesuit$*     *8$\spadesuit$*     *9$\spadesuit$*     *10$\spadesuit$*     *J$\spadesuit$*     *Q$\spadesuit$*     *K$\spadesuit$*     *A$\spadesuit$*
  ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- -------------------- ------------------- ------------------- ------------------- -------------------

  : Representations of the 52 unique cards in a
  deck.[]{label="deckOfCards"}

**Guided Practice**

(a) What is the probability that a randomly selected card is a
diamond
 

(b) What is the probability that a randomly selected card is a
face card
 
[^8]

**Venn diagrams** are useful when outcomes can be categorized as "in" or "out" for two or
three variables, attributes, or random processes. The Venn diagram in
Figure [1.3](#venn){reference-type="ref" reference="venn"} uses a circle
to represent diamonds and another to represent face cards. If a card is
both a diamond and a face card, it falls into the intersection of the
circles. If it is a diamond but not a face card, it will be in part of
the left circle that is not in the right circle (and so on). The total
number of cards that are diamonds is given by the total number of cards
in the diamonds circle: $10+3=13$. The probabilities are also shown
(e.g. $10/52 = 0.1923$).

![A Venn diagram for diamonds and face
cards.[]{label="venn"}](figures/venn/venn.png){#venn height="1.4in"}

**Guided Practice**

(a) Using the Venn diagram, verify $P($face card$) = 12/52=3/13$.[^9]

Let $A$ represent the event that a randomly selected card is a diamond
and $B$ represent the event that it is a face card. How do we compute
$P(A$ or $B)$
 
 Events $A$ and $B$ are not disjoint -- the cards
$J\diamondsuit$, $Q\diamondsuit$, and $K\diamondsuit$ fall into both
categories -- so we cannot use the Addition Rule for disjoint events.
Instead we use the Venn diagram. We start by adding the probabilities of
the two events: $$\begin{aligned}
P(A) + P(B) = P({\color{redcards}\diamondsuit}) + P(\text{face card}) = 12/52 + 13/52
\label{overCountFaceDiamond}\end{aligned}$$ However, the three cards
that are in both events were counted twice, once in each probability. We
must correct this double counting: $$\begin{aligned}
P(A\text{ or } B) &=&P(\text{face card or }{\color{redcards}\diamondsuit})  \notag \\
 &=& P(\text{face card}) + P({\color{redcards}\diamondsuit}) - P(\text{face card and }{\color{redcards}\diamondsuit}) \label{diamondFace} \\
 &=& 12/52 + 13/52 - 3/52 \notag \\
 &=& 22/52 = 11/26 \notag\end{aligned}$$
The Equation above is an example of the **General Addition Rule**.

**General Addition Rule**

> If $A$ and $B$ are any two events, disjoint or not, then the probability
> that at least one of them will occur is $$\begin{aligned}
> P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and }B)
> \label{generalAdditionRule}\end{aligned}$$ where $P(A$ and $B)$ is the
> probability that both events occur.

**Tip**

> When we write "or" in statistics, we mean "and/or" unless we explicitly
> state otherwise. Thus, $A$ or $B$ occurs means $A$, $B$, or both $A$ and
> $B$ occur.

**Guided Practice**

(a) If $A$ and $B$ are disjoint, describe why this implies $P(A$ and
$B) = 0$.
(b) Using part (a), verify that the General Addition Rule
simplifies to the simpler Addition Rule for disjoint events if $A$ and
$B$ are disjoint.[^10]

(c) In a given email data set with 3,921 emails, 367
were spam, 2,827 contained some small numbers but no big numbers, and
168 had both characteristics. Create a Venn diagram for this setup.[^11]

(d) Use your Venn diagram from (c) to determine the probability a
randomly drawn email from the data set is spam and had small numbers
(but not big numbers).

(e) What is the probability that the email had
either of these attributes
 
[^12]

### Probability distributions

A **Probability distribution** is a table of all disjoint outcomes and their associated
probabilities. The table below shows the probability distribution for the sum of
two dice.

  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
                                                                                                                                                                                          
  Dice sum             2                3                4                5                6                7                8                9                10               11               12
  Probability    $\frac{1}{36}$   $\frac{2}{36}$   $\frac{3}{36}$   $\frac{4}{36}$   $\frac{5}{36}$   $\frac{6}{36}$   $\frac{5}{36}$   $\frac{4}{36}$   $\frac{3}{36}$   $\frac{2}{36}$   $\frac{1}{36}$
  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------

  : Probability distribution for the sum of two
  dice.[]{label="diceProb"}

**Rules for probability distributions**

> A probability distribution is a list of the possible outcomes with
corresponding probabilities that satisfies three rules:

> 1.  The outcomes listed must be disjoint.
> 2.  Each probability must be between 0 and 1.
> 3.  The probabilities must total 1.

**Guided Practice**
The table below suggests three distributions for
household income in the United States. Only one is correct. Which one
must it be?
 
 What is wrong with the other two
 
[^13]

    Income range (\$1000s)   0-25   25-50   50-100   100+
  ------------------------ ------ ------- -------- ------
                     \(a\)   0.18    0.39     0.33   0.16
                     \(b\)   0.38   -0.27     0.52   0.37
                     \(c\)   0.28    0.27     0.29   0.16

  : Proposed distributions of US household incomes.[]{label="usHouseholdIncomeDists"}

Probability distributions can also be
summarized in a bar plot. For instance, the distribution of US household
incomes is shown in
Figure [1.4](#usHouseholdIncomeDistBar){reference-type="ref"
reference="usHouseholdIncomeDistBar"} as a bar plot.[^14] The
probability distribution for the sum of two dice is shown in
the table at the begining of the probability distributions section and plotted in
Figure [1.5](#diceSumDist){reference-type="ref"
reference="diceSumDist"}.

![The probability distribution of US household
income.[]{label="usHouseholdIncomeDistBar"}](figures/usHouseholdIncomeDistBar/usHouseholdIncomeDistBar.png){#usHouseholdIncomeDistBar
width="68%"}

![The probability distribution of the sum of two
dice.[]{label="diceSumDist"}](figures/diceSumDist/diceSumDist.png){#diceSumDist
width="73%"}

In these bar plots, the bar heights represent the probabilities of
outcomes. If the outcomes are numerical and discrete, it is usually
(visually) convenient to make a bar plot that resembles a histogram, as
in the case of the sum of two dice. Another example of plotting the bars
at their respective locations is shown in
Figure [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} on page .

### Complement of an event

Rolling a die produces a value in the set $\{$*1*, *2*, *3*, *4*, *5*,
*6*$\}$. This set of all possible outcomes is called the **sample space** ($S$) for
rolling a die. We often use the sample space to examine the scenario
where an event does not occur.

Let $D=\{$*2*, *3*$\}$ represent the event that the outcome of a die
roll is *2* or *3*. Then the **complement** of $D$ represents all outcomes in our
sample space that are not in $D$, which is denoted by $D^c = \{$*1*,
*4*, *5*, *6*$\}$. That is, $D^c$ is the set of all possible outcomes
not already included in $D$.
Figure [1.6](#complementOfD){reference-type="ref"
reference="complementOfD"} shows the relationship between $D$, $D^c$,
and the sample space $S$.

![Event $D=\{$*2*, *3*$\}$ and its complement, $D^c = \{$*1*, *4*, *5*,
*6*$\}$. $S$ represents the sample space, which is the set of all
possible
events.[]{label="complementOfD"}](figures/complementOfD/complementOfD.png){#complementOfD
width="40%"}

**Guided Practice**

(a) Compute $P(D^c) = P($rolling a *1*, *4*, *5*, or *6*$)$.

(b) What
is $P(D) + P(D^c)$
 
[^15]

Events $A=\{$*1*, *2*$\}$ and $B=\{$*4*, *6*$\}$ are shown in
Figure [1.2](#disjointSets){reference-type="ref"
reference="disjointSets"} on page .

**Guided Practice**

  (a) Write out what $A^c$ and $B^c$
represent.

  (b) Compute $P(A^c)$ and $P(B^c)$.
  
  (c) Compute $P(A)+P(A^c)$
and $P(B)+P(B^c)$.[^16]

A complement of an event $A$ is constructed to have two very important
properties: (i) every possible outcome not in $A$ is in $A^c$, and (ii)
$A$ and $A^c$ are disjoint. Property (i) implies $$\begin{aligned}
P(A\text{ or }A^c) = 1
\label{complementSumTo1}\end{aligned}$$ That is, if the outcome is not
in $A$, it must be represented in $A^c$. We use the Addition Rule for
disjoint events to apply Property (ii): $$\begin{aligned}
P(A\text{ or }A^c) = P(A) + P(A^c)
\label{complementDisjointEquation}\end{aligned}$$ Combining
the Equations above yields a very useful
relationship between the probability of an event and its complement.

**Complement**

> The complement of event $A$ is denoted $A^c$, and $A^c$ represents all
> outcomes not in $A$. $A$ and $A^c$ are mathematically related:
> $$\begin{aligned}
> \label{complement}
>  P(A) + P(A^c) = 1, \quad\text{i.e.}\quad P(A) = 1-P(A^c)\end{aligned}$$

In simple examples, computing $A$ or $A^c$ is feasible in a few steps.
However, using the complement can save a lot of time as problems grow in
complexity.

**Guided Practice**

Let $A$ represent the event where we roll two dice and their total is
less than *12*.

  (a) What does the event $A^c$ represent
 
  (b) Determine
$P(A^c)$ from the die sum table at the begining of the probability distribution section.

  (c) Determine $P(A)$.[^17]

Consider again the probabilities from
rolling two dice as in the table at the section on probability distributions. Find the following
probabilities:

  (a) The sum of the dice is *not* *6*.
  
  (b) The sum is at
least *4*, i.e. $\{$*4*, *5*, \..., *12*$\}$.

  (c) The sum is no more
than *10*. That is, determine the probability of the event $D=\{$*2*,
*3*, \..., *10*$\}$.[^18]

### Independence {#probabilityIndependence}

Just as variables and observations can be independent, random processes
can be independent, too. Two processes are **independent** if knowing the outcome of one
provides no useful information about the outcome of the other. For
instance, flipping a coin and rolling a die are two independent
processes -- knowing the coin was heads does not help determine the
outcome of a die roll. On the other hand, stock prices usually move up
or down together, so they are not independent.

The rolling two dice is a basic example of this. We want to determine the probability that
both will be *1*. Suppose one of the dice is red and the other white. If
the outcome of the red die is a *1*, it provides no information about
the outcome of the white die. We first encountered this same question in
in Q5 at the begining of this chapter, where we calculated the probability
using the following reasoning: $1/6^{th}$ of the time the red die is a
*1*, and $1/6^{th}$ of *those* times the white die will also be *1*.
This is illustrated in
Figure [1.7](#indepForRollingTwo1s){reference-type="ref"
reference="indepForRollingTwo1s"}. Because the rolls are independent,
the probabilities of the corresponding outcomes can be multiplied to get
the final answer: $(1/6)\times(1/6)=1/36$. This can be generalized to
many independent processes.

![$1/6^{th}$ of the time, the first roll is a *1*. Then $1/6^{th}$ of
*those* times, the second roll will also be a
*1*.[]{label="indepForRollingTwo1s"}](figures/indepForRollingTwo1s/indepForRollingTwo1s.png){#indepForRollingTwo1s
width="65%"}

**Example**
What if there was also a blue die independent of the other two?
 
 What is
the probability of rolling the three dice and getting all
*1*s?
 
If $1/36^{th}$ of the time the white and red
dice are both *1*, then $1/6^{th}$ of *those* times the blue die will
also be *1*, so multiply: $$\begin{aligned}
P(white=\text{1 and } red=\text{1 and } blue=\text{1})
    &= P(white=\text{1})\times P(red=\text{1})\times P(blue=\text{1}) \\
    &= (1/6)\times (1/6)\times (1/6)
    = 1/216\end{aligned}$$

The example above illustrate what is called the Multiplication Rule
for independent processes.

**Multiplication Rule for independent processes**

> If $A$ and $B$ represent events from two different and independent
processes, then the probability that both $A$ and $B$ occur can be
calculated as the product of their separate probabilities:
$$\begin{aligned}
\label{eqForIndependentEvents}
P(A \text{ and }B) = P(A) \times  P(B)\end{aligned}$$ Similarly, if
there are $k$ events $A_1$, \..., $A_k$ from $k$ independent processes,
then the probability they all occur is $$\begin{aligned}
P(A_1) \times  P(A_2)\times  \cdots \times  P(A_k)\end{aligned}$$

**Guided Practice**

About 9% of
people are left-handed. Suppose 2 people are selected at random from the
U.S. population. Because the sample size of 2 is very small relative to
the population, it is reasonable to assume these two people are
independent.

  (a) What is the probability that both are left-handed
 

  (b) What is the probability that both are right-handed
 
[^19]

**Guided Practice**

 Suppose 5
people are selected at random.[^20]

1.  What is the probability that all are right-handed
 


2.  What is the probability that all are left-handed
 


3.  What is the probability that not all of the people are right-handed
 


Suppose the variables handedness and gender are independent, i.e. knowing someone's gender
provides no useful information about their handedness and vice-versa. Then we can
compute whether a randomly selected person is right-handed and
female[^21] using the Multiplication Rule: $$\begin{aligned}
P(\text{right-handed and female}) &=& P(\text{right-handed}) \times  P(\text{female}) \\
&=& 0.91 \times  0.50 = 0.455\end{aligned}$$

**Guided Practice**

Three people are selected at random.[^22]

1.  What is the probability that the first person is male and
    right-handed
 


2.  What is the probability that the first two people are male and
    right-handed
 


3.  What is the probability that the third person is female and
    left-handed
 


4.  What is the probability that the first two people are male and
    right-handed and the third person is female and left-handed
 


Sometimes we wonder if one outcome provides useful information about
another outcome. The question we are asking is, are the occurrences of
the two events independent
 
 We say that two events $A$ and $B$ are
independent if they satisfy
$$P(A \text{ and }B) = P(A) \times  P(B)$$

**Example**

If we shuffle up a deck of cards and draw one, is the event that the
card is a heart independent of the event that the card is an ace
 
 The
probability the card is a heart is $1/4$ and the probability that it is
an ace is $1/13$. The probability the card is the ace of hearts is
$1/52$. We check whether
$P(A \text{ and }B) = P(A) \times  P(B)$ is satisfied: $$\begin{aligned}
P({\color{redcards}\heartsuit})\times P(\text{ace}) = \frac{1}{4}\times \frac{1}{13} = \frac{1}{52} 
                    = P({\color{redcards}\heartsuit}\text{ and ace})\end{aligned}$$
Because the equation holds, the event that the card is a heart and the
event that the card is an ace are independent events.

Conditional probability {#conditionalProbabilitySection}
-----------------------

Are students more likely to use marijuana when their parents used drugs
 

The data set contains a sample of 445 cases with two variables, students and parents,
and is summarized in the table below.[^23] The variable is either *uses*
or *not*, where a student is labeled as if she has recently used
marijuana. The student variable takes the value *used* if at least one of the
parents used drugs, including alcohol.

  --------- -------- -------- ------- ------- -- --
                       *used*   *not*   Total    
            *uses*        125      94     219    
            *not*          85     141     226    
            Total         210     235     445    
  --------- -------- -------- ------- ------- -- --

  : Contingency table summarizing the data
  set.[]{label="contTableOfParStDrugUse"}

![A Venn diagram using boxes for the data
set.[]{label="drugUseVenn"}](figures/drugUseVenn/drugUseVenn.png){#drugUseVenn
width="65%"}

**Example**

If at least one parent used drugs, what is the chance their child ()
uses
 
 We will estimate this probability using the data. Of the 210 cases
in this data set where = *used*, 125 represent cases where = *uses*:
$$\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}$$

**Example**

A student is randomly selected from the study and she does not use
drugs. What is the probability that at least one of her parents
used
 
If the student does not use
drugs, then she is one of the 226 students in the second row. Of these
226 students, 85 had at least one parent who used drugs:
$$\begin{aligned}
P(\text{parents = used given student = not}) = \frac{85}{226} = 0.376\end{aligned}$$

### Marginal and joint probabilities {#marginalAndJointProbabilities}

The Table below includes row and column totals for each
variable separately in the data set. These totals represent **marginal probabilities** for the
sample, which are the probabilities based on a single variable without
conditioning on any other variables. For instance, a probability based
solely on the variable is a marginal probability: $$\begin{aligned}
P(\text{student = uses}) = \frac{219}{445} = 0.492\end{aligned}$$
A probability of outcomes for two or more variables or processes is
called a **joint probability**: $$\begin{aligned}
P(\text{student = uses and parents = not}) = \frac{94}{445} = 0.21\end{aligned}$$
It is common to substitute a comma for "and" in a joint probability,
although either is acceptable.

               : *used*   : *not*   Total
  ---------- ---------- --------- -------
  : *uses*         0.28      0.21    0.49
  : *not*          0.19      0.32    0.51
  Total            0.47      0.53    1.00

  : Probability table summarizing parental and student drug
  use.[]{label="drugUseProbTable"}

**Marginal and joint Probabilities**

> If a probability is based on a single variable, it is a *marginal
> probability*. The probability of outcomes for two or more variables or
> processes is called a *joint probability*.

We use **table proportions** to summarize joint probabilities for the sample. These
proportions are computed by dividing each count in the first table by 445 to obtain the proportions in
the second table. The joint probability distribution of the
and variables is shown in
the table below.

  Joint outcome         Probability
  -------------------- -------------
  = *used*, = *uses*       0.28
  = *used*, = *not*        0.19
  = *not*, = *uses*        0.21
  = *not*, = *not*         0.32
  Total                    1.00

  : A joint probability distribution for the data
  set.[]{label="drugUseDistribution"}

**Guided Practice**

Verify
that the table above represents a probability distribution:
events are disjoint, all probabilities are non-negative, and the
probabilities sum to 1.[^24]


We can compute marginal probabilities using joint probabilities in
simple cases. For example, the probability a random student from the
study uses drugs is found by summing the outcomes from
the table above where = *uses*: $$\begin{aligned}
&&P(\text{student = uses}) \\
&& \quad =  P(\text{parents = used, student = uses}) + \\
&& \quad \quad \quad \quad P(\text{parents = not, student = uses}) \\
&& \quad = 0.28 + 0.21 = 0.49\end{aligned}$$

### Defining conditional probability

There is some connection between drug use of parents and of the student:
drug use of one is associated with drug use of the other.[^25] In this
section, we discuss how to use information about associations between
two variables to improve probability estimation.

The probability that a random student from the study uses drugs is 0.49.
Could we update this probability if we knew that this student's parents
used drugs
 
 Absolutely. To do so, we limit our view to only those 210
cases where parents used drugs and look at the fraction where the
student uses drugs: $$\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}$$
We call this a **conditional probability** because we computed the probability under a condition: =
*used*. There are two parts to a conditional probability, **the outcome of interest** and the **condition** . It
is useful to think of the condition as information we know to be true,
and this information usually can be described as a known outcome
or event.

We separate the text inside our probability notation into the outcome of
interest and the condition: $$\begin{aligned}
&& P(\text{student = uses given parents = used}) \notag \\
&& = P(\text{student = uses } | \text{ parents = used}) = \frac{125}{210} = 0.60
\label{probStudentUsedIfParentsUsedInFormalNotation}\end{aligned}$$ The
vertical bar "$|$" is read as *given*.

In
the Equation above, we computed
the probability a student uses based on the condition that at least one
parent used as a fraction: $$\begin{aligned}
&& P(\text{student = uses } | \text{ parents = used}) \notag \\
&&\quad = \frac{\text{#times student = uses and parents = used}}{\text{#times parents = used}} \label{ratioOfBothToRatioOfConditionalForParentsAndStudent} \\
&&\quad = \frac{125}{210} = 0.60 \notag\end{aligned}$$ We considered
only those cases that met the condition, = *used*, and then we computed
the ratio of those cases that satisfied our outcome of interest, the
student uses.

Counts are not always available for data, and instead only marginal and
joint probabilities may be provided. For example, disease rates are
commonly listed in percentages rather than in a count format. We would
like to be able to compute conditional probabilities even when no counts
are available, and we use
the equation above as an
example demonstrating this technique.

We considered only those cases that satisfied the condition, = *used*.
Of these cases, the conditional probability was the fraction who
represented the outcome of interest, = *uses*. Suppose we were provided
only the information in
the second table of this section i.e. only probability data. Then if we
took a sample of 1000 people, we would anticipate about 47% or
$0.47\times 1000 = 470$ would meet our information criterion. Similarly,
we would expect about 28% or $0.28\times 1000 = 280$ to meet both the
information criterion and represent our outcome of interest. Thus, the
conditional probability could be computed: $$\begin{aligned}
P(\text{student = uses } | \text{ parents = used})
    &= \frac{\text{#(student = uses and parents = used)}}{\text{#(parents = used)}} \notag \\
    &= \frac{280}{470} = \frac{0.28}{0.47} = 0.60
\label{stUserPUsedHypSampSize}\end{aligned}$$ In
In the equation above, we examine exactly the fraction of
two probabilities, 0.28 and 0.47, which we can write as
$$\begin{aligned}
P(student = uses\ \text{and}\ parents = used)
    \quad\text{and}\quad
    P(parents = used).\end{aligned}$$ The fraction of these
probabilities represents our general formula for conditional
probability.

**Conditional Probability**

> The conditional probability of the outcome of interest $A$ given
condition $B$ is computed as the following: $$\begin{aligned}
P(A | B) = \frac{P(A\text{ and }B)}{P(B)}
\label{condProbEq}\end{aligned}$$

**Guided Practice**

  (a) Write out the
following statement in conditional probability notation: "*The
probability a random case has = *not* if it is known that = *not**".
Notice that the condition is now based on the student, not the parent.

  (b) Determine the probability from part (a).
The Probability table summarizing parental and student drug use.
may be helpful.[^26]


  (a) Determine the probability that one of the parents had used drugs if
it is known the student does not use drugs.

  (b) Using the answers from
part (b) and (c), compute
$$\begin{aligned}
P(\text{parents = used}|\text{student = not})
    + P(\text{parents = not}|\text{student = not})\end{aligned}$$
(c) Provide an intuitive argument to explain why the sum in (b) is
1.[^27]

The data indicate that drug use of parents and children are associated.
Does this mean the drug use of parents causes the drug use of the
students
 
[^28]

### Smallpox in Boston, 1721

The data set provides a sample of 6,224 individuals from the year 1721
who were exposed to smallpox in Boston.[^29] Doctors at the time
believed that inoculation, which involves exposing a person to the
disease in a controlled form, could reduce the likelihood of death.

Each case represents one person with two variables: innoculated and result . The variable
takes two levels: *yes* or *no*, indicating whether the person was
inoculated or not. The variable has outcomes *lived* or *died*. These
data are summarized in
the tables below.

  --------- ------- ----- ------ -------
                      yes     no   Total
            lived     238   5136    5374
            died        6    844     850
            Total     244   5980    6224
  --------- ------- ----- ------ -------

  : Contingency table for the data
  set.[]{label="smallpoxContingencyTable"}

  --------- ------- -------- -------- --------
                         yes       no    Total
            lived     0.0382   0.8252   0.8634
            died      0.0010   0.1356   0.1366
            Total     0.0392   0.9608   1.0000
  --------- ------- -------- -------- --------

  : Table proportions for the data, computed by dividing each count by
  the table total, 6224.[]{label="smallpoxProbabilityTable"}


  : Table proportions for the data, computed by dividing each count by
  the table total, 6224.[]{label="smallpoxProbabilityTable"}

**Guided Practice**

Write out, in formal notation, the
probability a randomly selected person who was not inoculated died from
smallpox, and find this probability.[^30]

**Guided Practice**

Determine the probability that an inoculated person died from smallpox.
How does this result compare with the result of the Guided Practice above
 
[^31]

**Guided Practice**

The people of Boston
self-selected whether or not to be inoculated.
(a) Is this study
observational or was this an experiment
 
 (b) Can we infer any causal
connection using these data
 
 (c) What are some potential confounding
variables that might influence whether someone *lived* or *died* and
also affect whether that person was inoculated
 
[^32]

### General multiplication rule

Section [1.1.6](#probabilityIndependence){reference-type="ref"
reference="probabilityIndependence"} introduced the Multiplication Rule
for independent processes. Here we provide the **General Multiplication rule** for events that might not
be independent.

**General Multiplication Rule**

> If $A$ and $B$ represent two outcomes or events, then $$\begin{aligned}
P(A\text{ and }B) = P(A | B)\times P(B)\end{aligned}$$

> It is useful to think of $A$ as the outcome of interest and $B$ as the
condition.

This General Multiplication Rule is simply a rearrangement of the
definition for conditional probability.

**Example**

Consider the smallpox data set. Suppose we are given only two pieces of
information: 96.08% of residents were not inoculated, and 85.88% of the
residents who were not inoculated ended up surviving. How could we
compute the probability that a resident was not inoculated and lived
 
 We
will compute our answer using the General Multiplication Rule and then
verify it using
the smallpox probability table. We want to determine
$$\begin{aligned}
P(\text{result = lived and inoculated = no})\end{aligned}$$
and we are given that $$\begin{aligned}
P(\text{result = lived }|\text{ inoculated = no})=0.8588 \\
P(\text{inoculated = no})=0.9608\end{aligned}$$ Among the
96.08% of people who were not inoculated, 85.88% survived:
$$\begin{aligned}
P(\text{result = lived and inoculated = no}) = 0.8588\times 0.9608 = 0.8251\end{aligned}$$
This is equivalent to the General Multiplication Rule. We can confirm
this probability in
the smallpox probability table at the intersection of *no* and
*lived* (with a small rounding error).

**Guided Practice**

Use $P($ = *yes*$) = 0.0392$ and $P($ = *lived* $|$ = *yes*$) = 0.9754$
to determine the probability that a person was both inoculated and
lived.[^33]

**Guided Practice**

If 97.45% of the people who were inoculated lived, what proportion of
inoculated people must have died
 
[^34]

**Sum of conditional probabilities**

> Let $A_1$, \..., $A_k$ represent all the disjoint outcomes for a
variable or process. Then if $B$ is an event, possibly for another
variable or process, we have: $$\begin{aligned}
P(A_1|B)+\cdots+P(A_k|B) = 1\end{aligned}$$

> The rule for complements also holds when an event and its complement are
conditioned on the same information: $$\begin{aligned}
P(A | B) = 1 - P(A^c | B)\end{aligned}$$

**Guided Practice**

Based on the probabilities computed above, does it appear that
inoculation is effective at reducing the risk of death from
smallpox
 
[^35]

### Independence considerations in conditional probability

If two processes are independent, then knowing the outcome of one should
provide no information about the other. We can show this is
mathematically true using conditional probabilities.

**Guided Practice**

Let $X$ and $Y$ represent the
outcomes of rolling two dice.

  (a) What is the probability that the first
die, $X$, is *1*
 
  (b) What is the probability that both $X$ and $Y$ are
*1*
 
  (c) Use the formula for conditional probability to compute $P(Y =$
*1* $| X =$ *1*$)$.
  (d) What is $P(Y=1)$
 
 Is this different from the
answer from part (c)
 
 Explain.[^36]

We can show in the Guided Practice (c) that the conditioning
information has no influence by using the Multiplication Rule for
independence processes: $$\begin{aligned}
P(Y=\text{1}|X=\text{1})
    &=& \frac{P(Y=\text{1 and }X=\text{1})}{P(X=\text{1})} \\
    &=& \frac{P(Y=\text{1})\times \color{oiGB}P(X=\text{1})}{\color{oiGB}P(X=\text{1})} \\
    &=& P(Y=\text{1}) \\\end{aligned}$$

**Guided Practice**

Ron is watching a roulette table in a casino and notices that the last
five outcomes were *black*. He figures that the chances of getting
*black* six times in a row is very small (about $1/64$) and puts his
paycheck on red. What is wrong with his reasoning
 
[^37]

### Tree diagrams

**Tree diagrams** are a tool to organize outcomes and probabilities around the structure
of the data. They are most useful when two or more processes occur in a
sequence and each process is conditioned on its predecessors.

The data fit this description. We see the population as split by : *yes*
and *no*. Following this split, survival rates were observed for each
group. This structure is reflected in the *tree diagram** shown in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. The first branch for is said to be the **primary**
branch while the other branches are **secondary** .

![A tree diagram of the data
set.[]{label="smallpoxTreeDiagram"}](figures/smallpoxTreeDiagram/smallpoxTreeDiagram.png){#smallpoxTreeDiagram
width="93%"}

Tree diagrams are annotated with marginal and conditional probabilities,
as shown in Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. This tree diagram splits the smallpox
data by innoculation into the *yes* and *no* groups with respective marginal
probabilities 0.0392 and 0.9608. The secondary branches are conditioned
on the first, so we assign conditional probabilities to these branches.
For example, the top branch in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"} is the probability that result = *lived*
conditioned on the information that innoculated = *yes*. We may (and usually do)
construct joint probabilities at the end of each branch in our tree by
multiplying the numbers we come across as we move from left to right.
These joint probabilities are computed using the General Multiplication
Rule: $$\begin{aligned}
&& P(\text{inoculated = yes and result = lived}) \\
    &&\quad = P(\text{inoculated = yes})\times P(\text{result = lived}|\text{inoculated = yes}) \\
    &&\quad = 0.0392\times 0.9754=0.0382\end{aligned}$$

**Example**

Consider the midterm and final for a statistics class. Suppose 13% of
students earned an *A* on the midterm. Of those students who earned an
*A* on the midterm, 47% received an *A* on the final, and 11% of the
students who earned lower than an *A* on the midterm received an *A* on
the final. You randomly pick up a final exam and notice the student
received an *A*. What is the probability that this student earned an *A*
on the midterm
 


The end-goal is to find
$P(\text{midterm = A} | \text{final = A})$. To
calculate this conditional probability, we need the following
probabilities: $$\begin{aligned}
P(\text{midterm = A and final = A}) \qquad\text{and}\qquad
P(\text{final = A})\end{aligned}$$ 


However, this
information is not provided, and it is not obvious how to calculate
these probabilities. Since we aren't sure how to proceed, it is useful
to organize the information into a tree diagram, as shown in
Figure [1.10](#testTree){reference-type="ref" reference="testTree"}.
When constructing a tree diagram, variables provided with marginal
probabilities are often used to create the tree's primary branches; in
this case, the marginal probabilities are provided for midterm grades.
The final grades, which correspond to the conditional probabilities
provided, will be shown on the secondary branches.

![A tree diagram describing the and
variables.[]{label="testTree"}](figures/testTree/testTree.png){#testTree
width="87%"}

With the tree diagram constructed, we may compute the required
probabilities: $$\begin{aligned}
&&P(\text{midterm = A and final = A}) = 0.0611 \\
&&P(\text{final = A})  \\
&& \quad= P(\text{midterm = other and final = A}) + P(\text{midterm = A and final = A}) \\
&& \quad= 0.0611 + 0.0957 = 0.1568\end{aligned}$$ The marginal
probability, $P($ = *A*$)$, was calculated by adding up all the joint
probabilities on the right side of the tree that correspond to = *A*. We
may now finally take the ratio of the two probabilities:
$$\begin{aligned}
P(\text{midterm = A} | \text{final = A}) &=& \frac{P(\text{midterm = A and final = A})}{P(\text{final = A})} \\
&=& \frac{0.0611}{0.1568} = 0.3897\end{aligned}$$ The probability the
student also earned an A on the midterm is about 0.39.

**Guided Practice**

After an introductory statistics course, 78% of students can
successfully construct tree diagrams. Of those who can construct tree
diagrams, 97% passed, while only 57% of those students who could not
construct tree diagrams passed.

  (a) Organize this information into a
tree diagram.

  (b) What is the probability that a randomly selected
student passed
 

  (c) Compute the probability a student is able to
construct a tree diagram if it is known that she passed.[^38]

Random variables {#randomVariablesSection}
----------------

**Example**

Two books are assigned for a statistics class: a textbook and its
corresponding study guide. The university bookstore determined 20% of
enrolled students do not buy either book, 55% buy the textbook only, and
25% buy both books, and these percentages are relatively constant from
one term to another. If there are 100 students enrolled, how many books
should the bookstore expect to sell to this
class
 

**Guided Practice**

Around 20 students will not buy either book (0 books total), about 55
will buy one book (55 books total), and approximately 25 will buy two
books (totaling 50 books for these 25 students). The bookstore should
expect to sell about 105 books for this class.

**Example**

Would you be surprised if the bookstore sold slightly more or less than
105 books
 
[^39]

The textbook costs \$137 and the study guide \$33. How much revenue
should the bookstore expect from this class of 100
students
 
 About 55
students will just buy a textbook, providing revenue of
$$\begin{aligned}
\$137 \times  55 = \$7,535\end{aligned}$$ The roughly 25 students who
buy both the textbook and the study guide would pay a total of
$$\begin{aligned}
(\$137 + \$33) \times  25 = \$170 \times  25 = \$4,250\end{aligned}$$
Thus, the bookstore should expect to generate about
$\$7,535 + \$4,250 = \$11,785$ from these 100 students for this one
class. However, there might be some *sampling variability* so the actual
amount may differ by a little bit.

![Probability distribution for the bookstore's revenue from a single
student. The distribution balances on a triangle representing the
average revenue per
student.[]{label="bookCostDist"}](figures/bookCostDist/bookCostDist.png){#bookCostDist
width="69%"}

**Example**

What is the average revenue per student for this
course
 
 The
expected total revenue is \$11,785, and there are 100 students.
Therefore the expected revenue per student is
$\$11,785/100 =  \$117.85$.

### Expectation

We call a variable or process with a numerical outcome a , and we
usually represent this random variable with a capital letter such as
$X$, $Y$, or $Z$. The amount of money a single student will spend on her
statistics books is a random variable, and we represent it by $X$.

**Random Variable**
> A random process or variable with a numerical outcome.

The possible outcomes of $X$ are labeled with a corresponding lower case
letter $x$ and subscripts. For example, we write $x_1=\$0$, $x_2=\$137$,
and $x_3=\$170$, which occur with probabilities $0.20$, $0.55$, and
$0.25$. The distribution of $X$ is summarized in
Figure [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and
the table below

  $i$            1       2       3      Total
  ------------ ------ ------- ------- -------
  $x_i$         \$0    \$137   \$170       --
  $P(X=x_i)$    0.20   0.55    0.25      1.00

  : The probability distribution for the random variable $X$,
  representing the bookstore's revenue from a single
  student.[]{label="statSpendDist"}

We computed the average outcome of $X$ as \$117.85 in
dealing with the revenue per student. We call this average the **expected value** of $X$, denoted by
$E(X)$. The expected value of a random variable is computed by adding
each outcome weighted by its probability: $$\begin{aligned}
E(X) &= 0 \times  P(X=0) + 137 \times  P(X=137) + 170 \times  P(X=170) \\
    &= 0 \times  0.20 + 137 \times  0.55 + 170 \times  0.25 = 117.85\end{aligned}$$
    
**Expected value of a Discrete Random Variable**

> If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$, the expected value of $X$ is the sum of each outcome
multiplied by its corresponding probability: $$\begin{aligned}
E(X)    &= x_1\times P(X=x_1) + \cdots + x_k\times P(X=x_k) \notag \\
    &= \sum_{i=1}^{k}x_iP(X=x_i)\end{aligned}$$ The Greek letter $\mu$
may be used in place of the notation $E(X)$.

The expected value for a random variable represents the average outcome.
For example, $E(X)=117.85$ represents the average amount the bookstore
expects to make from a single student, which we could also write as
$\mu=117.85$.

It is also possible to compute the expected value of a continuous random
variable. However, it requires a little calculus and we save it for a
later class.[^40]

In physics, the expectation holds the same meaning as the center of
gravity. The distribution can be represented by a series of weights at
each outcome, and the mean represents the balancing point. This is
represented in Figures [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and [1.12](#bookWts){reference-type="ref"
reference="bookWts"}. The idea of a center of gravity also expands to
continuous probability distributions.
Figure [1.13](#contBalance){reference-type="ref"
reference="contBalance"} shows a continuous probability distribution
balanced atop a wedge placed at the mean.

![A weight system representing the probability distribution for $X$. The
string holds the distribution at the mean to keep the system
balanced.[]{label="bookWts"}](figures/bookWts/bookWts.png){#bookWts
width="72%"}

![A continuous distribution can also be balanced at its
mean.[]{label="contBalance"}](figures/contBalance/contBalance.png){#contBalance
width="65%"}

### Variability in random variables

Suppose you ran the university bookstore. Besides how much revenue you
expect to generate, you might also want to know the volatility
(variability) in your revenue.

The and can be used to describe the variability of a random variable. We first computed deviations from
the mean ($x_i - \mu$), squared those deviations, and took an average to
get the variance. In the case of a random variable, we again compute
squared deviations. However, we take their sum weighted by their
corresponding probabilities, just like we did for the expectation. This
weighted sum of squared deviations equals the variance, and we calculate
the standard deviation by taking the square root of the variance.

**General variance formula**

> If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$ and expected value $\mu=E(X)$, then the variance of
$X$, denoted by $Var(X)$ or the symbol $\sigma^2$, is $$\begin{aligned}
\sigma^2 &= (x_1-\mu)^2\times P(X=x_1) + \cdots \notag \\
    & \qquad\quad\cdots+ (x_k-\mu)^2\times P(X=x_k) \notag \\
    &= \sum_{j=1}^{k} (x_j - \mu)^2 P(X=x_j)\end{aligned}$$ The standard
deviation of $X$, labeled $\sigma$, is the square root of the variance.

**Example**

Compute the expected value, variance, and standard deviation of $X$, the
revenue of a single statistics student for the bookstore. It is useful
to construct a table that holds computations for each outcome
separately, then add up the results.

  $i$                           1       2       3    Total
  ------------------------ ------ ------- ------- --------
  $x_i$                       \$0   \$137   \$170 
  $P(X=x_i)$                 0.20    0.55    0.25 
  $x_i \times  P(X=x_i)$        0   75.35   42.50   117.85

Thus, the expected value is $\mu=117.85$, which we computed earlier. The
variance can be constructed by extending this table:

  $i$                                     1        2         3    Total
  ------------------------------ ---------- -------- --------- --------
  $x_i$                                 \$0    \$137     \$170 
  $P(X=x_i)$                           0.20     0.55      0.25 
  $x_i \times  P(X=x_i)$                  0    75.35     42.50   117.85
  $x_i - \mu$                       -117.85    19.15     52.15 
  $(x_i-\mu)^2$                    13888.62   366.72   2719.62 
  $(x_i-\mu)^2\times P(X=x_i)$       2777.7    201.7     679.9   3659.3

The variance of $X$ is $\sigma^2 = 3659.3$, which means the standard
deviation is $\sigma = \sqrt{3659.3} = \$60.49$.

**Guided Practice**

The bookstore also offers a chemistry textbook for \$159 and a book
supplement for \$41. From past experience, they know about 25% of
chemistry students just buy the textbook while 60% buy both the textbook
and supplement.[^41]

1.  What proportion of students don't buy either book
 
 Assume no
    students buy the supplement without the textbook.

2.  Let $Y$ represent the revenue from a single student. Write out the
    probability distribution of $Y$, i.e. a table for each outcome and
    its associated probability.

3.  Compute the expected revenue from a single chemistry student.

4.  Find the standard deviation to describe the variability associated
    with the revenue from a single student.

### Linear combinations of random variables

So far, we have thought of each variable as being a complete story in
and of itself. Sometimes it is more appropriate to use a combination of
variables. For instance, the amount of time a person spends commuting to
work each week can be broken down into several daily commutes.
Similarly, the total gain or loss in a stock portfolio is the sum of the
gains and losses in its components.

**Example**

John travels to work five days a week. We will use $X_1$ to represent
his travel time on Monday, $X_2$ to represent his travel time on
Tuesday, and so on. Write an equation using $X_1$, \..., $X_5$ that
represents his travel time for the week, denoted by $W$. His total
weekly travel time is the sum of the five daily values:
$$W = X_1 + X_2 + X_3 + X_4 + X_5$$ Breaking the weekly travel time $W$
into pieces provides a framework for understanding each source of
randomness and is useful for modeling $W$.

**Example**

It takes John an average of 18 minutes each day to commute to work. What
would you expect his average commute time to be for the week
 
 We were
told that the average (i.e. expected value) of the commute time is 18
minutes per day: $E(X_i) = 18$. To get the expected time for the sum of
the five days, we can add up the expected time for each individual day:
$$\begin{aligned}
E(W) &= E(X_1 + X_2 + X_3 + X_4 + X_5) \\
    &= E(X_1) + E(X_2) + E(X_3) + E(X_4) + E(X_5) \\
    &= 18 + 18 + 18 + 18 + 18 = 90\text{ minutes}\end{aligned}$$ The
expectation of the total time is equal to the sum of the expected
individual times. More generally, the expectation of a sum of random
variables is always the sum of the expectation for each random variable.

**Guided Practice**

Elena is
selling a TV at a cash auction and also intends to buy a toaster oven in
the auction. If $X$ represents the profit for selling the TV and $Y$
represents the cost of the toaster oven, write an equation that
represents the net change in Elena's cash.[^42]

Based on past auctions, Elena figures she should expect to make about
\$175 on the TV and pay about \$23 for the toaster oven. In total, how
much should she expect to make or spend
 
[^43]

**Guided Practice**

Would you be surprised if
John's weekly commute wasn't exactly 90 minutes or if Elena didn't make
exactly \$152
 
 Explain.[^44]

Two important concepts concerning combinations of random variables have
so far been introduced. First, a final value can sometimes be described
as the sum of its parts in an equation. Second, intuition suggests that
putting the individual average values into this equation gives the
average value we would expect in total. This second point needs
clarification -- it is guaranteed to be true in what are called *linear
combinations of random variables*.

A **Linear Combination** of two random variables $X$ and $Y$ is a fancy phrase to describe a
combination $$aX + bY$$ where $a$ and $b$ are some fixed and known
numbers. For John's commute time, there were five random variables --
one for each work day -- and each random variable could be written as
having a fixed coefficient of 1:
$$1X_1 + 1 X_2 + 1 X_3 + 1 X_4 + 1 X_5$$ For Elena's net gain or loss,
the $X$ random variable had a coefficient of +1 and the $Y$ random
variable had a coefficient of -1.

When considering the average of a linear combination of random
variables, it is safe to plug in the mean of each random variable and
then compute the final result. For a few examples of nonlinear
combinations of random variables -- cases where we cannot simply plug in
the means -- see the footnote.[^45]

**Linear combinations of random variables and the average result**

> If $X$ and $Y$ are random variables, then a linear combination of the
random variables is given by $$\begin{aligned}
\label{linComboOfRandomVariablesXAndY}
aX + bY\end{aligned}$$ where $a$ and $b$ are some fixed numbers. To
compute the average value of a linear combination of random variables,
plug in the average of each individual random variable and compute the
result: $$\begin{aligned}
a\times E(X) + b\times E(Y)\end{aligned}$$ Recall that the expected
value is the same as the mean, e.g. $E(X) = \mu_X$.

**Example**

Leonard has invested \$6000 in Google Inc. (stock ticker: GOOG) and
\$2000 in Exxon Mobil Corp. (XOM). If $X$ represents the change in
Google's stock next month and $Y$ represents the change in Exxon Mobil
stock next month, write an equation that describes how much money will
be made or lost in Leonard's stocks for the month. For simplicity, we
will suppose $X$ and $Y$ are not in percents but are in decimal form
(e.g. if Google's stock increases 1%, then $X=0.01$; or if it loses 1%,
then $X=-0.01$). Then we can write an equation for Leonard's gain as
$$\begin{aligned}
\$6000\times X + \$2000\times Y\end{aligned}$$ If we plug in the change
in the stock value for $X$ and $Y$, this equation gives the change in
value of Leonard's stock portfolio for the month. A positive value
represents a gain, and a negative value represents a loss.

**Guided Practice**

Suppose Google and Exxon
Mobil stocks have recently been rising 2.1% and 0.4% per month,
respectively. Compute the expected change in Leonard's stock portfolio
for next month.[^46]

**Guided Practice**

You should have found that Leonard expects a positive gain. However, would you
be surprised if he actually had a loss this month
 
[^47]

### Variability in linear combinations of random variables

Quantifying the average outcome from a linear combination of random
variables is helpful, but it is also important to have some sense of the
uncertainty associated with the total outcome of that combination of
random variables. We calculated the expected net gain or loss of Leonard's stock
portfolio was considered in Guided
Practice. However, there was
no quantitative discussion of the volatility of this portfolio. For
instance, while the average monthly gain might be about \$134 according
to the data, that gain is not guaranteed.
Figure [1.14](#changeInLeonardsStockPortfolioFor36Months){reference-type="ref"
reference="changeInLeonardsStockPortfolioFor36Months"} shows the monthly
changes in a portfolio like Leonard's during the 36 months from 2009 to
2011. The gains and losses vary widely, and quantifying these
fluctuations is important when investing in stocks.

![The change in a portfolio like Leonard's for the 36 months from 2009
to 2011, where \$6000 is in Google's stock and \$2000 is in Exxon
Mobil's.[]{label="changeInLeonardsStockPortfolioFor36Months"}](figures/changeInLeonardsStockPortfolioFor36Months/changeInLeonardsStockPortfolioFor36Months.png){#changeInLeonardsStockPortfolioFor36Months
width="65%"}

Just as we have done in many previous cases, we use the variance and
standard deviation to describe the uncertainty associated with Leonard's
monthly returns. To do so, the variances of each stock's monthly return
will be useful, and these are shown in
the table below. The stocks' returns are nearly
independent.

           Mean ($\bar{x}$)   Standard deviation ($s$)   Variance ($s^2$)
  ------ ------------------ -------------------------- ------------------
  GOOG               0.0210                     0.0846             0.0072
  XOM                0.0038                     0.0519             0.0027

  : The mean, standard deviation, and variance of the GOOG and XOM
  stocks. These statistics were estimated from historical stock data, so
  notation used for sample statistics has been
  used.[]{label="sumStatOfGOOGXOM"}

Here we use an equation from probability theory to describe the
uncertainty of Leonard's monthly returns; we leave the proof of this
method to a dedicated probability course. The variance of a linear
combination of random variables can be computed by plugging in the
variances of the individual random variables and squaring the
coefficients of the random variables: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ It is
important to note that this equality assumes the random variables are
independent; if independence doesn't hold, then more advanced methods
are necessary. This equation can be used to compute the variance of
Leonard's monthly return: $$\begin{aligned}
Var(6000\times X + 2000\times Y)
    &= 6000^2\times Var(X) + 2000^2\times Var(Y) \\
    &= 36,000,000\times 0.0072 + 4,000,000\times 0.0027 \\
    &= 270,000\end{aligned}$$ The standard deviation is computed as the
square root of the variance: $\sqrt{270,000} = \$520$. While an average
monthly return of \$134 on an \$8000 investment is nothing to scoff at,
the monthly returns are so volatile that Leonard should not expect this
income to be very stable.

**Variability of linear combinations of random variables**

>The variance of a linear combination of random variables may be computed
by squaring the constants, substituting in the variances for the random
variables, and computing the result: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ This
equation is valid as long as the random variables are independent of
each other. The standard deviation of the linear combination may be
found by taking the square root of the variance.

**Example**

Suppose John's daily commute has a standard deviation of 4 minutes. What
is the uncertainty in his total commute time for the week
 

The expression for John's commute
time was $$\begin{aligned}
X_1 + X_2 + X_3 + X_4 + X_5\end{aligned}$$ Each coefficient is 1, and
the variance of each day's time is $4^2=16$. Thus, the variance of the
total weekly commute time is $$\begin{aligned}
&\text{variance }= 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 = 5\times 16 = 80 \\
&\text{standard deviation } = \sqrt{\text{variance}} = \sqrt{80} = 8.94\end{aligned}$$
The standard deviation for John's weekly work commute time is about 9
minutes.

**Guided Practice**

The computation in
the example above relied on an important
assumption: the commute time for each day is independent of the time on
other days of that week. Do you think this is valid
 
 Explain.[^48]


**Guided Practice**

Elena is
selling a TV at a cash auction and also intends to buy a toaster oven in
the auction. If $X$ represents the profit for selling the TV and $Y$
represents the cost of the toaster oven.
Suppose these auctions are approximately independent and the variability
in auction prices associated with the TV and toaster oven can be
described using standard deviations of \$25 and \$8. Compute the
standard deviation of Elena's net gain.[^49]

The negative coefficient for $Y$ in the linear combination was
eliminated when we squared the coefficients. This generally holds true:
negatives in a linear combination will have no impact on the variability
computed for a linear combination, but they do impact the expected value
computations.

[^1]: Here are four examples. (i) Whether someone gets sick in the next
    month or not is an apparently random process with outcomes *sick*
    and *not*. (ii) We can *generate* a random process by randomly
    picking a person and measuring that person's height. The outcome of
    this process will be a positive number. (iii) Whether the stock
    market goes up or down next week is a seemingly random process with
    possible outcomes *up*, *down*, and *no\_change*. Alternatively, we
    could have used the percent change in the stock market as a
    numerical outcome. (iv) Whether your roommate cleans her dishes
    tonight probably seems like a random process with possible outcomes
    *cleans\_dishes* and *leaves\_dishes*.

[^2]: () The random process is a die roll, and at most one of these
    outcomes can come up. This means they are disjoint outcomes.
    (b) $P($*1* or *4* or
    *5*$) = P($*1*$)+P($*4*$)+P($*5*$) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2}$

[^3]: (a) Yes. Each email is categorized in only one level of . (b)
    Small: $\frac{2827}{3921} = 0.721$. Big: $\frac{545}{3921} = 0.139$.
    (c) $P($*small* or
    *big*$) = P($*small*$) + P($*big*$) = 0.721 + 0.139 = 0.860$.

[^4]: (a) $P(A) = P($*1* or
    *2*$) = P($*1*$) + P($*2*$) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}$.
    (b) Similarly, $P(B) = 1/3$.

[^5]: (a) Outcomes *2* and *3*. (b) Yes, events $B$ and $D$ are disjoint
    because they share no outcomes. (c) The events $A$ and $D$ share an
    outcome in common, *2*, and so are not disjoint.

[^6]: Since $B$ and $D$ are disjoint events, use the Addition Rule:
    $P(B$ or
    $D) = P(B) + P(D) = \frac{1}{3} + \frac{1}{3} = \frac{2}{3}$.

[^7]: The 52 cards are split into four : $\clubsuit$ (club),
    $\diamondsuit$ (diamond), $\heartsuit$ (heart), $\spadesuit$
    (spade). Each suit has its 13 cards labeled: *2*, *3*, \..., *10*,
    *J* (jack), *Q* (queen), *K* (king), and *A* (ace). Thus, each card
    is a unique combination of a suit and a label, e.g. *4$\heartsuit$*
    and *J$\clubsuit$*. The 12 cards represented by the jacks, queens,
    and kings are called . The cards that are $\diamondsuit$ or
    $\heartsuit$ are typically colored red while the other two suits are
    typically colored black.

[^8]: (a) There are 52 cards and 13 diamonds. If the cards are
    thoroughly shuffled, each card has an equal chance of being drawn,
    so the probability that a randomly selected card is a diamond is
    $P({\color{redcards}\diamondsuit}) = \frac{13}{52} = 0.250$.
    (b) Likewise, there are 12 face cards, so $P($face
    card$) = \frac{12}{52} = \frac{3}{13} = 0.231$.

[^9]: The Venn diagram shows face cards split up into "face card but not
    $\diamondsuit$" and "face card and $\diamondsuit$". Since these
    correspond to disjoint events, $P($face card$)$ is found by adding
    the two corresponding probabilities:
    $\frac{3}{52} + \frac{9}{52} = \frac{12}{52} = \frac{3}{13}$.

[^10]: (a) If $A$ and $B$ are disjoint, $A$ and $B$ can never occur
    simultaneously. (b) If $A$ and $B$ are disjoint, then the last term
    of
    Equation ({reference-type="ref"
    reference="generalAdditionRule"}) is 0 (see part (a)) and we are
    left with the Addition Rule for disjoint events.

[^11]: Both the counts and corresponding probabilities (e.g.
    $2659/3921 = 0.678$) are shown. Notice that the number of emails
    represented in the left circle corresponds to $2659 + 168 = 2827$,
    and the number represented in the right circle is $168 + 199 = 367$.

     

    ![image](figures/emailSpamNumberVenn/emailSpamNumberVenn.png){height="13mm"}

[^12]: (a) The solution is represented by the intersection of the two
    circles: 0.043. (b) This is the sum of the three disjoint
    probabilities shown in the circles: $0.678 + 0.043 + 0.051 = 0.772$.

[^13]: The probabilities of (a) do not sum to 1. The second probability
    in (b) is negative. This leaves (c), which sure enough satisfies the
    requirements of a distribution. One of the three was said to be the
    actual distribution of US household incomes, so it must be (c).

[^14]: It is also possible to construct a distribution plot when income
    is not artificially binned into four groups.

[^15]: (a) The outcomes are disjoint and each has probability $1/6$, so
    the total probability is $4/6=2/3$. (b) We can also see that
    $P(D)=\frac{1}{6} + \frac{1}{6} = 1/3$. Since $D$ and $D^c$ are
    disjoint, $P(D) + P(D^c) = 1$.

[^16]: Brief solutions: (a) $A^c=\{$*3*, *4*, *5*, *6*$\}$ and
    $B^c=\{$*1*, *2*, *3*, *5*$\}$. (b) Noting that each outcome is
    disjoint, add the individual outcome probabilities to get
    $P(A^c)=2/3$ and $P(B^c)=2/3$. (c) $A$ and $A^c$ are disjoint, and
    the same is true of $B$ and $B^c$. Therefore, $P(A) + P(A^c) = 1$
    and $P(B) + P(B^c) = 1$.

[^17]: (a) The complement of $A$: when the total is equal to *12*.
    (b) $P(A^c) = 1/36$. (c) Use the probability of the complement from
    part (b), $P(A^c) = 1/36$, and
    Equation ({reference-type="ref"
    reference="complement"}): $P($less than
    *12*$) = 1 - P($*12*$) = 1 - 1/36 = 35/36$.

[^18]: (a) First find $P($*6*$)=5/36$, then use the complement: $P($not
    *6*$) = 1 - P($*6*$) = 31/36$. (b) First find the complement, which
    requires much less effort: $P($*2* or *3*$)=1/36+2/36=1/12$. Then
    calculate $P(B) = 1-P(B^c) = 1-1/12 = 11/12$. (c) As before, finding
    the complement is the clever way to determine $P(D)$. First find
    $P(D^c) = P($*11* or *12*$)=2/36 + 1/36=1/12$. Then calculate
    $P(D) = 1 - P(D^c) = 11/12$.

[^19]: (a) The probability the first person is left-handed is $0.09$,
    which is the same for the second person. We apply the Multiplication
    Rule for independent processes to determine the probability that
    both will be left-handed: $0.09\times 0.09 = 0.0081$.

    (b) It is reasonable to assume the proportion of people who are
    ambidextrous (both right and left handed) is nearly 0, which results
    in $P($right-handed$)=1-0.09=0.91$. Using the same reasoning as in
    part (a), the probability that both will be right-handed is
    $0.91\times 0.91 = 0.8281$.

[^20]: (a) The abbreviations *RH* and *LH* are used for right-handed and
    left-handed, respectively. Since each are independent, we apply the
    Multiplication Rule for independent processes: $$\begin{aligned}
    P(\text{all five are RH})
    &= P(\text{first = RH, second = RH, ..., fifth = RH}) \\
    &= P(\text{first = RH})\times P(\text{second = RH})\times  \dots \times P(\text{fifth = RH}) \\
    &= 0.91\times 0.91\times 0.91\times 0.91\times 0.91 = 0.624\end{aligned}$$

    (b) Using the same reasoning as in (a),
    $0.09\times 0.09\times 0.09\times 0.09\times 0.09 = 0.0000059$

    (c) Use the complement, $P($all five are *RH*$)$, to answer this
    question: $$\begin{aligned}
    P(\text{not all RH})
        = 1 - P(\text{all RH})
        = 1 - 0.624 = 0.376\end{aligned}$$

[^21]: The actual proportion of the U.S. population that is *female* is
    about 50%, and so we use 0.5 for the probability of sampling a
    woman. However, this probability does differ in other countries.

[^22]: Brief answers are provided. (a) This can be written in
    probability notation as $P($a randomly selected person is male and
    right-handed$)=0.455$. (b) 0.207. (c) 0.045. (d) 0.0093.

[^23]: Ellis GJ and Stone LH. 1979. Marijuana Use in College: An
    Evaluation of a Modeling Explanation. Youth and Society 10:323-334.

[^24]: Each of the four outcome combination are disjoint, all
    probabilities are indeed non-negative, and the sum of the
    probabilities is $0.28 + 0.19 + 0.21 + 0.32 = 1.00$.

[^25]: This is an observational study and no causal conclusions may be
    reached.

[^26]: (a)
    $P(\text{parent = not} | \text{student = not})$.
    (b) Equation ({reference-type="ref"
    reference="condProbEq"}) for conditional probability indicates we
    should first find
    $P(\text{parents = not and student = not})=0.32$
    and $P(\text{student = not})=0.51$. Then the ratio
    represents the conditional probability: $0.32/0.51 = 0.63$.

[^27]: (a) This probability is
    $\frac{P(\text{parents = used and student = not})}{P(\text{student = not})} = \frac{0.19}{0.51} = 0.37$.
    (b) The total equals 1. (c) Under the condition the student does not
    use drugs, the parents must either use drugs or not. The complement
    still appears to work *when conditioning on the same information*.

[^28]: No. This was an observational study. Two potential confounding
    variables include and . Can you think of others
 


[^29]: Fenner F. 1988. *Smallpox and Its Eradication (History of
    International Public Health, No. 6)*. Geneva: World Health
    Organization. ISBN 92-4-156110-6.

[^30]: $P($ = *died* $|$ =
    *no*$) = \frac{P(\text{result = died and inoculated = no})}{P(\text{inoculated = no})} = \frac{0.1356}{0.9608} = 0.1411$.

[^31]: $P($ = *died* $|$ =
    *yes*$) = \frac{P(\text{result = died and inoculated = yes})}{P(\text{inoculated = yes})} = \frac{0.0010}{0.0392} = 0.0255$.
    The death rate for individuals who were inoculated is only about
    1 in 40 while the death rate is about 1 in 7 for those who were not
    inoculated.

[^32]: Brief answers: (a) Observational. (b) No, we cannot infer
    causation from this observational study. (c) Accessibility to the
    latest and best medical care. There are other valid answers for
    part (c).

[^33]: The answer is 0.0382.

[^34]: There were only two possible outcomes: *lived* or *died*. This
    means that 100% - 97.45% = 2.55% of the people who were inoculated
    died.

[^35]: The samples are large relative to the difference in death rates
    for the "inoculated" and "not inoculated" groups, so it seems there
    is an association between and . However, as noted in the solution to
    Guided
    Practice, this is an
    observational study and we cannot be sure if there is a causal
    connection. (Further research has shown that inoculation is
    effective at reducing death rates.)

[^36]: Brief solutions: (a) $1/6$. (b) $1/36$.
    (c) $\frac{P(Y = \text{ 1 and }X=\text{ 1})}{P(X=\text{ 1})} = \frac{1/36}{1/6} = 1/6$.
    (d) The probability is the same as in part (c): $P(Y=1)=1/6$. The
    probability that $Y=1$ was unchanged by knowledge about $X$, which
    makes sense as $X$ and $Y$ are independent.

[^37]: He has forgotten that the next roulette spin is independent of
    the previous spins. Casinos do employ this practice; they post the
    last several outcomes of many betting games to trick unsuspecting
    gamblers into believing the odds are in their favor. This is called
    the .

[^38]: (a) The tree diagram is shown to the right. (b) Identify which
    two joint probabilities represent students who passed, and add them:
    $P($passed$) = 0.7566+0.1254= 0.8820$. (c) $P($construct tree
    diagram $|$ passed$) = \frac{0.7566}{0.8820} = 0.8578$.\
     

    ![image](figures/treeDiagramAndPass/treeDiagramAndPass.png){width="\\textwidth"}

[^39]: If they sell a little more or a little less, this should not be a
    surprise. For example, if we would flip
    a coin 100 times, it will not usually come up heads exactly half the
    time, but it will probably be close.

[^40]: $\mu = \int xf(x)dx$ where $f(x)$ represents a function for the
    density curve.

[^41]: (a) 100% - 25% - 60% = 15% of students do not buy any books for
    the class. Part (b) is represented by the first two lines in the
    table below. The expectation for part (c) is given as the total on
    the line $y_i\times P(Y=y_i)$. The result of part (d) is the
    square-root of the variance listed on in the total on the last line:
    $\sigma = \sqrt{Var(Y)} = \$69.28$.

                   $i$ (scenario)   1 (*noBook*)   2 (*textbook*)   3 (*both*)                   Total
      --------------------------- -------------- ---------------- ------------ -----------------------
                            $y_i$           0.00           159.00       200.00 
                       $P(Y=y_i)$           0.15             0.25         0.60 
             $y_i\times P(Y=y_i)$           0.00            39.75       120.00         $E(Y) = 159.75$
                       $y_i-E(Y)$        -159.75            -0.75        40.25 
                   $(y_i-E(Y))^2$       25520.06             0.56      1620.06 
        $(y_i-E(Y))^2\times P(Y)$         3828.0              0.1        972.0   $Var(Y) \approx 4800$

[^42]: She will make $X$ dollars on the TV but spend $Y$ dollars on the
    toaster oven: $X-Y$.

[^43]: $E(X-Y) = E(X) - E(Y) = 175 - 23 = \$152$. She should expect to
    make about \$152.

[^44]: No, since there is probably some variability. For example, the
    traffic will vary from one day to next, and auction prices will vary
    depending on the quality of the merchandise and the interest of the
    attendees.

[^45]: If $X$ and $Y$ are random variables, consider the following
    combinations: $X^{1+Y}$, $X\times Y$, $X/Y$. In such cases, plugging
    in the average value for each random variable and computing the
    result will not generally lead to an accurate average value for the
    end result.

[^46]: $E(\$6000\times X + \$2000\times Y) = \$6000\times 0.021 + \$2000\times 0.004 = \$134$.

[^47]: No. While stocks tend to rise over time, they are often volatile
    in the short term.

[^48]: One concern is whether traffic patterns tend to have a weekly
    cycle (e.g. Fridays may be worse than other days). If that is the
    case, and John drives, then the assumption is probably not
    reasonable. However, if John walks to work, then his commute is
    probably not affected by any weekly traffic cycle.

[^49]: The equation for Elena can be written as $$\begin{aligned}
    (1)\times X + (-1)\times Y\end{aligned}$$ The variances of $X$ and
    $Y$ are 625 and 64. We square the coefficients and plug in the
    variances: $$\begin{aligned}
    (1)^2\times Var(X) + (-1)^2\times Var(Y) = 1\times 625 + 1\times 64 = 689\end{aligned}$$
    The variance of the linear combination is 689, and the standard
    deviation is the square root of 689: about \$26.25.